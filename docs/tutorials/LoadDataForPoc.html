<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh" lang="zh" data-whc_version="26.0">
    <head><link rel="shortcut icon" href="../favicon.ico"/><link rel="icon" href="../favicon.ico"/><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="description" content="在部署完 DolphinDB 后，将历史数据导入数据库是后续进行数据查询、计算和分析的基础。为协助用户快速导入数据，本文档基于 DolphinDB 已有的教程与大量用户的实践经验，从操作者角度出发，以 CSV 格式的文件为例，详细介绍金融行业用户导入逐笔数据的完整操作步骤。 在导入历史数据之前，需要先将 CSV 文件存放在部署了 DolphinDB 的服务器上，然后从 DolphinDB ..."/><meta name="DC.rights.owner" content="(C) 版权 2025"/><meta name="copyright" content="(C) 版权 2025"/><meta name="generator" content="DITA-OT"/><meta name="DC.type" content="topic"/><meta name="DC.coverage" content=""/><meta name="DC.relation" content="../tutorials/about_tutorials.html"/><meta name="prodname" content="DolphinDB"/><meta name="brand" content="DolphinDB"/><meta name="DC.creator" content="DolphinDB"/><meta name="DC.publisher" content="DDB N/A DDB 200"/><meta name="DC.format" content="HTML5"/><meta name="DC.identifier" content="金融-poc-用户历史数据导入指导手册之股票-level-2-逐笔篇"/><title>金融 PoC 用户历史数据导入指导手册之股票 Level-2 逐笔篇</title><!--  Generated with Oxygen version 26.0, build number 2024012323.  --><meta name="wh-path2root" content="../"/><meta name="wh-toc-id" content="&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;?workdir /tmp/temp20250305183303418/tutorials?&gt;&lt;?workdir-uri file:/tmp/temp20250305183303418/tutorials/?&gt;&lt;?path2project ../?&gt;&lt;?path2project-uri ../?&gt;&lt;?path2rootmap-uri ../?&gt;&lt;topic xmlns:dita-ot=&#34;http://dita-ot.sourceforge.net/ns/201007/dita-ot&#34; xmlns:ditaarch=&#34;http://dita.oasis-open.org/architecture/2005/&#34; class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;金融-poc-用户历史数据导入指导手册之股票-level-2-逐笔篇&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:1;1:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:1;1:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;金融 PoC 用户历史数据导入指导手册之股票 Level-2 逐笔篇&lt;/title&gt;&lt;prolog class=&#34;- topic/prolog &#34;&gt;&lt;author class=&#34;- topic/author &#34; xtrc=&#34;author:1;12:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DolphinDB&lt;/author&gt;&lt;publisherinformation class=&#34;- topic/publisher bookmap/publisherinformation &#34; xtrc=&#34;publisherinformation:1;14:31&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt; &lt;person class=&#34;- topic/data bookmap/person &#34; xtrc=&#34;person:1;15:21&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DDB&lt;/person&gt; &lt;printlocation class=&#34;- topic/data bookmap/printlocation &#34; xtrc=&#34;printlocation:1;16:28&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;N/A&lt;/printlocation&gt; &lt;published class=&#34;- topic/data bookmap/published &#34; xtrc=&#34;published:1;17:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt; &lt;person class=&#34;- topic/data bookmap/person &#34; xtrc=&#34;person:2;18:25&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DDB&lt;/person&gt; &lt;publishtype class=&#34;- topic/data bookmap/publishtype &#34; value=&#34;HTML&#34; xtrc=&#34;publishtype:1;19:44&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;revisionid class=&#34;- topic/ph bookmap/revisionid &#34; xtrc=&#34;revisionid:1;20:29&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;200&lt;/revisionid&gt; &lt;summary class=&#34;- topic/ph bookmap/summary &#34; xtrc=&#34;summary:1;22:27&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;data class=&#34;- topic/data &#34; xtrc=&#34;data:1;23:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;/published&gt; &lt;data class=&#34;- topic/data &#34; xtrc=&#34;data:2;25:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;/publisherinformation&gt;&lt;metadata class=&#34;- topic/metadata &#34;&gt;&lt;audience class=&#34;- topic/audience &#34; xtrc=&#34;audience:2;39:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt;&lt;audience class=&#34;- topic/audience &#34; xtrc=&#34;audience:1;28:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt;&lt;category class=&#34;- topic/category &#34; xtrc=&#34;category:1;29:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt;&lt;prodinfo class=&#34;- topic/prodinfo &#34; xtrc=&#34;prodinfo:1;34:23&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt; &lt;prodname class=&#34;- topic/prodname &#34; xtrc=&#34;prodname:1;35:27&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DolphinDB&lt;/prodname&gt; &lt;brand class=&#34;- topic/brand &#34; xtrc=&#34;brand:1;36:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DolphinDB&lt;/brand&gt; &lt;/prodinfo&gt;&lt;/metadata&gt;&lt;/prolog&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:1;1:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:1;3:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;在部署完 DolphinDB 后，将历史数据导入数据库是后续进行数据查询、计算和分析的基础。为协助用户快速导入数据，本文档基于 DolphinDB 已有的教程与大量用户的实践经验，从操作者角度出发，以 CSV 格式的文件为例，详细介绍金融行业用户导入逐笔数据的完整操作步骤。&lt;/p&gt;&lt;/body&gt;&lt;related-links class=&#34;- topic/related-links &#34;&gt;&lt;linkpool class=&#34;- topic/linkpool &#34; xtrc=&#34;topicref:110;145:77&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/chap_tutorials.ditamap&#34;&gt;&lt;link class=&#34;- topic/link &#34; format=&#34;dita&#34; href=&#34;../tutorials/about_tutorials.dita&#34; mapclass=&#34;- map/topicref bookmap/chapter &#34; role=&#34;parent&#34; scope=&#34;local&#34; type=&#34;topic&#34; xtrc=&#34;topicref:1;5:53&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/chap_tutorials.ditamap&#34;&gt;&lt;?ditaot usertext?&gt;&lt;linktext class=&#34;- topic/linktext &#34;&gt;&lt;?ditaot usertext?&gt;教程&lt;/linktext&gt;&lt;?ditaot usershortdesc?&gt;&lt;desc class=&#34;- topic/desc &#34;&gt;DolphinDB 产品使用教程&lt;/desc&gt;&lt;/link&gt;&lt;/linkpool&gt;&lt;/related-links&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;1-任务规划&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:2;5:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:2;5:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;1. 任务规划&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:2;5:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:2;7:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;在导入历史数据之前，需要先将 CSV 文件存放在部署了 DolphinDB 的服务器上，然后从 DolphinDB 数据类型兼容性的角度分析数据源，根据分析结果选择满足建库建表要求的方案，并根据表连接需求选择适合的存储方案。最后，通过合理的分区规划，完成数据导入的准备。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;11-数据源分析&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:3;9:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:3;9:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;1.1. 数据源分析&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:3;9:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;/&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;111-存储-csv-文件&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:4;11:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:4;11:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;1.1.1. 存储 CSV 文件&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:4;11:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:3;13:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;列数相同的以单字符分割的格式化 CSV 文件，DolphinDB 都可以导入。如下是常见的几种格式：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:1;15:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:1;15:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;第一行是各列的列名&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:2;16:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;第一行是数据，文件没有列名&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:3;17:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;前几行是文件注释说明，接下来才是列名或数据&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:4;18:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;CSV 文件中缺少日期列或股票代码列，缺失的列以文件名或文件夹名的形式给出&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:4;20:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;CSV 文件需要解压好，放到 DolphinDB 所在服务器上，并确认用户有权限访问对应目录。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:5;22:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;逐笔数据包括逐笔委托和逐笔成交，上市和深市的数据格式不同，每个市场每种数据每天的数据量大约几个 GB。当总数据量超过一周时，推荐使用多任务并行导入，并行度按天区分，每种格式的数据每天一个任务。比如：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:2;24:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:5;24:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;一天一个 CSV 文件&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:6;25:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;同一天的 CSV 文件在同一个文件夹中&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:7;26:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;文件名中包含了日期&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;112-导入-csv-文件&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:5;28:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:5;28:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;1.1.2. 导入 CSV 文件&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:5;28:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:6;30:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;使用 Linux 系统的 head 等命令打开 CSV 文件，确定要导入或添加的列在 DolphinDB 数据库中的字段名称和数据类型。字段名称的确定方式如下：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:3;32:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:8;32:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;如果 CSV 文件有列名，使用函数&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:1;32:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;extractTextSchema&lt;/codeph&gt;提取 CSV 文件的列名和列类型作为字段名称和类型。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:9;33:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;如果 CSV 文件没有列名，根据相关数据对应的说明文档确定字段名称和类型（见下文的字段类型转换）。&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:7;35:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:1;35:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;字段类型转换&lt;/b&gt;&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:8;37:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;DolphinDB 支持的数据类型如下图：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/LoadDataForPoc/dataType.png&#34; xtrc=&#34;image:1;39:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; dita-ot:image-width=&#34;1539&#34; dita-ot:image-height=&#34;1199&#34; dita-ot:horizontal-dpi=&#34;120&#34; dita-ot:vertical-dpi=&#34;120&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:9;41:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;在这些数据类型中，整型、浮点型与其他数据库相同，可直接根据数据精度选择。DolphinDB 比较有特色的是如下两种类型：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:4;43:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:10;43:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;字符串：在 DolphinDB 中可以把字符串保存为 SYMBOL 类型数据。一个 SYMBOL 类型数据在 DolphinDB 系统内部存储为一个整数，数据排序、查询、比较时更有效率。因此，使用 SYMBOL 类型有可能提高系统性能，同时也可节省存储空间。SYMBOL 和 STRING 的使用原则是：&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:2;43:155&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;重复多的有限数量的字符串使用 SYMBOL，重复少的描述性字符串使用 STRING。&lt;/b&gt; 比如，股票代码，交易类型标志等使用 SYMBOL，例如 [&#34;IBM&#34;,&#34;C&#34;,&#34;MS&#34;] 等；备注、自定义信息等使用 STRING。在结构化的 level2 金融数据中，STRING 使用得较少。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:11;44:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;时间日期：如上图所示，DolphinDB 支持丰富的时间日期类型。凡是涉及时间日期的，推荐用户根据不同精度选择对应的 DolphinDB 时间日期类型。&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:10;46:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;下图是通过 head 命令查看的上市委托数据的 CSV 文件。&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/LoadDataForPoc/headEntrust.png&#34; xtrc=&#34;image:2;48:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; dita-ot:image-width=&#34;969&#34; dita-ot:image-height=&#34;419&#34; dita-ot:horizontal-dpi=&#34;120&#34; dita-ot:vertical-dpi=&#34;120&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:11;50:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;从上图可以看出，这个 CSV 文件的第一行是一些说明备注信息，在后续读取的时候需要跳过。这个文件没有列名，从第二行开始是数据，共 10 列。从左至右的字段名根据上市的说明文档定义为：SecurityID, TransactTime, valOrderNoue, Price, Balance, OrderBSFlag, OrdType, OrderIndex, ChannelNo, BizIndex。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:12;52:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;其中 SecurityID, OrderBSFlag 和 OrdType 为重复较多的有限数量的字符串，使用 SYMBOL 类型；TransactTime 为从年到毫秒的日期，使用 TIMESTAMP 数据类型；其它的字段没有特殊之处，整数用 INT，浮点数用 DOUBLE。所以，从左至右存储字段的数据类型定义为：SYMBOL, TIMESTAMP, INT, DOUBLE, INT, SYMBOL, SYMBOL, INT, INT, INT。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:13;54:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;其它格式的 CSV 文件，也按此方式确定好字段名称和数据类型。后续数据库中按这些定义好的类型存储数据。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:14;56:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;按上述分析定义的表结构列数和 CSV 文件完全一致。如果有特殊需要，也可以增加或减少列。只要字段名称和数据类型按顺序一一对应即可。比如计划将上市和深市的数据统一存储，那么分别分析两市的 CSV 文件，确定共同保留的列，确定字段名称和字段类型。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:15;58:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;DolphinDB 导入数据的步骤是先把 CSV 文件读入内存，再写入硬盘。由于不同 CSV 文件对相同字段保存方式不同，CSV 文件在导入内存时不一定能正确识别出数据类型。可能需要对如下字段进行转换：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:5;60:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:12;60:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;股票代码列：对于 002415, 600001 等数字样式，会被识别为 INT 类型，需要转为 SYMBOL 类型。如果不同代码的数字位数不同，转换时，还要按 6 位对齐&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:13;61:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;时间日期列：对于 20220101093000000, 20220101, 93000000 和 epoch 格式等数字样式，会被识别为 LONG 类型，需要转为 DolphinDB 的 TIMESTAMP, DATE, TIME 等精度的日期时间类型&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:14;62:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;一些交易标志列：对于 C, B, S 等字母样式，会识别为 CHAR 类型，需要转为 SYMBOL 类型&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:15;63:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;需要最终存储为 SYMBOL 类型的，只要转为 STRING 类型即可。&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:16;65:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;总而言之，CSV 数据的一些列在导入内存后，可能和期望存储到数据库中的数据类型不一致，需要进行转换。具体的转换方式也比较简单，将在后面实操章节中详细介绍。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;12-规划存储方案&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:6;67:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:6;67:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;1.2. 规划存储方案&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:6;67:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:17;69:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;分析完数据源后，需要规划如何在 DolphinDB 中基于 level2 逐笔数据建库建表。存储方案的设计原则是：&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:3;69:58&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;当没有表连接分析的需求时，推荐单库单表存储数据；当有表连接需求时，一库多表存储数据。&lt;/b&gt;&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:6;71:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:16;71:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;沪深两市的逐笔委托和逐笔成交数据之间一般是有关联分析需求的，所以推荐一库多表。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:17;72:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;上市和深市不需要合并时，建立两数据库，一个保存上市数据，另一个保存深市数据。每个数据库中分别建立两个数据表，一个数据表存储逐笔委托数据，另一个数据表存储逐笔成交数据。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:18;73:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;若沪深两市的数据需要合并统一存储，则规划一个数据库，库内建两个数据表，一个数据表保存两市的逐笔委托，另一个保存两市的逐笔成交。&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:18;75:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:4;75:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;DolphinDB 单表存储的数据量无上限，同一种类型的数据全部存储到一个数据表，不需要考虑分库分表。&lt;/b&gt;&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;13-规划分区&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:7;77:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:7;77:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;1.3. 规划分区&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:7;77:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:19;79:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:5;79:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;规划分区是建立数据库之前最重要的一环&lt;/b&gt;，有以下几点作用：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:7;81:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:19;81:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;分区使大型表更易于管理，提高查询速度&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:20;82:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;分区使系统可以充分利用资源，提高计算速度&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:21;83:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;增加了系统的可用性&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:20;85:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;分区原理及详细教程参见：&lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;database.md&#34; xtrc=&#34;xref:1;85:13&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;分区数据库设计和操作&lt;/xref&gt;。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:21;87:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;对于 level2 逐笔数据的场景，推荐复合分区，先按日期做值分区，再按股票代码做 HASH 分区。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:22;89:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;分区数量由数据大小决定，TSDB 引擎每个分区数据量为压缩前 400MB-1GB，OLAP 引擎每个分区数据量为压缩前 100MB-300MB。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:23;91:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;分区是在数据库层面进行的，同一个数据库中的不同数据表，分区方式相同。当需要关联的两表存储到同一个数据库中时，以数据量大的表为基准，按上述原则进行分区。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;2-导入步骤&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:8;93:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:8;93:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2. 导入步骤&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:8;93:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:24;95:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;完成分析和规划后，用户可按照本章步骤导入数据。先用单个文件进行调试，调试成功后，再使用多任务并行方式，对全量数据进行快速导入。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;21-建库建表&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:9;97:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:9;97:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.1. 建库建表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:9;97:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:25;99:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;本教程以上海证券交易所的逐笔委托数据为例来建库建表，点击 &lt;xref class=&#34;- topic/xref &#34; format=&#34;zip&#34; href=&#34;https://www.dolphindb.cn/downloads/docs/LoadDataForPoc.zip&#34; scope=&#34;external&#34; xtrc=&#34;xref:2;99:30&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;Entrust&lt;/xref&gt; 下载用例数据。文件解压后放到 loadForPoc/SH/Order/20210104 目录下。在 DolphinDB 中，可以使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:2;99:166&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;create&lt;/codeph&gt;语句建库建表。DolphinDB 建库时有 OLAP 和 TSDB 两种存储引擎可以选择。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:26;101:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;本教程推荐选用 TSDB 引擎。上市每天逐笔委托数据大小在 3GB 左右，根据前面的分区规划，先按日期做值分区，再用股票代码做 7 个 HASH 分区。按日期值分区时，&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:6;101:85&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;VALUE 的初始值写两三天的初始值即可，实际分区值会根据数据的实际日期自动扩展&lt;/b&gt;。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:27;103:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;完整的建库代码如下：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:1;105:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;if (existsDatabase(&#34;dfs://sh_entrust&#34;)) { dropDatabase(&#34;dfs://sh_entrust&#34;) } create database &#34;dfs://sh_entrust&#34; partitioned by VALUE(2022.01.01..2022.01.03), HASH([SYMBOL, 10]), engine='TSDB'&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:28;114:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;建库完成后，开始建表。建表的关键是指定字段名称及类型，先用 head 命令在 Linux 系统下查看一下 CSV 文件的结构，如下图所示：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/LoadDataForPoc/csvType.jpg&#34; xtrc=&#34;image:3;116:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; dita-ot:image-width=&#34;1000&#34; dita-ot:image-height=&#34;422&#34; dita-ot:horizontal-dpi=&#34;120&#34; dita-ot:vertical-dpi=&#34;120&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:29;118:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;可以看到，这个 CSV 文件有如下特点：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:8;120:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:22;120:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;第一行是文件说明，后续各种读取都需要跳过这一行&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:23;121:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;从第二行开始是数据，没有列名，在建表时需要根据数据的说明文档定义字段名称和字段类型&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:30;123:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;建表时，OLAP 引擎和 TSDB 引擎都需要指定分区字段，例如：partitioned by TransactTime,SecurityID。TSDB 引擎还有一个分区内排序字段的参数要指定，例如：sortColumns = [`SecurityID,`TransactTime]。注意字段顺序不能调换。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:31;125:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;完整建表语句如下：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:2;127:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;create table &#34;dfs://sh_entrust&#34;.&#34;entrust&#34;( SecurityID SYMBOL, TransactTime TIMESTAMP, valOrderNoue INT, Price DOUBLE, Balance INT, OrderBSFlag SYMBOL, OrdType SYMBOL, OrderIndex INT, ChannelNo INT, BizIndex INT) partitioned by TransactTime,SecurityID, sortColumns = [`SecurityID,`TransactTime]&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:32;143:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;确认数据表列数时，应当根据用户需求来指定。当 CSV 文件缺少或多余某些列时，用户可使用脚本在 CSV 文件基础上增加或减少列。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:33;145:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;在列数和 CSV 文件不一样时，确认 HASH 分区的数量，需要先将各列数据类型占用的字节数据求和，得到一行数据的大小，然后乘以数据行数，得到一天的数据大小。最后，使用一天的数据大小除以每个分区的大小，得到 HASH 分区的数量。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:34;147:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;通常逐笔数据是不需要去重的。如果由于特定的数据源等原因，有去重的需求，可在建表时指定 keepDuplicates 参数的值，包含以下选项：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:9;149:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:24;149:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;ALL: 保留所有数据&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:25;150:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;LAST：仅保留最新数据&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:26;151:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;FIRST：仅保留第一条数据&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;22-编写导入脚本&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:10;153:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:10;153:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.2. 编写导入脚本&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:10;153:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;/&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;221-导入单个文件&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:11;155:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:11;155:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.2.1. 导入单个文件&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:11;155:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:35;157:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;DolphinDB 导入数据的核心函数是&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:3;157:21&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;loadTextEx&lt;/codeph&gt;，可用于 CSV 文件读取、数据清洗和入库一体化操作。导入数据核心代码如下：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:3;159:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;db = database(&#34;dfs://sh_entrust&#34;) def transType(mutable memTable) { return memTable.replaceColumn!(`col0,string(memTable.col0)).replaceColumn!(`col1,datetimeParse(string(memTable.col1),&#34;yyyyMMddHHmmssSSS&#34;)).replaceColumn!(`col5,string(memTable.col5)).replaceColumn!(`col6,string(memTable.col6)) } filePath = &#34;/home/ychan/data/loadForPoc/SH/Order/20210104/Entrust.csv&#34; loadTextEx(dbHandle = db, tableName = `entrust, partitionColumns = `col1`col0, filename = filePath, skipRows = 1,transform = transType)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:36;169:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;导入完成后，查询部分数据，代码如下：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:4;171:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;select top 10 * from loadTable(&#34;dfs://sh_entrust&#34;,`entrust)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:37;175:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;如果数据导入成功，查询结果如下图所示&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/LoadDataForPoc/selectResult.jpg&#34; xtrc=&#34;image:4;177:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; dita-ot:image-width=&#34;953&#34; dita-ot:image-height=&#34;441&#34; dita-ot:horizontal-dpi=&#34;120&#34; dita-ot:vertical-dpi=&#34;120&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:38;179:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;在单个文件导入过程中可能出现的问题及解决方案如下：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:10;181:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:27;181:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:39;181:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;数据类型不匹配，常见的报错信息如：“某列需要 SYMBOL 类型，实际数据类型是 INT”，此类报错提示用户进行数据类型转换。 详细的解决方式见 &lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;markdown&#34; format=&#34;dita&#34; href=&#34;#清洗转换数据&#34; xtrc=&#34;xref:3;182:10&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;清洗转换数据&lt;/xref&gt;。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:28;184:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:40;184:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;如果系统中存在 nfs 存储介质，可能报 Bad file descriptor 的错误。这种情况要按照指定方式重新挂载一下 nfs 文件。nfs 文件需要用 v3 版本，并设置 local_lock 参数为 all。具体的挂载命令为：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:5;186:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;mount -t nfs -o v3,local_lock=all [IP]:/hdd/hdd0/nfs /hdd/hdd0/DolphinDB-test/&lt;/codeblock&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:29;190:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:41;190:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;执行没有任何报错，但是任务长时间执行不完，等待时间已经远超文件大小除以硬盘速度的时间，观测硬盘状态，也没有任何写入。这种情况是因为单个 CSV 文件太大了，缓存不够用，这个缓存是专门为数据入库设置的一块内存，有关缓存机制的详细介绍见：&lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;redoLog_cacheEngine.md&#34; xtrc=&#34;xref:4;190:120&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;CacheEngine 与数据库日志教程&lt;/xref&gt; 与 &lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;tsdb_explained.md&#34; xtrc=&#34;xref:5;190:169&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;DolphinDB TSDB 存储引擎介绍&lt;/xref&gt;。解决方法是：先把 OLAPCacheEngineSize 和 TSDBCacheEngineSize 两个参数的值修改为大于 CSV 文件的大小，再重启系统。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:42;192:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;单文件完整的导入脚本下载链接为：&lt;xref class=&#34;- topic/xref &#34; format=&#34;dos&#34; href=&#34;script/LoadDataForPoc/loadOneFile.dos&#34; xtrc=&#34;xref:6;192:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;单文件导入&lt;/xref&gt;&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;222-清洗转换数据&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:12;194:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:12;194:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.2.2. 清洗转换数据&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:12;194:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:43;196:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;上一节的核心导入代码中，使用了&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:4;196:16&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;loadTextEx&lt;/codeph&gt;函数，其中 transform 参数引用了 transType 函数定义，其作用是数据清洗和类型转换。&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:5;196:79&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;loadTextEx&lt;/codeph&gt;导入机制如下：&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:44;198:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;首先，把 CSV 文件加载到内存生成一个内存表，这个内存表的数据类型可能和之前建立的分布式数据表定义的类型不一致。可以通过指定 schema 的方式尝试进行自动转换，详见：&lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;import_csv.md&#34; xtrc=&#34;xref:7;198:87&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;指定数据导入格式&lt;/xref&gt;。无法进行自动转换的类型会提示失败。此时，我们需要使用 transform 参数引用的函数进行类型转换和数据清洗。从该函数的返回值中获得清洗转换后的数据，类型依然是一个内存表。然后，把处理好的内存表数据写到硬盘上对应数据库中的数据表内。如果 transform 参数已赋值，&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:7;198:249&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;分布式表的结构和 transform 参数引用的函数返回的表的结构保持一致，不用和原 CSV 文件的结构保持一致。&lt;/b&gt;&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:45;200:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;transform 能够非常方便地完成但不限于如下需求：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:11;202:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:30;202:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;数据类型的转换&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:31;203:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;在 CSV 文件的基础上增加列&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:32;204:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;过滤 CSV 文件中的无效数据&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:33;205:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;字符编码转换，通常用于把 GBK 编码转换为 UTF-8 编码&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:34;206:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;把多档数据合成 array vector&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;223-转换数据类型&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:13;208:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:13;208:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.2.3. 转换数据类型&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:13;208:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:46;210:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;DolphinDB 提供了读取 CSV 文件 schema 的函数&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:6;210:34&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;extractTextSchema&lt;/codeph&gt;。使用以下代码提取 CSV 文件的 schema：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:6;212:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;filePath = &#34;/home/ychan/data/loadForPoc/SH/Order/20210104/Entrust.csv&#34; extractTextSchema(filename = filePath, skipRows = 1)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:47;217:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;执行完成后，结果如下图&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/LoadDataForPoc/schemaResult.jpg&#34; xtrc=&#34;image:5;219:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; dita-ot:image-width=&#34;151&#34; dita-ot:image-height=&#34;287&#34; dita-ot:horizontal-dpi=&#34;120&#34; dita-ot:vertical-dpi=&#34;120&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:48;221:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;返回结果中，第一列 name 表示 CSV 文件中各列的列名。如果 CSV 文件数据之前没有列名信息，列名自动命名为 col0, col1 等；如果有列名信息，列名和文件中的名称保持一致。第二列 type 表示 CSV 文件中自动识别出来的各列的数据类型。这个结果表的字段和我们建表时的字段是按从上到下的顺序一一对应的，我们把二者整理到一起，如下图所示：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/LoadDataForPoc/vsType.jpg&#34; xtrc=&#34;image:6;223:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; dita-ot:image-width=&#34;408&#34; dita-ot:image-height=&#34;321&#34; dita-ot:horizontal-dpi=&#34;120&#34; dita-ot:vertical-dpi=&#34;120&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:49;225:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;通过对比可以发现，内存表中的字段 col0, col1, col5, col6 与数据表中对应字段 SecurityID, TransactTime, OrderBSFlag, OrdType 的类型不同。如果此时直接进行数据导入，如下代码所示：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:7;227:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;db = database(&#34;dfs://sh_entrust&#34;) filePath = &#34;/home/ychan/data/loadForPoc/SH/Order/20210104/Entrust.csv&#34; loadTextEx(dbHandle = db, tableName = `entrust, partitionColumns = `col1`col0, filename = filePath, skipRows = 1)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:50;233:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;执行后发现报错：&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:8;233:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;The column [SecurityID] expects type of SYMBOL, but the actual type is INT&lt;/b&gt;，即传入的 SecurityID 数据类型为整型，不符合 SYMBOL 的要求。而 transType 函数的作用就是自定义转换数据类型，赋给 transform 参数后再执行导入语句，会发现不再报错。其他字段的数据导入和类型转换依此类推。本案例中，共有四列做了转换，相关代码如下：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:8;235:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;def transType(mutable memTable) { return memTable.replaceColumn!(`col0,string(memTable.col0)).replaceColumn!(`col1,datetimeParse(string(memTable.col1),&#34;yyyyMMddHHmmssSSS&#34;)).replaceColumn!(`col5,string(memTable.col5)).replaceColumn!(`col6,string(memTable.col6)) }&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:51;242:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;可以看到，每修改一列就增加一个&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:7;242:16&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;replaceColumn!&lt;/codeph&gt;函数。这个函数的作用是使用一个向量替换 table 中指定列，替换后，指定列的数据类型与向量的数据类型一致。在这个案例中，它的第一个参数是数据表的列名，第二个参数是使用相关函数对内存表的指定列处理之后的数据。所以，数据类型的转换的关键在于&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:8;242:151&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;replaceColumn!&lt;/codeph&gt;函数第二个参数的写法。在金融数据的导入实践中，主要有以下几类：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:12;244:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:35;244:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:52;244:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;时间日期为 epoch 格式，也就是指定时间减去 1970-01-01 00:00:00 的差值。这个差值可以到秒、毫秒等，它是一串纯数字，会自动识别成整数。在转换时，直接把这个整数传递给 DolphinDB 对应时间日期类型的函数即可，如需精确到秒，使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:9;244:131&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;datetime&lt;/codeph&gt;，精确到毫秒使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:10;244:149&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;timestamp&lt;/codeph&gt;，精确到纳秒使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:11;244:168&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;namotimestamp&lt;/codeph&gt;。逐笔数据一般精确到毫秒，类型转换函数的写法为：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:9;246:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;def transType(mutable memTable) { return memTable.replaceColumn!(`epochTimeCol,timestamp(memTable.epochTimeCol)) }&lt;/codeblock&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:36;253:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:53;253:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;时间是日期格式，是纯数字组成的年月日时分秒等，中间没有分割符。比如 20220101，20220101093000 等，这些格式会被识别为整数。转换时，先把这些数字使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:12;253:87&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;string&lt;/codeph&gt;函数转成字符串，再用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:13;253:105&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;temporalParse&lt;/codeph&gt;格式化成对应的日期格式。逐笔数据一般精确到毫秒，这种类型转换函数的写法为：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:10;255:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;def transType(mutable memTable) { return memTable.replaceColumn!(`ymdTimeCol,datetimeParse(string(memTable.ymdTimeCol),&#34;yyyyMMddHHmmssSSS&#34;)) }&lt;/codeblock&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:37;262:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:54;262:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;股票代码是纯数字，会识别成整数。股票代码推荐定义为 SYMBOL 类型，在内存表中，只要使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:14;262:49&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;string&lt;/codeph&gt;函数把其转化为字符串格式，在导入时，就能够自动存储为 SYMBOL 类型。此外，股票代码一般是 6 位，以零开头的需要用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:15;262:117&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;lpad&lt;/codeph&gt;函数要进行补齐。纯数字股票代码列转换的函数写法为&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:11;264:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;def transType(mutable memTable) { return memTable.replaceColumn!(`securityId,lpad(string(memTable.securityId),6,`0)) }&lt;/codeblock&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;224-文件名给出某列信息在-csv-文件的基础上增加此列&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:14;271:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:14;271:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.2.4. 文件名给出某列信息，在 CSV 文件的基础上增加此列&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:14;271:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:55;273:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;有些时候，CSV 文件会缺少某些列，比如确少日期，然后，通过文件名给出了日期信息。其中所有数据的日期都和文件名相同。这种情况我们通过 transform 参数引用的函数，增加列并赋值。代码如下：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:12;275:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;def addCol(mutable memTable,datePara) {     update memTable set date = datePara     return memTable }&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:56;283:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;新增的列总是在最后，如果和分布式表的顺序不一致，在这个函数返回之前，先用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:16;283:37&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;reorderColumns!&lt;/codeph&gt;函数调整成一致。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;225-过滤数据&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:15;285:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:15;285:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.2.5. 过滤数据&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:15;285:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:57;287:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;有些情况下，需要把 CSV 文件中的一些无效数据过滤掉再写入分布式表。在 transform 参数引用的函数中使用 select 筛选出符合条件的数据即可，比如我们只写入价格大于 0 的数据，函数定义的代码为：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:13;289:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;def fliterData(mutable memTable) {     return select * from memTable where price &amp;gt; 0 }&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;226-转换字符编码转换&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:16;296:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:16;296:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.2.6. 转换字符编码转换&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:16;296:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:58;298:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;为了显示正常，有时候需要把 GBK 编码的列转成 UTF-8。transform 参数引用的函数的代码为：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:14;300:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;def addCol(mutable memTable) {     return mutable.replaceColumn!(`custname,toUTF8(mutable.custname,`gbk)) }&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;227-导入部分列&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:17;307:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:17;307:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.2.7. 导入部分列&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:17;307:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:59;309:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;导入部分列有两种方法，一是在 transform 参数引用的函数中筛选出需要的列，代码如下：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:15;311:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;def partCol(mutable memTable) {     return select [需要的部分列名] from memTable }&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:60;318:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;方法二是通过指定 schema 的方式，详见如下链接的教程 2.4 节：&lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;import_csv.md&#34; xtrc=&#34;xref:8;318:37&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;导入指定列&lt;/xref&gt;&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;228-并行导入&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:18;320:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:18;320:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.2.8. 并行导入&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:18;320:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:61;322:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;并行导入能够快速导入数据，这种导入方法会占用比较多的内存，所以在导入前，要配置合理的并行度。workerNum 可以控制并行度，估算方式为，&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:9;322:71&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;可用内存除以一天的文件大小，得到 workerNum 的值。&lt;/b&gt; 可用内存的值是由 maxMemSize 参数确定的，一般配置为机器可用内存的 80%。此外，也要确保，maxMemSize 的值不大于 license 文件限制的内存大小。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:62;324:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;并行导入时，多个任务不能同时写入一个分区，在做任务分配时，要确保不同任务写入不同的分区。因为一级分区为天，不同日期的数据会写到不同的分区。所以，推荐以每天数据与任务一一对应的方式来并行导入。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:63;326:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;本案例批量导入了 2021 年 01 月 05 日到 01 月 15 日期间，9 个工作日的逐笔委托数据。为了方便下载，每天的数据限定为 180MB 左右，点击此处下载数据：&lt;xref class=&#34;- topic/xref &#34; format=&#34;zip&#34; href=&#34;https://www.dolphindb.cn/downloads/docs/LoadDataForPoc.zip&#34; scope=&#34;external&#34; xtrc=&#34;xref:9;326:88&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;批量导入数据&lt;/xref&gt;。由于之前单个文件导入的 CSV 文件比较大，在进行并行导入前，推荐先把单个导入的文件删除。批量导入的基本步骤如下：&lt;/p&gt;&lt;ol class=&#34;- topic/ol &#34; xtrc=&#34;ol:1;328:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:38;328:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;在单个 CSV 文件导入的基础上，把一天的数据导入封装为一个函数&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:39;329:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;用异步任务的方式提交一批任务，按天进行批量导入。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:40;330:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;如果两市的数据合并成一张表，则需要分别并行导入，不同市场的数据同时并行导入意味着不同任务同时写入一个分区，会报错。&lt;/li&gt;&lt;/ol&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:64;332:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;异步任务的详细用法见：&lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;job_management_tutorial.md&#34; xtrc=&#34;xref:10;332:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;DolphinDB 教程：作业管理&lt;/xref&gt;。代码如下：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:16;334:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;def loadOneDayFile(db,table,filePath) { csvFiles = exec filename from files(filePath) where filename like&#34;%.csv&#34; for(csvIdx in csvFiles) { loadTextEx(dbHandle = db, tableName = table, partitionColumns = `col1`col0, filename = filePath + &#34;/&#34; + csvIdx, transform = transType, skipRows = 1) } } def parallelLoad(allFileContents) { db = database(&#34;dfs://sh_entrust&#34;) table = `entrust dateFiles = exec filename from files(allFileContents) where isDir = true for(dateIdx in dateFiles) { submitJob(&#34;parallelLoad&#34; + dateIdx,&#34;parallelLoad&#34;,loadOneDayFile{db,table,},allFileContents + &#34;/&#34; + dateIdx) } } allFileContents = &#34;/home/ychan/data/loadForPoc/SH/Order&#34; parallelLoad(allFileContents)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:65;359:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;以上代码定义了以下两个函数：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:13;361:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:41;361:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:66;361:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;loadOneDayFile，导入一天某种类型的数据。由于一天数据可能有多个 CSV 文件，因此需要在该函数内遍历目录下所有 CSV 文件后逐个导入。该函数使用 3 个入参：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:14;363:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:42;363:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;db，数据库句柄。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:43;364:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;table，表名。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:44;365:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;filePath，目录参数，截止到日期一级。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:45;367:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:67;367:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;parallelLoad，包含唯一参数 allFileContents，参数值为目录，最小级别为快照、逐笔委托、逐笔成交等。parallelLoad 函数遍历指定目录下的所有日期作为任务参数，调用 loadOneDayFile 按日期提交任务。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:68;369:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;loadOneDayFile 和 parallelLoad 这两个函数的写法不唯一，可以根据数据的存储格式参考本案例代码灵活设计。主要目的是按天提交任务，每个任务导入某种数据一天的数据。这些代码执行完成后，会马上返回，所提交的异步任务会在后台执行，可以调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:17;369:129&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;getRecentJobs&lt;/codeph&gt;函数查看后台的任务执行情况。任务情况如下图所示：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/LoadDataForPoc/getRecentJobs.jpg&#34; xtrc=&#34;image:7;371:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; dita-ot:image-width=&#34;1430&#34; dita-ot:image-height=&#34;395&#34; dita-ot:horizontal-dpi=&#34;120&#34; dita-ot:vertical-dpi=&#34;120&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:69;373:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;上图重 startTime 字段不为空，表示该任务已经在执行；endTime 不为空，表示该任务已经执行完成；errorMsg 字段不为空，说明这个任务执行出错了，根据这个错误信息对代码进行调试。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:70;375:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;errorMsg 可能的错误信息及解决方式如下：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:15;377:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:46;377:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;报错信息类似于：Retrieve directory content [/home/ychan/data/loadForPoc/SH/Order20210108]: No such file or directory。导入时文件找不到，一般是路径拼接的时候出错，尤其是反斜杠字符“/”容易多写或漏写，需要仔细检查查&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:47;378:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;报错信息为 Out of memory，根本原因是内存不够用了。需要增加可用内存或降低并发度&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:48;379:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;报错信息类似于：&amp;lt;ChunkInTransaction&amp;gt;filepath '/tickHot/20221125/Key0/5ncmg' has been owned by transaction 9702796 RefId:S00002。原因是分区冲突，不同任务往同一个分区写数据了，需要检查不同日期的数据是不是放乱了，任务分割是否合理&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:71;381:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;完整的批量导入脚本链接为：&lt;xref class=&#34;- topic/xref &#34; format=&#34;dos&#34; href=&#34;script/LoadDataForPoc/parallelLoad.dos&#34; xtrc=&#34;xref:11;381:14&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;批量导入&lt;/xref&gt;&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;229-监测导入状态&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:19;383:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:19;383:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;2.2.9. 监测导入状态&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:19;383:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:72;385:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;在数据导入的过程中，如果对导入的性能存在疑虑，可以通过一些工具观测系统资源使用情况，判断是否存在资源利用的瓶颈。在 Linux 系统的终端中输入 dstat 命令，可以查看硬盘写入情况。如下图所示：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/LoadDataForPoc/hardWrite.jpg&#34; xtrc=&#34;image:8;387:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; dita-ot:image-width=&#34;1376&#34; dita-ot:image-height=&#34;531&#34; dita-ot:horizontal-dpi=&#34;120&#34; dita-ot:vertical-dpi=&#34;120&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:73;389:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;并行导入追求高速的写入性能，通过配置多块磁盘，可发挥硬盘并行 IO 的能力。通过单机配置文件 dolphindb.cfg 或集群配置文件 cluster.cfg 中的 volumes 参数进行磁盘配置。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:74;391:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;并行导入时，通过观察硬盘的写入速度、内存消耗情况、CPU 利用率、集群间网络速率，查看资源使用情况。如果内存、CPU 和集群间网络都还有盈余，硬盘的 IO 还没有饱和，可以把 workerNum 配置修改的大一些，提升并行度。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:75;393:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;总而言之，通过对并行任务的合理调度，充分利用某一类硬件的物理性能，达到硬件可以支持的最大导入速度。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;3-附件&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:20;395:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:20;395:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;3. 附件&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:20;395:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:76;397:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;本章再以问答的形式，对导入时可能遇到的问题进行总结。&lt;/p&gt;&lt;ol class=&#34;- topic/ol &#34; xtrc=&#34;ol:2;399:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:49;399:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:77;399:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;只提交了一个文件的导入，长时间执行不完，硬盘也没有写入，这是什么原因？&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:78;401:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;答：这是因为单个 CSV 文件太大了，缓存不够用。这个缓存是专门为数据入库设置的一块内存， 详细的介绍见：&lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;redoLog_cacheEngine.md&#34; xtrc=&#34;xref:12;402:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;CacheEngine 与数据库日志教程&lt;/xref&gt; 与 &lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;tsdb_explained.md&#34; xtrc=&#34;xref:13;402:61&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;DolphinDB TSDB 存储引擎介绍&lt;/xref&gt;。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:79;404:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;解决方法是：先把 OLAPCacheEngineSize 和 TSDBCacheEngineSize 两个参数的值修改为大于 CSV 文件的大小，再重启系统。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:50;406:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:80;406:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;导入时，时间是年月日时分秒结构的纯数字类型，如何转化为 DolphinDB 的时间日期格式？&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:81;408:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;答：解决方法见本篇文章 &lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;markdown&#34; format=&#34;dita&#34; href=&#34;#清洗转换数据&#34; xtrc=&#34;xref:14;408:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;清洗转换数据&lt;/xref&gt; 的时间类型转换部分。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:51;410:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:82;410:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;导入时，时间是 epoch 格式，也就是指定时间减去 1970-01-01 00:00:00 的差值，如何转化为 DolphinDB 的时间日期格式？&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:83;412:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;答：解决方法见本篇文章 &lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;markdown&#34; format=&#34;dita&#34; href=&#34;#清洗转换数据&#34; xtrc=&#34;xref:15;412:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;清洗转换数据&lt;/xref&gt; 的时间类型转换部分。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:52;414:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:84;414:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;导入时，股票代码列是纯数字，如何转成 SYMBOL 类型。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:85;416:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;答：解决方法见本篇文章 &lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;markdown&#34; format=&#34;dita&#34; href=&#34;#清洗转换数据&#34; xtrc=&#34;xref:16;416:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;清洗转换数据&lt;/xref&gt; 的股票代码类型转换部分。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:53;418:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:86;418:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;执行过程中，报 out of memory 错误，怎么处理？&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:87;420:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;答：这是因为导入过程中内存不够用了。如果使用的是社区版本 license，请联系负责支持的销售人员，获取试用版本 license。然后，查看 maxMemSize 参数的配置是否远小于系统内存，建议配置为系统内存的 80%。最后，检查 workerNum 配置，合理配置值的计算方法为：可用内存除以单个文件大小向下取整得到 workerNum 的值。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:54;422:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:88;422:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;nsf 系统导入时，报 Bad file descriptor 错误，怎么解决？&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:89;424:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;答：如果我们存储系统中存在 nfs 文件，那么 nfs 文件需要用 v3 版本，并设置 local_lock 参数为 all 的方式进行挂载。具体的挂载命令为：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:17;426:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;mount -t nfs -o v3,local_lock=all [IP]:/hdd/hdd0/nfs /hdd/hdd0/DolphinDB-test/&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:90;430:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;如果不是这种挂载方式，需要先卸载，再使用这种方式重新挂载。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:55;432:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:91;432:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;如何在 DolphinDB 中 LoadTextEx 导入数据时，过滤无效数据？&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:92;434:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;答：过滤方法是在 transform 引用的函数中做清洗。解决方法详见 &lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;markdown&#34; format=&#34;dita&#34; href=&#34;#清洗转换数据&#34; xtrc=&#34;xref:17;434:41&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;清洗转换数据&lt;/xref&gt; 的过滤无效数据部分。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:56;436:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:93;436:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;向 DolphinDB 数据库导入 CSV 数据时还要再加上 2 列怎么办？&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:94;438:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;答：增加方法是在 transform 引用的函数中做增加。解决方法详见 &lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;markdown&#34; format=&#34;dita&#34; href=&#34;#清洗转换数据&#34; xtrc=&#34;xref:18;438:41&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;清洗转换数据&lt;/xref&gt; 的 增加列部分。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:57;440:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:95;440:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;符合如何导入部分列？&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:96;442:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;答：方法详见&lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;markdown&#34; format=&#34;dita&#34; href=&#34;#清洗转换数据&#34; xtrc=&#34;xref:19;442:11&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;?ditaot usertext?&gt;清洗转换数据&lt;/xref&gt; 导入部分列。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:58;444:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:97;444:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;数据如何去重复？&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:98;446:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;答：建表时指定 keepDuplicates 参数的值可以去重，包含以下选项：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:16;448:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:59;448:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;ALL: 保留所有数据&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:60;449:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;LAST：仅保留最新数据&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:61;450:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/LoadDataForPoc.md&#34;&gt;FIRST：仅保留第一条数据&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;"/><meta name="wh-source-relpath" content="tutorials/LoadDataForPoc.md"/><meta name="wh-out-relpath" content="tutorials/LoadDataForPoc.html"/>

    <link rel="stylesheet" type="text/css" href="../oxygen-webhelp/app/commons.css?buildId=2024012323"/>
    <link rel="stylesheet" type="text/css" href="../oxygen-webhelp/app/topic.css?buildId=2024012323"/>

    <script src="../oxygen-webhelp/app/options/properties.js?buildId=20250305183303"></script>
    <script src="../oxygen-webhelp/app/localization/strings.js?buildId=2024012323"></script>
    <script src="../oxygen-webhelp/app/search/index/keywords.js?buildId=20250305183303"></script>
    <script defer="defer" src="../oxygen-webhelp/app/commons.js?buildId=2024012323"></script>
    <script defer="defer" src="../oxygen-webhelp/app/topic.js?buildId=2024012323"></script>
<link rel="stylesheet" type="text/css" href="../oxygen-webhelp/template/styles.css?buildId=2024012323"/><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script></head>

    <body id="金融-poc-用户历史数据导入指导手册之股票-level-2-逐笔篇" class="wh_topic_page frmBody">
        <a href="#wh_topic_body" class="sr-only sr-only-focusable">
            跳转到主要内容
        </a>
        
        
        
        
        <header class="navbar navbar-default wh_header">
    <div class="container-fluid">
        <div xmlns:whc="http://www.oxygenxml.com/webhelp/components" class="wh_header_flex_container navbar-nav navbar-expand-md navbar-dark">
            <div class="wh_logo_and_publication_title_container">
                <div class="wh_logo_and_publication_title">
                    
                    <a href="https://docs.dolphindb.cn/zh/index.html" class=" wh_logo d-none d-sm-block "><img src="../logo.png" alt="  DolphinDB 文档中心  "/></a>
                    <div class=" wh_publication_title "><a href="../index.html"><span class="booktitle">  <span class="ph mainbooktitle">DolphinDB 文档中心</span>  </span></a></div>
                    
                </div>
                
                
            </div>

            <div class="wh_top_menu_and_indexterms_link collapse navbar-collapse" id="wh_top_menu_and_indexterms_link">
                
                
                
                
            </div>
        <div class=" wh_search_input navbar-form wh_topic_page_search search " role="form">
            
            
            
            <form id="searchForm" method="get" role="search" action="../search.html"><div><input type="search" placeholder="搜索 " class="wh_search_textfield" id="textToSearch" name="searchQuery" aria-label="搜索查询" required="required"/><button type="submit" class="wh_search_button" aria-label="搜索"><span class="search_input_text">搜索</span></button></div></form>
            
            <script src="/vendors/react/umd/react.production.min.js" defer="defer"></script>
<script src="/vendors/react-dom/umd/react-dom.production.min.js" defer="defer"></script>
<script src="/vendors/dayjs/dayjs.min.js" defer="defer"></script>
<script src="/vendors/antd/dist/antd.min.js" defer="defer"></script>
<script src="/vendors/@ant-design/icons/dist/index.umd.min.js" defer="defer"></script>
<script src="/zh/index.js" type="module"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" defer="defer"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer="defer"><!--


--></script>
<script defer="defer"><!--

// 从主页重定向
const currentUrl = window.location.href;

// 判断当前URL是否包含index.html并且路径最后部分是index.html
if (currentUrl.endsWith('index.html')) {
    // 处理根目录下的index.html跳转
    const baseUrl = currentUrl.split('/index.html')[0]; // 获取index.html之前的部分
    const redirectUrl = `${baseUrl}/about/ddb_intro.html`; // 构建跳转路径
    window.location.href = redirectUrl; // 执行跳转
}

--></script>
            
        </div></div>
    </div>
</header>
        
        
         
        
        
        
        <div class="container-fluid" id="wh_topic_container">
            <div class="row">

                <nav class="wh_tools d-print-none navbar-expand-md" aria-label="Tools">
                    
                    <div data-tooltip-position="bottom" class=" wh_breadcrumb "><ol class="d-print-none"><li><span class="home"><a href="../index.html"><span>主页</span></a></span></li><li><div class="topicref" data-id="about_tutorials"><div class="title"><a href="../tutorials/about_tutorials.html"><span class="keyword label">教程</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 产品使用教程</p></div></div></div></li><li><div class="topicref"><div class="title"><a href="../tutorials/OHLC_2.html">金融场景案例</a></div></div></li><li class="active"><div class="topicref" data-id="金融-poc-用户历史数据导入指导手册之股票-level-2-逐笔篇"><div class="title"><a href="../tutorials/LoadDataForPoc.html">金融 PoC 用户历史数据导入指导手册之股票 Level-2 逐笔篇</a></div></div></li></ol></div>
                    
                    
                    
                    <div class="wh_right_tools">
                        <button class="wh_hide_highlight" aria-label="切换搜索突出显示" title="切换搜索突出显示"></button>
                        <button class="webhelp_expand_collapse_sections" data-next-state="collapsed" aria-label="折叠截面" title="折叠截面"></button>
                        
                        
                        
                        
                        <div class=" wh_print_link print d-none d-md-inline-block "><button onClick="window.print()" title="打印此页" aria-label="打印此页"></button></div>
                        
                        <button type="button" id="wh_toc_button" class="custom-toggler navbar-toggler collapsed wh_toggle_button navbar-light" aria-expanded="false" aria-label="Toggle publishing table of content" aria-controls="wh_publication_toc">
                            <span class="navbar-toggler-icon"></span>
                        </button>
                    </div>
                    
                </nav>
            </div>
            
            
            
            
            <div class="wh_content_area">
                <div class="row">
                    
                        <nav id="wh_publication_toc" class="col-lg-3 col-md-3 col-sm-12 d-md-block d-none d-print-none" aria-label="Table of Contents Container">
                            <div id="wh_publication_toc_content">
		                        
                            	<div class=" wh_publication_toc " data-tooltip-position="right"><span class="expand-button-action-labels"><span id="button-expand-action" role="button" aria-label="Expand"></span><span id="button-collapse-action" role="button" aria-label="Collapse"></span><span id="button-pending-action" role="button" aria-label="Pending"></span></span><ul role="tree" aria-label="Table of Contents"><li role="treeitem"><div data-tocid="ddb_intro-d9713e87" class="topicref" data-id="ddb_intro" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../about/ddb_intro.html" id="ddb_intro-d9713e87-link">关于DolphinDB</a></div></div></li><li role="treeitem"><div data-tocid="chap1_getstarted-d9713e136" class="topicref" data-id="chap1_getstarted" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../getstarted/chap1_getstarted.html" id="chap1_getstarted-d9713e136-link">快速上手</a><div class="wh-tooltip"><p class="shortdesc">如何快速部署 DolphinDB、建库建表、写入和查询数据</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="sectionddb_deployment-d9713e189" class="topicref" data-id="sectionddb_deployment" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action sectionddb_deployment-d9713e189-link" class="wh-expand-btn"></span><div class="title"><a href="../deploy/deploy_intro.html" id="sectionddb_deployment-d9713e189-link"><span class="keyword label">部署</span></a><div class="wh-tooltip"><p class="shortdesc">如何在不同的场景中部署 DolphinDB</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="new_chap_database_manage_new_chap_dbmanage_landing_page-d9713e2259" class="topicref" data-id="new_chap_database_manage_new_chap_dbmanage_landing_page" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action new_chap_database_manage_new_chap_dbmanage_landing_page-d9713e2259-link" class="wh-expand-btn"></span><div class="title"><a href="../db_distr_comp/cfg/db_intro.html" id="new_chap_database_manage_new_chap_dbmanage_landing_page-d9713e2259-link"><span class="keyword label">数据库</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 数据库的基本概念</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="chap7_tutorials_streaming-d9713e3760" class="topicref" data-id="chap7_tutorials_streaming" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action chap7_tutorials_streaming-d9713e3760-link" class="wh-expand-btn"></span><div class="title"><a href="../stream/str_intro.html" id="chap7_tutorials_streaming-d9713e3760-link"><span class="keyword label">流数据</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 流数据引擎及流数据计算的基本概念</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e7513" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e7513-link" class="wh-expand-btn"></span><div class="title"><a href="../db_distr_comp/db_oper/import_data.html" id="tocId-d9713e7513-link">数据迁移</a><div class="wh-tooltip"><p class="shortdesc">如何从不同数据源向 DolphinDB 迁移数据</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="chap7_tutorials_system_management-d9713e7940" class="topicref" data-id="chap7_tutorials_system_management" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action chap7_tutorials_system_management-d9713e7940-link" class="wh-expand-btn"></span><div class="title"><a href="../sys_man/om_intro.html" id="chap7_tutorials_system_management-d9713e7940-link"><span class="keyword label">系统运维</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 的系统运维功能及方法</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="troubleshooting-d9713e8780" class="topicref" data-id="troubleshooting" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action troubleshooting-d9713e8780-link" class="wh-expand-btn"></span><div class="title"><a href="../error_codes/troubleshooting.html" id="troubleshooting-d9713e8780-link">故障排查</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="about_language_resources-d9713e20911" class="topicref" data-id="about_language_resources" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action about_language_resources-d9713e20911-link" class="wh-expand-btn"></span><div class="title"><a href="../progr/progr_intro.html" id="about_language_resources-d9713e20911-link"><span class="keyword label">编程语言</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 编程基本概念与方法、SQL 在 DolphinDB 的应用</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="functions_references-d9713e30925" class="topicref" data-id="functions_references" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action functions_references-d9713e30925-link" class="wh-expand-btn"></span><div class="title"><a href="../funcs/funcs_intro.html" id="functions_references-d9713e30925-link"><span class="keyword label">函数参考</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 函数分类、语法、详解及示例</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="api_protocol-d9713e94064" class="topicref" data-id="api_protocol" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action api_protocol-d9713e94064-link" class="wh-expand-btn"></span><div class="title"><a href="../api/connapi_intro.html" id="api_protocol-d9713e94064-link"><span class="keyword label">连接器 &amp; API</span></a><div class="wh-tooltip"><p class="shortdesc">面向不同编程语言的 DolphinDB API 及连接器，相关协议和用法</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="chap6_plugin-d9713e94210" class="topicref" data-id="chap6_plugin" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action chap6_plugin-d9713e94210-link" class="wh-expand-btn"></span><div class="title"><a href="../plugins/plg_intro.html" id="chap6_plugin-d9713e94210-link"><span class="keyword label">插件</span></a><div class="wh-tooltip"><p class="shortdesc">多个应用场景的插件使用说明和插件开发指导</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="third_party-d9713e97904" class="topicref" data-id="third_party" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action third_party-d9713e97904-link" class="wh-expand-btn"></span><div class="title"><a href="../third_party.html" id="third_party-d9713e97904-link">第三方工具</a></div></div></li><li role="treeitem" aria-expanded="true"><div data-tocid="about_tutorials-d9713e98227" class="topicref" data-id="about_tutorials" data-state="expanded"><span role="button" tabindex="0" aria-labelledby="button-collapse-action about_tutorials-d9713e98227-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/about_tutorials.html" id="about_tutorials-d9713e98227-link"><span class="keyword label">教程</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 产品使用教程</p></div></div></div><ul role="group" class="navbar-nav nav-list"><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e98280" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e98280-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/new_users_finance.html" id="tocId-d9713e98280-link">新用户入门</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e98327" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e98327-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/database.html" id="tocId-d9713e98327-link">数据库</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e99111" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e99111-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/std_sql_ddb.html" id="tocId-d9713e99111-link">编程</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e100448" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e100448-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming-real-time-correlation-processing_2.html" id="tocId-d9713e100448-link">流数据</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e100955" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e100955-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/scheduledJob_2.html" id="tocId-d9713e100955-link">系统运维</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="模块概述-d9713e101923" class="topicref" data-id="模块概述" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action 模块概述-d9713e101923-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/tu_modules.html" id="模块概述-d9713e101923-link">模块</a></div></div></li><li role="treeitem" aria-expanded="true"><div data-tocid="tocId-d9713e102568" class="topicref" data-state="expanded"><span role="button" tabindex="0" aria-labelledby="button-collapse-action tocId-d9713e102568-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/OHLC_2.html" id="tocId-d9713e102568-link">金融场景案例</a></div></div><ul role="group" class="navbar-nav nav-list"><li role="treeitem"><div data-tocid="k-线计算-d9713e102569" class="topicref" data-id="k-线计算" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/OHLC_2.html" id="k-线计算-d9713e102569-link">K 线计算</a></div></div></li><li role="treeitem"><div data-tocid="使用-klinechart-展示-dolphindb-k-线-d9713e102615" class="topicref" data-id="使用-klinechart-展示-dolphindb-k-线" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/displaying_the_dolphindb_k-line_with_klinechart.html" id="使用-klinechart-展示-dolphindb-k-线-d9713e102615-link">使用 KLineChart 展示 DolphinDB K 线</a></div></div></li><li role="treeitem"><div data-tocid="python--hdf5-因子计算与-dolphindb-一体化因子计算方案对比-d9713e102661" class="topicref" data-id="python--hdf5-因子计算与-dolphindb-一体化因子计算方案对比" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/Python_HDF5_vs_DolphinDB.html" id="python--hdf5-因子计算与-dolphindb-一体化因子计算方案对比-d9713e102661-link">Python + HDF5 因子计算与 DolphinDB 一体化因子计算方案对比</a></div></div></li><li role="treeitem"><div data-tocid="python--文件存储与-dolphindb-因子计算性能比较-d9713e102707" class="topicref" data-id="python--文件存储与-dolphindb-因子计算性能比较" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/DolphinDB_VS_PythonFile_Storage.html" id="python--文件存储与-dolphindb-因子计算性能比较-d9713e102707-link">Python + 文件存储与 DolphinDB 因子计算性能比较</a></div></div></li><li role="treeitem"><div data-tocid="python-parser-在金融量化分析场景的应用入门-d9713e102753" class="topicref" data-id="python-parser-在金融量化分析场景的应用入门" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/py_parser__quant_fin.html" id="python-parser-在金融量化分析场景的应用入门-d9713e102753-link">Python Parser 在金融量化分析场景的应用入门</a></div></div></li><li role="treeitem"><div data-tocid="处理-level-2-行情数据实例-d9713e102799" class="topicref" data-id="处理-level-2-行情数据实例" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/l2_stk_data_proc_2.html" id="处理-level-2-行情数据实例-d9713e102799-link">处理 Level-2 行情数据实例</a></div></div></li><li role="treeitem"><div data-tocid="存储金融数据的分区方案最佳实践-d9713e102845" class="topicref" data-id="存储金融数据的分区方案最佳实践" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/best_practices_for_partitioned_storage.html" id="存储金融数据的分区方案最佳实践-d9713e102845-link">存储金融数据的分区方案最佳实践</a></div></div></li><li role="treeitem"><div data-tocid="公募基金历史数据基础分析教程-d9713e102891" class="topicref" data-id="公募基金历史数据基础分析教程" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/public_fund_basic_analysis.html" id="公募基金历史数据基础分析教程-d9713e102891-link">公募基金历史数据基础分析教程</a></div></div></li><li role="treeitem"><div data-tocid="股票行情回放-d9713e102937" class="topicref" data-id="股票行情回放" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/stock_market_replay_2.html" id="股票行情回放-d9713e102937-link">股票行情回放</a></div></div></li><li role="treeitem"><div data-tocid="搭建行情回放服务的最佳实践-d9713e102983" class="topicref" data-id="搭建行情回放服务的最佳实践" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/appendices_market_replay_bp.html" id="搭建行情回放服务的最佳实践-d9713e102983-link">搭建行情回放服务的最佳实践</a></div></div></li><li role="treeitem"><div data-tocid="国内股票行情数据导入实例-d9713e103029" class="topicref" data-id="国内股票行情数据导入实例" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/stockdata_csv_import_demo.html" id="国内股票行情数据导入实例-d9713e103029-link">国内股票行情数据导入实例</a></div></div></li><li role="treeitem"><div data-tocid="基金份额参考价值-iopv-计算-d9713e103076" class="topicref" data-id="基金份额参考价值-iopv-计算" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming_IOPV_2.html" id="基金份额参考价值-iopv-计算-d9713e103076-link">基金份额参考价值 IOPV 计算</a></div></div></li><li role="treeitem"><div data-tocid="基于快照行情的股票和基金-k-线合成-d9713e103122" class="topicref" data-id="基于快照行情的股票和基金-k-线合成" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/k.html" id="基于快照行情的股票和基金-k-线合成-d9713e103122-link">基于快照行情的股票和基金 K 线合成</a></div></div></li><li role="treeitem"><div data-tocid="计算基金日频因子-d9713e103168" class="topicref" data-id="计算基金日频因子" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/fund_factor_contrasted_by_py.html" id="计算基金日频因子-d9713e103168-link">计算基金日频因子</a></div></div></li><li role="treeitem"><div data-tocid="基于逐笔数据合成高频-orderbookdolphindb-orderbook-引擎-d9713e103214" class="topicref" data-id="基于逐笔数据合成高频-orderbookdolphindb-orderbook-引擎" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/orderBookSnapshotEngine.html" id="基于逐笔数据合成高频-orderbookdolphindb-orderbook-引擎-d9713e103214-link">基于逐笔数据合成高频 Orderbook：DolphinDB Orderbook 引擎</a></div></div></li><li role="treeitem" class="active"><div data-tocid="金融-poc-用户历史数据导入指导手册之股票-level-2-逐笔篇-d9713e103260" class="topicref" data-id="金融-poc-用户历史数据导入指导手册之股票-level-2-逐笔篇" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/LoadDataForPoc.html" id="金融-poc-用户历史数据导入指导手册之股票-level-2-逐笔篇-d9713e103260-link">金融 PoC 用户历史数据导入指导手册之股票 Level-2 逐笔篇</a></div></div></li><li role="treeitem"><div data-tocid="金融实时实际波动率预测-d9713e103306" class="topicref" data-id="金融实时实际波动率预测" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/ml_volatility_2.html" id="金融实时实际波动率预测-d9713e103306-link">金融实时实际波动率预测</a></div></div></li><li role="treeitem"><div data-tocid="金融因子流式实现-d9713e103352" class="topicref" data-id="金融因子流式实现" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/str_comp_fin_quant_2.html" id="金融因子流式实现-d9713e103352-link">金融因子流式实现</a></div></div></li><li role="treeitem"><div data-tocid="开发股票波动率预测模型的-676-个输入特征-d9713e103398" class="topicref" data-id="开发股票波动率预测模型的-676-个输入特征" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/metacode_derived_features_2.html" id="开发股票波动率预测模型的-676-个输入特征-d9713e103398-link">开发股票波动率预测模型的 676 个输入特征</a></div></div></li><li role="treeitem"><div data-tocid="快速搭建-level-2-快照数据流批一体因子计算平台最佳实践-d9713e103444" class="topicref" data-id="快速搭建-level-2-快照数据流批一体因子计算平台最佳实践" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/l2_snapshot_factor_calc_2.html" id="快速搭建-level-2-快照数据流批一体因子计算平台最佳实践-d9713e103444-link">快速搭建 Level-2 快照数据流批一体因子计算平台最佳实践</a></div></div></li><li role="treeitem"><div data-tocid="量化金融范例-d9713e103490" class="topicref" data-id="量化金融范例" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/quant_finance_examples.html" id="量化金融范例-d9713e103490-link">量化金融范例</a></div></div></li><li role="treeitem"><div data-tocid="流式计算中证-1000-指数主买主卖交易量-d9713e103536" class="topicref" data-id="流式计算中证-1000-指数主买主卖交易量" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/CSI_1000_2.html" id="流式计算中证-1000-指数主买主卖交易量-d9713e103536-link">流式计算中证 1000 指数主买/主卖交易量</a></div></div></li><li role="treeitem"><div data-tocid="深度不平衡买卖压力指标波动率计算-d9713e103583" class="topicref" data-id="深度不平衡买卖压力指标波动率计算" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/sql_performance_optimization_wap_di_rv.html" id="深度不平衡买卖压力指标波动率计算-d9713e103583-link">深度不平衡、买卖压力指标、波动率计算</a></div></div></li><li role="treeitem"><div data-tocid="实时合成自定义频订单簿快照dolphindb-insight-行情插件与订单簿引擎应用-d9713e103629" class="topicref" data-id="实时合成自定义频订单簿快照dolphindb-insight-行情插件与订单簿引擎应用" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/insight_plugin_orderbook_engine_application.html" id="实时合成自定义频订单簿快照dolphindb-insight-行情插件与订单簿引擎应用-d9713e103629-link">实时合成自定义频订单簿快照：DolphinDB INSIGHT 行情插件与订单簿引擎应用</a></div></div></li><li role="treeitem"><div data-tocid="实时计算分钟资金流-d9713e103675" class="topicref" data-id="实时计算分钟资金流" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming_capital_flow_order_by_order_2.html" id="实时计算分钟资金流-d9713e103675-link">实时计算分钟资金流</a></div></div></li><li role="treeitem"><div data-tocid="实时计算高频因子-d9713e103721" class="topicref" data-id="实时计算高频因子" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/hf_factor_streaming_2.html" id="实时计算高频因子-d9713e103721-link">实时计算高频因子</a></div></div></li><li role="treeitem"><div data-tocid="实时计算日累计逐单资金流-d9713e103767" class="topicref" data-id="实时计算日累计逐单资金流" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming_capital_flow_daily_2.html" id="实时计算日累计逐单资金流-d9713e103767-link">实时计算日累计逐单资金流</a></div></div></li><li role="treeitem"><div data-tocid="实时计算涨幅榜-d9713e103813" class="topicref" data-id="实时计算涨幅榜" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/rt_stk_price_inc_calc_2.html" id="实时计算涨幅榜-d9713e103813-link">实时计算涨幅榜</a></div></div></li><li role="treeitem"><div data-tocid="实时选取外汇行情多价源最优价-d9713e103859" class="topicref" data-id="实时选取外汇行情多价源最优价" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/best_price_selection.html" id="实时选取外汇行情多价源最优价-d9713e103859-link">实时选取外汇行情多价源最优价</a></div></div></li><li role="treeitem"><div data-tocid="外汇掉期估值计算-d9713e103905" class="topicref" data-id="外汇掉期估值计算" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/FxSwapValuation.html" id="外汇掉期估值计算-d9713e103905-link">外汇掉期估值计算</a></div></div></li><li role="treeitem"><div data-tocid="因子计算平台构建-d9713e103951" class="topicref" data-id="因子计算平台构建" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/Python_Celery.html" id="因子计算平台构建-d9713e103951-link">因子计算平台构建</a></div></div></li><li role="treeitem"><div data-tocid="因子计算最佳实践-d9713e103997" class="topicref" data-id="因子计算最佳实践" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/best_practice_for_factor_calculation.html" id="因子计算最佳实践-d9713e103997-link">因子计算最佳实践</a></div></div></li><li role="treeitem"><div data-tocid="mvo_tutorial-d9713e104043" class="topicref" data-id="mvo_tutorial" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/MVO.html" id="mvo_tutorial-d9713e104043-link">优化投资组合：DolphinDB 最优化求解系列函数应用指南</a></div></div></li><li role="treeitem"><div data-tocid="中高频多因子库存储最佳实践-d9713e104090" class="topicref" data-id="中高频多因子库存储最佳实践" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/best_practices_for_multi_factor.html" id="中高频多因子库存储最佳实践-d9713e104090-link">中高频多因子库存储最佳实践</a></div></div></li><li role="treeitem"><div data-tocid="alphalens-在-dolphindb-中的应用因子分析建模实践-d9713e104136" class="topicref" data-id="alphalens-在-dolphindb-中的应用因子分析建模实践" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/Practical_Factor_Analysis_Modeling.html" id="alphalens-在-dolphindb-中的应用因子分析建模实践-d9713e104136-link">Alphalens 在 DolphinDB 中的应用：因子分析建模实践</a></div></div></li><li role="treeitem"><div data-tocid="dolphindb-与-dolphinscheduler-的集成-d9713e104182" class="topicref" data-id="dolphindb-与-dolphinscheduler-的集成" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/dolphinscheduler_integration.html" id="dolphindb-与-dolphinscheduler-的集成-d9713e104182-link">DolphinDB 与 DolphinScheduler 的集成</a></div></div></li><li role="treeitem"><div data-tocid="dolphindb-与-python-airflow-最佳实践-d9713e104228" class="topicref" data-id="dolphindb-与-python-airflow-最佳实践" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/ddb_airflow.html" id="dolphindb-与-python-airflow-最佳实践-d9713e104228-link">DolphinDB 与 Python AirFlow 最佳实践</a></div></div></li><li role="treeitem"><div data-tocid="gplearn-d9713e104274" class="topicref" data-id="gplearn" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/gplearn.html" id="gplearn-d9713e104274-link">Shark GPLearn 快速上手</a></div></div></li><li role="treeitem"><div data-tocid="利用jit加速计算-etf-期权隐含波动率和希腊值-d9713e104320" class="topicref" data-id="利用jit加速计算-etf-期权隐含波动率和希腊值" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/IV_Greeks_Calculation_for_ETF_Options_Using_JIT.html" id="利用jit加速计算-etf-期权隐含波动率和希腊值-d9713e104320-link">利用JIT加速计算 ETF 期权隐含波动率和希腊值</a></div></div></li><li role="treeitem"><div data-tocid="基于-dolphindb-的-brinson-绩效归因模型实践-d9713e104366" class="topicref" data-id="基于-dolphindb-的-brinson-绩效归因模型实践" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/brinson.html" id="基于-dolphindb-的-brinson-绩效归因模型实践-d9713e104366-link">基于 DolphinDB 的 Brinson 绩效归因模型实践</a></div></div></li><li role="treeitem"><div data-tocid="基于-dolphindb-的-campisi-绩效归因模型实践-d9713e104412" class="topicref" data-id="基于-dolphindb-的-campisi-绩效归因模型实践" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/campisi.html" id="基于-dolphindb-的-campisi-绩效归因模型实践-d9713e104412-link">基于 DolphinDB 的 Campisi 绩效归因模型实践</a></div></div></li><li role="treeitem"><div data-tocid="期货分钟频cta策略回测案例-d9713e104458" class="topicref" data-id="期货分钟频cta策略回测案例" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/futures_minute_frequency_cta_strategy_backtest_example.html" id="期货分钟频cta策略回测案例-d9713e104458-link">期货分钟频CTA策略回测案例</a></div></div></li><li role="treeitem"><div data-tocid="exchdata-交易所历史股票数据自动化导入功能模块使用教程-d9713e104504" class="topicref" data-id="exchdata-交易所历史股票数据自动化导入功能模块使用教程" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/exchdata_exchange_historical_stock_data_auto_import_module_tutorial.html" id="exchdata-交易所历史股票数据自动化导入功能模块使用教程-d9713e104504-link">ExchData 交易所历史股票数据自动化导入功能模块使用教程</a></div></div></li><li role="treeitem"><div data-tocid="ficc_func_uasge_and_performance-d9713e104550" class="topicref" data-id="ficc_func_uasge_and_performance" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/ficc_func_uasge_and_performance.html" id="ficc_func_uasge_and_performance-d9713e104550-link">FICC 固收系列函数使用示例及性能</a></div></div></li><li role="treeitem"><div data-tocid="title1-d9713e104597" class="topicref" data-id="title1" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/ficc_funcs_application.html" id="title1-d9713e104597-link">FICC 固收系列函数应用场景</a></div></div></li><li role="treeitem"><div data-tocid="最优化函数_socp_的使用及转化案例-d9713e104643" class="topicref" data-id="最优化函数_socp_的使用及转化案例" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/socp_usage_case.html" id="最优化函数_socp_的使用及转化案例-d9713e104643-link">最优化函数 socp 的使用及转化案例</a></div></div></li><li role="treeitem"><div data-tocid="k_line_calculation-d9713e104689" class="topicref" data-id="k_line_calculation" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/k_line_calculation%20.html" id="k_line_calculation-d9713e104689-link">基于期货快照行情数据计算合约 K 线以及主连行情</a></div></div></li><li role="treeitem"><div data-tocid="backtest_introduction_usage-d9713e104735" class="topicref" data-id="backtest_introduction_usage" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/backtest_introduction_usage.html" id="backtest_introduction_usage-d9713e104735-link">融资融券策略回测使用说明及回测案例</a></div></div></li><li role="treeitem"><div data-tocid="stock_backtest-d9713e104781" class="topicref" data-id="stock_backtest" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/stock_backtest.html" id="stock_backtest-d9713e104781-link">股票中低频投资组合回测案例实现</a></div></div></li></ul></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e104827" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e104827-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming_engine_anomaly_alerts_2.html" id="tocId-d9713e104827-link">物联网场景案例</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e105795" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e105795-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/dolphindb_tensor_libtorch_tutorial.html" id="tocId-d9713e105795-link">机器学习</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e105842" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e105842-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/api_performance.html" id="tocId-d9713e105842-link">测试报告</a></div></div></li></ul></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e105982" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e105982-link" class="wh-expand-btn"></span><div class="title"><a href="../rn/server/3_00_2.html" id="tocId-d9713e105982-link">版本说明</a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 版本发布历史</p></div></div></div></li></ul></div>
		                        
                            </div>
                        </nav>
                    
                    
                    <div class="col-lg-7 col-md-9 col-sm-12" id="wh_topic_body">
                        <button id="wh_close_publication_toc_button" class="close-toc-button d-none" aria-label="Toggle publishing table of content" aria-controls="wh_publication_toc" aria-expanded="true">
                            <span class="close-toc-icon-container">
                                <span class="close-toc-icon"></span>     
                            </span>
                        </button>
                        <button id="wh_close_topic_toc_button" class="close-toc-button d-none" aria-label="Toggle topic table of content" aria-controls="wh_topic_toc" aria-expanded="true">
                            <span class="close-toc-icon-container">
                                <span class="close-toc-icon"></span>     
                            </span>
                        </button>
                        
                        <div class=" wh_topic_content body "><main role="main"><article class="- topic/topic topic" role="article" aria-labelledby="ariaid-title1"><h1 class="- topic/title title topictitle1" id="ariaid-title1">金融 PoC 用户历史数据导入指导手册之股票 Level-2 逐笔篇</h1><div class="- topic/body body"><p class="- topic/p p">在部署完 DolphinDB 后，将历史数据导入数据库是后续进行数据查询、计算和分析的基础。为协助用户快速导入数据，本文档基于 DolphinDB 已有的教程与大量用户的实践经验，从操作者角度出发，以 CSV 格式的文件为例，详细介绍金融行业用户导入逐笔数据的完整操作步骤。</p></div><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title2" id="1-任务规划"><h2 class="- topic/title title topictitle2" id="ariaid-title2">1. 任务规划</h2><div class="- topic/body body"><p class="- topic/p p">在导入历史数据之前，需要先将 CSV 文件存放在部署了 DolphinDB 的服务器上，然后从 DolphinDB 数据类型兼容性的角度分析数据源，根据分析结果选择满足建库建表要求的方案，并根据表连接需求选择适合的存储方案。最后，通过合理的分区规划，完成数据导入的准备。</p></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title3" id="11-数据源分析"><h3 class="- topic/title title topictitle3" id="ariaid-title3">1.1. 数据源分析</h3><div class="- topic/body body"></div><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title4" id="111-存储-csv-文件"><h4 class="- topic/title title topictitle4" id="ariaid-title4">1.1.1. 存储 CSV 文件</h4><div class="- topic/body body"><p class="- topic/p p">列数相同的以单字符分割的格式化 CSV 文件，DolphinDB 都可以导入。如下是常见的几种格式：</p><ul class="- topic/ul ul"><li class="- topic/li li">第一行是各列的列名</li><li class="- topic/li li">第一行是数据，文件没有列名</li><li class="- topic/li li">前几行是文件注释说明，接下来才是列名或数据</li><li class="- topic/li li">CSV 文件中缺少日期列或股票代码列，缺失的列以文件名或文件夹名的形式给出</li></ul><p class="- topic/p p">CSV 文件需要解压好，放到 DolphinDB 所在服务器上，并确认用户有权限访问对应目录。</p><p class="- topic/p p">逐笔数据包括逐笔委托和逐笔成交，上市和深市的数据格式不同，每个市场每种数据每天的数据量大约几个 GB。当总数据量超过一周时，推荐使用多任务并行导入，并行度按天区分，每种格式的数据每天一个任务。比如：</p><ul class="- topic/ul ul"><li class="- topic/li li">一天一个 CSV 文件</li><li class="- topic/li li">同一天的 CSV 文件在同一个文件夹中</li><li class="- topic/li li">文件名中包含了日期</li></ul></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title5" id="112-导入-csv-文件"><h4 class="- topic/title title topictitle4" id="ariaid-title5">1.1.2. 导入 CSV 文件</h4><div class="- topic/body body"><p class="- topic/p p">使用 Linux 系统的 head 等命令打开 CSV 文件，确定要导入或添加的列在 DolphinDB 数据库中的字段名称和数据类型。字段名称的确定方式如下：</p><ul class="- topic/ul ul"><li class="- topic/li li">如果 CSV 文件有列名，使用函数<code class="+ topic/ph pr-d/codeph ph codeph">extractTextSchema</code>提取 CSV 文件的列名和列类型作为字段名称和类型。</li><li class="- topic/li li">如果 CSV 文件没有列名，根据相关数据对应的说明文档确定字段名称和类型（见下文的字段类型转换）。</li></ul><p class="- topic/p p"><strong class="+ topic/ph hi-d/b ph b">字段类型转换</strong></p><p class="- topic/p p">DolphinDB 支持的数据类型如下图：</p><img class="- topic/image image" src="images/LoadDataForPoc/dataType.png"/><br/><p class="- topic/p p">在这些数据类型中，整型、浮点型与其他数据库相同，可直接根据数据精度选择。DolphinDB 比较有特色的是如下两种类型：</p><ul class="- topic/ul ul"><li class="- topic/li li">字符串：在 DolphinDB 中可以把字符串保存为 SYMBOL 类型数据。一个 SYMBOL 类型数据在 DolphinDB 系统内部存储为一个整数，数据排序、查询、比较时更有效率。因此，使用 SYMBOL 类型有可能提高系统性能，同时也可节省存储空间。SYMBOL 和 STRING 的使用原则是：<strong class="+ topic/ph hi-d/b ph b">重复多的有限数量的字符串使用 SYMBOL，重复少的描述性字符串使用 STRING。</strong> 比如，股票代码，交易类型标志等使用 SYMBOL，例如 ["IBM","C","MS"] 等；备注、自定义信息等使用 STRING。在结构化的 level2 金融数据中，STRING 使用得较少。</li><li class="- topic/li li">时间日期：如上图所示，DolphinDB 支持丰富的时间日期类型。凡是涉及时间日期的，推荐用户根据不同精度选择对应的 DolphinDB 时间日期类型。</li></ul><p class="- topic/p p">下图是通过 head 命令查看的上市委托数据的 CSV 文件。</p><img class="- topic/image image" src="images/LoadDataForPoc/headEntrust.png"/><br/><p class="- topic/p p">从上图可以看出，这个 CSV 文件的第一行是一些说明备注信息，在后续读取的时候需要跳过。这个文件没有列名，从第二行开始是数据，共 10 列。从左至右的字段名根据上市的说明文档定义为：SecurityID, TransactTime, valOrderNoue, Price, Balance, OrderBSFlag, OrdType, OrderIndex, ChannelNo, BizIndex。</p><p class="- topic/p p">其中 SecurityID, OrderBSFlag 和 OrdType 为重复较多的有限数量的字符串，使用 SYMBOL 类型；TransactTime 为从年到毫秒的日期，使用 TIMESTAMP 数据类型；其它的字段没有特殊之处，整数用 INT，浮点数用 DOUBLE。所以，从左至右存储字段的数据类型定义为：SYMBOL, TIMESTAMP, INT, DOUBLE, INT, SYMBOL, SYMBOL, INT, INT, INT。</p><p class="- topic/p p">其它格式的 CSV 文件，也按此方式确定好字段名称和数据类型。后续数据库中按这些定义好的类型存储数据。</p><p class="- topic/p p">按上述分析定义的表结构列数和 CSV 文件完全一致。如果有特殊需要，也可以增加或减少列。只要字段名称和数据类型按顺序一一对应即可。比如计划将上市和深市的数据统一存储，那么分别分析两市的 CSV 文件，确定共同保留的列，确定字段名称和字段类型。</p><p class="- topic/p p">DolphinDB 导入数据的步骤是先把 CSV 文件读入内存，再写入硬盘。由于不同 CSV 文件对相同字段保存方式不同，CSV 文件在导入内存时不一定能正确识别出数据类型。可能需要对如下字段进行转换：</p><ul class="- topic/ul ul"><li class="- topic/li li">股票代码列：对于 002415, 600001 等数字样式，会被识别为 INT 类型，需要转为 SYMBOL 类型。如果不同代码的数字位数不同，转换时，还要按 6 位对齐</li><li class="- topic/li li">时间日期列：对于 20220101093000000, 20220101, 93000000 和 epoch 格式等数字样式，会被识别为 LONG 类型，需要转为 DolphinDB 的 TIMESTAMP, DATE, TIME 等精度的日期时间类型</li><li class="- topic/li li">一些交易标志列：对于 C, B, S 等字母样式，会识别为 CHAR 类型，需要转为 SYMBOL 类型</li><li class="- topic/li li">需要最终存储为 SYMBOL 类型的，只要转为 STRING 类型即可。</li></ul><p class="- topic/p p">总而言之，CSV 数据的一些列在导入内存后，可能和期望存储到数据库中的数据类型不一致，需要进行转换。具体的转换方式也比较简单，将在后面实操章节中详细介绍。</p></div></article></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title6" id="12-规划存储方案"><h3 class="- topic/title title topictitle3" id="ariaid-title6">1.2. 规划存储方案</h3><div class="- topic/body body"><p class="- topic/p p">分析完数据源后，需要规划如何在 DolphinDB 中基于 level2 逐笔数据建库建表。存储方案的设计原则是：<strong class="+ topic/ph hi-d/b ph b">当没有表连接分析的需求时，推荐单库单表存储数据；当有表连接需求时，一库多表存储数据。</strong></p><ul class="- topic/ul ul"><li class="- topic/li li">沪深两市的逐笔委托和逐笔成交数据之间一般是有关联分析需求的，所以推荐一库多表。</li><li class="- topic/li li">上市和深市不需要合并时，建立两数据库，一个保存上市数据，另一个保存深市数据。每个数据库中分别建立两个数据表，一个数据表存储逐笔委托数据，另一个数据表存储逐笔成交数据。</li><li class="- topic/li li">若沪深两市的数据需要合并统一存储，则规划一个数据库，库内建两个数据表，一个数据表保存两市的逐笔委托，另一个保存两市的逐笔成交。</li></ul><p class="- topic/p p"><strong class="+ topic/ph hi-d/b ph b">DolphinDB 单表存储的数据量无上限，同一种类型的数据全部存储到一个数据表，不需要考虑分库分表。</strong></p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title7" id="13-规划分区"><h3 class="- topic/title title topictitle3" id="ariaid-title7">1.3. 规划分区</h3><div class="- topic/body body"><p class="- topic/p p"><strong class="+ topic/ph hi-d/b ph b">规划分区是建立数据库之前最重要的一环</strong>，有以下几点作用：</p><ul class="- topic/ul ul"><li class="- topic/li li">分区使大型表更易于管理，提高查询速度</li><li class="- topic/li li">分区使系统可以充分利用资源，提高计算速度</li><li class="- topic/li li">增加了系统的可用性</li></ul><p class="- topic/p p">分区原理及详细教程参见：<a class="- topic/xref xref" href="database.html">分区数据库设计和操作</a>。</p><p class="- topic/p p">对于 level2 逐笔数据的场景，推荐复合分区，先按日期做值分区，再按股票代码做 HASH 分区。</p><p class="- topic/p p">分区数量由数据大小决定，TSDB 引擎每个分区数据量为压缩前 400MB-1GB，OLAP 引擎每个分区数据量为压缩前 100MB-300MB。</p><p class="- topic/p p">分区是在数据库层面进行的，同一个数据库中的不同数据表，分区方式相同。当需要关联的两表存储到同一个数据库中时，以数据量大的表为基准，按上述原则进行分区。</p></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title8" id="2-导入步骤"><h2 class="- topic/title title topictitle2" id="ariaid-title8">2. 导入步骤</h2><div class="- topic/body body"><p class="- topic/p p">完成分析和规划后，用户可按照本章步骤导入数据。先用单个文件进行调试，调试成功后，再使用多任务并行方式，对全量数据进行快速导入。</p></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title9" id="21-建库建表"><h3 class="- topic/title title topictitle3" id="ariaid-title9">2.1. 建库建表</h3><div class="- topic/body body"><p class="- topic/p p">本教程以上海证券交易所的逐笔委托数据为例来建库建表，点击 <a class="- topic/xref xref" href="https://www.dolphindb.cn/downloads/docs/LoadDataForPoc.zip" target="_blank" rel="external noopener">Entrust</a> 下载用例数据。文件解压后放到 loadForPoc/SH/Order/20210104 目录下。在 DolphinDB 中，可以使用<code class="+ topic/ph pr-d/codeph ph codeph">create</code>语句建库建表。DolphinDB 建库时有 OLAP 和 TSDB 两种存储引擎可以选择。</p><p class="- topic/p p">本教程推荐选用 TSDB 引擎。上市每天逐笔委托数据大小在 3GB 左右，根据前面的分区规划，先按日期做值分区，再用股票代码做 7 个 HASH 分区。按日期值分区时，<strong class="+ topic/ph hi-d/b ph b">VALUE 的初始值写两三天的初始值即可，实际分区值会根据数据的实际日期自动扩展</strong>。</p><p class="- topic/p p">完整的建库代码如下：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>if (existsDatabase("dfs://sh_entrust"))
{
 dropDatabase("dfs://sh_entrust")
}

create database "dfs://sh_entrust" partitioned by VALUE(2022.01.01..2022.01.03), HASH([SYMBOL, 10]), engine='TSDB'</code></pre><p class="- topic/p p">建库完成后，开始建表。建表的关键是指定字段名称及类型，先用 head 命令在 Linux 系统下查看一下 CSV 文件的结构，如下图所示：</p><img class="- topic/image image" src="images/LoadDataForPoc/csvType.jpg"/><br/><p class="- topic/p p">可以看到，这个 CSV 文件有如下特点：</p><ul class="- topic/ul ul"><li class="- topic/li li">第一行是文件说明，后续各种读取都需要跳过这一行</li><li class="- topic/li li">从第二行开始是数据，没有列名，在建表时需要根据数据的说明文档定义字段名称和字段类型</li></ul><p class="- topic/p p">建表时，OLAP 引擎和 TSDB 引擎都需要指定分区字段，例如：partitioned by TransactTime,SecurityID。TSDB 引擎还有一个分区内排序字段的参数要指定，例如：sortColumns = [`SecurityID,`TransactTime]。注意字段顺序不能调换。</p><p class="- topic/p p">完整建表语句如下：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>create table "dfs://sh_entrust"."entrust"(
 SecurityID SYMBOL,
 TransactTime TIMESTAMP,
 valOrderNoue INT,
 Price DOUBLE,
 Balance INT,
 OrderBSFlag SYMBOL,
 OrdType SYMBOL,
 OrderIndex INT,
 ChannelNo INT,
 BizIndex INT)
partitioned by TransactTime,SecurityID,
sortColumns = [`SecurityID,`TransactTime]</code></pre><p class="- topic/p p">确认数据表列数时，应当根据用户需求来指定。当 CSV 文件缺少或多余某些列时，用户可使用脚本在 CSV 文件基础上增加或减少列。</p><p class="- topic/p p">在列数和 CSV 文件不一样时，确认 HASH 分区的数量，需要先将各列数据类型占用的字节数据求和，得到一行数据的大小，然后乘以数据行数，得到一天的数据大小。最后，使用一天的数据大小除以每个分区的大小，得到 HASH 分区的数量。</p><p class="- topic/p p">通常逐笔数据是不需要去重的。如果由于特定的数据源等原因，有去重的需求，可在建表时指定 keepDuplicates 参数的值，包含以下选项：</p><ul class="- topic/ul ul"><li class="- topic/li li">ALL: 保留所有数据</li><li class="- topic/li li">LAST：仅保留最新数据</li><li class="- topic/li li">FIRST：仅保留第一条数据</li></ul></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title10" id="22-编写导入脚本"><h3 class="- topic/title title topictitle3" id="ariaid-title10">2.2. 编写导入脚本</h3><div class="- topic/body body"></div><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title11" id="221-导入单个文件"><h4 class="- topic/title title topictitle4" id="ariaid-title11">2.2.1. 导入单个文件</h4><div class="- topic/body body"><p class="- topic/p p">DolphinDB 导入数据的核心函数是<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>，可用于 CSV 文件读取、数据清洗和入库一体化操作。导入数据核心代码如下：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>db = database("dfs://sh_entrust")
def transType(mutable memTable)
{
 return memTable.replaceColumn!(`col0,string(memTable.col0)).replaceColumn!(`col1,datetimeParse(string(memTable.col1),"yyyyMMddHHmmssSSS")).replaceColumn!(`col5,string(memTable.col5)).replaceColumn!(`col6,string(memTable.col6))
}
filePath = "/home/ychan/data/loadForPoc/SH/Order/20210104/Entrust.csv"
loadTextEx(dbHandle = db, tableName = `entrust, partitionColumns = `col1`col0, filename = filePath, skipRows = 1,transform = transType)</code></pre><p class="- topic/p p">导入完成后，查询部分数据，代码如下：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select top 10 * from loadTable("dfs://sh_entrust",`entrust)</code></pre><p class="- topic/p p">如果数据导入成功，查询结果如下图所示</p><img class="- topic/image image" src="images/LoadDataForPoc/selectResult.jpg"/><br/><p class="- topic/p p">在单个文件导入过程中可能出现的问题及解决方案如下：</p><ul class="- topic/ul ul"><li class="- topic/li li"><p class="- topic/p p">数据类型不匹配，常见的报错信息如：“某列需要 SYMBOL 类型，实际数据类型是 INT”，此类报错提示用户进行数据类型转换。
详细的解决方式见 <a class="- topic/xref xref" href="#%E6%B8%85%E6%B4%97%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE">清洗转换数据</a>。</p></li><li class="- topic/li li"><p class="- topic/p p">如果系统中存在 nfs 存储介质，可能报 Bad file descriptor 的错误。这种情况要按照指定方式重新挂载一下 nfs 文件。nfs 文件需要用 v3 版本，并设置 local_lock 参数为 all。具体的挂载命令为：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>mount -t nfs -o v3,local_lock=all [IP]:/hdd/hdd0/nfs /hdd/hdd0/DolphinDB-test/</code></pre></li><li class="- topic/li li"><p class="- topic/p p">执行没有任何报错，但是任务长时间执行不完，等待时间已经远超文件大小除以硬盘速度的时间，观测硬盘状态，也没有任何写入。这种情况是因为单个 CSV 文件太大了，缓存不够用，这个缓存是专门为数据入库设置的一块内存，有关缓存机制的详细介绍见：<a class="- topic/xref xref" href="redoLog_cacheEngine.html">CacheEngine 与数据库日志教程</a> 与 <a class="- topic/xref xref" href="tsdb_explained.html">DolphinDB TSDB 存储引擎介绍</a>。解决方法是：先把 OLAPCacheEngineSize 和 TSDBCacheEngineSize 两个参数的值修改为大于 CSV 文件的大小，再重启系统。</p></li></ul><p class="- topic/p p">单文件完整的导入脚本下载链接为：<a class="- topic/xref xref" href="script/LoadDataForPoc/loadOneFile.dos">单文件导入</a></p></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title12" id="222-清洗转换数据"><h4 class="- topic/title title topictitle4" id="ariaid-title12">2.2.2. 清洗转换数据</h4><div class="- topic/body body"><p class="- topic/p p">上一节的核心导入代码中，使用了<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>函数，其中 transform 参数引用了 transType 函数定义，其作用是数据清洗和类型转换。<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>导入机制如下：</p><p class="- topic/p p">首先，把 CSV 文件加载到内存生成一个内存表，这个内存表的数据类型可能和之前建立的分布式数据表定义的类型不一致。可以通过指定 schema 的方式尝试进行自动转换，详见：<a class="- topic/xref xref" href="import_csv.html">指定数据导入格式</a>。无法进行自动转换的类型会提示失败。此时，我们需要使用 transform 参数引用的函数进行类型转换和数据清洗。从该函数的返回值中获得清洗转换后的数据，类型依然是一个内存表。然后，把处理好的内存表数据写到硬盘上对应数据库中的数据表内。如果 transform 参数已赋值，<strong class="+ topic/ph hi-d/b ph b">分布式表的结构和 transform 参数引用的函数返回的表的结构保持一致，不用和原 CSV 文件的结构保持一致。</strong></p><p class="- topic/p p">transform 能够非常方便地完成但不限于如下需求：</p><ul class="- topic/ul ul"><li class="- topic/li li">数据类型的转换</li><li class="- topic/li li">在 CSV 文件的基础上增加列</li><li class="- topic/li li">过滤 CSV 文件中的无效数据</li><li class="- topic/li li">字符编码转换，通常用于把 GBK 编码转换为 UTF-8 编码</li><li class="- topic/li li">把多档数据合成 array vector</li></ul></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title13" id="223-转换数据类型"><h4 class="- topic/title title topictitle4" id="ariaid-title13">2.2.3. 转换数据类型</h4><div class="- topic/body body"><p class="- topic/p p">DolphinDB 提供了读取 CSV 文件 schema 的函数<code class="+ topic/ph pr-d/codeph ph codeph">extractTextSchema</code>。使用以下代码提取 CSV 文件的 schema：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>filePath = "/home/ychan/data/loadForPoc/SH/Order/20210104/Entrust.csv"
extractTextSchema(filename = filePath, skipRows = 1)</code></pre><p class="- topic/p p">执行完成后，结果如下图</p><img class="- topic/image image" src="images/LoadDataForPoc/schemaResult.jpg"/><br/><p class="- topic/p p">返回结果中，第一列 name 表示 CSV 文件中各列的列名。如果 CSV 文件数据之前没有列名信息，列名自动命名为 col0, col1 等；如果有列名信息，列名和文件中的名称保持一致。第二列 type 表示 CSV 文件中自动识别出来的各列的数据类型。这个结果表的字段和我们建表时的字段是按从上到下的顺序一一对应的，我们把二者整理到一起，如下图所示：</p><img class="- topic/image image" src="images/LoadDataForPoc/vsType.jpg"/><br/><p class="- topic/p p">通过对比可以发现，内存表中的字段 col0, col1, col5, col6 与数据表中对应字段 SecurityID, TransactTime, OrderBSFlag, OrdType 的类型不同。如果此时直接进行数据导入，如下代码所示：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>db = database("dfs://sh_entrust")
filePath = "/home/ychan/data/loadForPoc/SH/Order/20210104/Entrust.csv"
loadTextEx(dbHandle = db, tableName = `entrust, partitionColumns = `col1`col0, filename = filePath, skipRows = 1)</code></pre><p class="- topic/p p">执行后发现报错：<strong class="+ topic/ph hi-d/b ph b">The column [SecurityID] expects type of SYMBOL, but the actual type is INT</strong>，即传入的 SecurityID 数据类型为整型，不符合 SYMBOL 的要求。而 transType 函数的作用就是自定义转换数据类型，赋给 transform 参数后再执行导入语句，会发现不再报错。其他字段的数据导入和类型转换依此类推。本案例中，共有四列做了转换，相关代码如下：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def transType(mutable memTable)
{
   return memTable.replaceColumn!(`col0,string(memTable.col0)).replaceColumn!(`col1,datetimeParse(string(memTable.col1),"yyyyMMddHHmmssSSS")).replaceColumn!(`col5,string(memTable.col5)).replaceColumn!(`col6,string(memTable.col6))
}</code></pre><p class="- topic/p p">可以看到，每修改一列就增加一个<code class="+ topic/ph pr-d/codeph ph codeph">replaceColumn!</code>函数。这个函数的作用是使用一个向量替换 table 中指定列，替换后，指定列的数据类型与向量的数据类型一致。在这个案例中，它的第一个参数是数据表的列名，第二个参数是使用相关函数对内存表的指定列处理之后的数据。所以，数据类型的转换的关键在于<code class="+ topic/ph pr-d/codeph ph codeph">replaceColumn!</code>函数第二个参数的写法。在金融数据的导入实践中，主要有以下几类：</p><ul class="- topic/ul ul"><li class="- topic/li li"><p class="- topic/p p">时间日期为 epoch 格式，也就是指定时间减去 1970-01-01 00:00:00 的差值。这个差值可以到秒、毫秒等，它是一串纯数字，会自动识别成整数。在转换时，直接把这个整数传递给 DolphinDB 对应时间日期类型的函数即可，如需精确到秒，使用<code class="+ topic/ph pr-d/codeph ph codeph">datetime</code>，精确到毫秒使用<code class="+ topic/ph pr-d/codeph ph codeph">timestamp</code>，精确到纳秒使用<code class="+ topic/ph pr-d/codeph ph codeph">namotimestamp</code>。逐笔数据一般精确到毫秒，类型转换函数的写法为：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def transType(mutable memTable)
{
   return memTable.replaceColumn!(`epochTimeCol,timestamp(memTable.epochTimeCol))
}</code></pre></li><li class="- topic/li li"><p class="- topic/p p">时间是日期格式，是纯数字组成的年月日时分秒等，中间没有分割符。比如 20220101，20220101093000 等，这些格式会被识别为整数。转换时，先把这些数字使用<code class="+ topic/ph pr-d/codeph ph codeph">string</code>函数转成字符串，再用<code class="+ topic/ph pr-d/codeph ph codeph">temporalParse</code>格式化成对应的日期格式。逐笔数据一般精确到毫秒，这种类型转换函数的写法为：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def transType(mutable memTable)
{
   return memTable.replaceColumn!(`ymdTimeCol,datetimeParse(string(memTable.ymdTimeCol),"yyyyMMddHHmmssSSS"))
}</code></pre></li><li class="- topic/li li"><p class="- topic/p p">股票代码是纯数字，会识别成整数。股票代码推荐定义为 SYMBOL 类型，在内存表中，只要使用<code class="+ topic/ph pr-d/codeph ph codeph">string</code>函数把其转化为字符串格式，在导入时，就能够自动存储为 SYMBOL 类型。此外，股票代码一般是 6 位，以零开头的需要用<code class="+ topic/ph pr-d/codeph ph codeph">lpad</code>函数要进行补齐。纯数字股票代码列转换的函数写法为</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def transType(mutable memTable)
{
   return memTable.replaceColumn!(`securityId,lpad(string(memTable.securityId),6,`0))
}</code></pre></li></ul></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title14" id="224-文件名给出某列信息在-csv-文件的基础上增加此列"><h4 class="- topic/title title topictitle4" id="ariaid-title14">2.2.4. 文件名给出某列信息，在 CSV 文件的基础上增加此列</h4><div class="- topic/body body"><p class="- topic/p p">有些时候，CSV 文件会缺少某些列，比如确少日期，然后，通过文件名给出了日期信息。其中所有数据的日期都和文件名相同。这种情况我们通过 transform 参数引用的函数，增加列并赋值。代码如下：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def addCol(mutable memTable,datePara)
{
    update memTable set date = datePara
    return memTable
}</code></pre><p class="- topic/p p">新增的列总是在最后，如果和分布式表的顺序不一致，在这个函数返回之前，先用<code class="+ topic/ph pr-d/codeph ph codeph">reorderColumns!</code>函数调整成一致。</p></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title15" id="225-过滤数据"><h4 class="- topic/title title topictitle4" id="ariaid-title15">2.2.5. 过滤数据</h4><div class="- topic/body body"><p class="- topic/p p">有些情况下，需要把 CSV 文件中的一些无效数据过滤掉再写入分布式表。在 transform 参数引用的函数中使用 select 筛选出符合条件的数据即可，比如我们只写入价格大于 0 的数据，函数定义的代码为：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def fliterData(mutable memTable)
{
    return select * from memTable where price &gt; 0
}</code></pre></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title16" id="226-转换字符编码转换"><h4 class="- topic/title title topictitle4" id="ariaid-title16">2.2.6. 转换字符编码转换</h4><div class="- topic/body body"><p class="- topic/p p">为了显示正常，有时候需要把 GBK 编码的列转成 UTF-8。transform 参数引用的函数的代码为：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def addCol(mutable memTable)
{
    return mutable.replaceColumn!(`custname,toUTF8(mutable.custname,`gbk))
}</code></pre></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title17" id="227-导入部分列"><h4 class="- topic/title title topictitle4" id="ariaid-title17">2.2.7. 导入部分列</h4><div class="- topic/body body"><p class="- topic/p p">导入部分列有两种方法，一是在 transform 参数引用的函数中筛选出需要的列，代码如下：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def partCol(mutable memTable)
{
    return select [需要的部分列名] from memTable
}</code></pre><p class="- topic/p p">方法二是通过指定 schema 的方式，详见如下链接的教程 2.4 节：<a class="- topic/xref xref" href="import_csv.html">导入指定列</a></p></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title18" id="228-并行导入"><h4 class="- topic/title title topictitle4" id="ariaid-title18">2.2.8. 并行导入</h4><div class="- topic/body body"><p class="- topic/p p">并行导入能够快速导入数据，这种导入方法会占用比较多的内存，所以在导入前，要配置合理的并行度。workerNum 可以控制并行度，估算方式为，<strong class="+ topic/ph hi-d/b ph b">可用内存除以一天的文件大小，得到 workerNum 的值。</strong> 可用内存的值是由 maxMemSize 参数确定的，一般配置为机器可用内存的 80%。此外，也要确保，maxMemSize 的值不大于 license 文件限制的内存大小。</p><p class="- topic/p p">并行导入时，多个任务不能同时写入一个分区，在做任务分配时，要确保不同任务写入不同的分区。因为一级分区为天，不同日期的数据会写到不同的分区。所以，推荐以每天数据与任务一一对应的方式来并行导入。</p><p class="- topic/p p">本案例批量导入了 2021 年 01 月 05 日到 01 月 15 日期间，9 个工作日的逐笔委托数据。为了方便下载，每天的数据限定为 180MB 左右，点击此处下载数据：<a class="- topic/xref xref" href="https://www.dolphindb.cn/downloads/docs/LoadDataForPoc.zip" target="_blank" rel="external noopener">批量导入数据</a>。由于之前单个文件导入的 CSV 文件比较大，在进行并行导入前，推荐先把单个导入的文件删除。批量导入的基本步骤如下：</p><ol class="- topic/ol ol"><li class="- topic/li li">在单个 CSV 文件导入的基础上，把一天的数据导入封装为一个函数</li><li class="- topic/li li">用异步任务的方式提交一批任务，按天进行批量导入。</li><li class="- topic/li li">如果两市的数据合并成一张表，则需要分别并行导入，不同市场的数据同时并行导入意味着不同任务同时写入一个分区，会报错。</li></ol><p class="- topic/p p">异步任务的详细用法见：<a class="- topic/xref xref" href="job_management_tutorial.html">DolphinDB 教程：作业管理</a>。代码如下：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def loadOneDayFile(db,table,filePath)
{
 csvFiles = exec filename from files(filePath) where filename like"%.csv"
 for(csvIdx in csvFiles)
 {
  loadTextEx(dbHandle = db, tableName = table, partitionColumns = `col1`col0, filename = filePath + "/"  + csvIdx, transform = transType, skipRows = 1)
 }
}

def parallelLoad(allFileContents)
{
 db = database("dfs://sh_entrust")
 table = `entrust
 dateFiles = exec filename from files(allFileContents) where isDir = true
 for(dateIdx in dateFiles)
 {
  submitJob("parallelLoad" + dateIdx,"parallelLoad",loadOneDayFile{db,table,},allFileContents + "/" + dateIdx)
 }
}

allFileContents = "/home/ychan/data/loadForPoc/SH/Order"
parallelLoad(allFileContents)</code></pre><p class="- topic/p p">以上代码定义了以下两个函数：</p><ul class="- topic/ul ul"><li class="- topic/li li"><p class="- topic/p p">loadOneDayFile，导入一天某种类型的数据。由于一天数据可能有多个 CSV 文件，因此需要在该函数内遍历目录下所有 CSV 文件后逐个导入。该函数使用 3 个入参：</p><ul class="- topic/ul ul"><li class="- topic/li li">db，数据库句柄。</li><li class="- topic/li li">table，表名。</li><li class="- topic/li li">filePath，目录参数，截止到日期一级。</li></ul></li><li class="- topic/li li"><p class="- topic/p p">parallelLoad，包含唯一参数 allFileContents，参数值为目录，最小级别为快照、逐笔委托、逐笔成交等。parallelLoad 函数遍历指定目录下的所有日期作为任务参数，调用 loadOneDayFile 按日期提交任务。</p></li></ul><p class="- topic/p p">loadOneDayFile 和 parallelLoad 这两个函数的写法不唯一，可以根据数据的存储格式参考本案例代码灵活设计。主要目的是按天提交任务，每个任务导入某种数据一天的数据。这些代码执行完成后，会马上返回，所提交的异步任务会在后台执行，可以调用<code class="+ topic/ph pr-d/codeph ph codeph">getRecentJobs</code>函数查看后台的任务执行情况。任务情况如下图所示：</p><img class="- topic/image image" src="images/LoadDataForPoc/getRecentJobs.jpg"/><br/><p class="- topic/p p">上图重 startTime 字段不为空，表示该任务已经在执行；endTime 不为空，表示该任务已经执行完成；errorMsg 字段不为空，说明这个任务执行出错了，根据这个错误信息对代码进行调试。</p><p class="- topic/p p">errorMsg 可能的错误信息及解决方式如下：</p><ul class="- topic/ul ul"><li class="- topic/li li">报错信息类似于：Retrieve directory content [/home/ychan/data/loadForPoc/SH/Order20210108]: No such file or directory。导入时文件找不到，一般是路径拼接的时候出错，尤其是反斜杠字符“/”容易多写或漏写，需要仔细检查查</li><li class="- topic/li li">报错信息为 Out of memory，根本原因是内存不够用了。需要增加可用内存或降低并发度</li><li class="- topic/li li">报错信息类似于：&lt;ChunkInTransaction&gt;filepath '/tickHot/20221125/Key0/5ncmg' has been owned by transaction 9702796 RefId:S00002。原因是分区冲突，不同任务往同一个分区写数据了，需要检查不同日期的数据是不是放乱了，任务分割是否合理</li></ul><p class="- topic/p p">完整的批量导入脚本链接为：<a class="- topic/xref xref" href="script/LoadDataForPoc/parallelLoad.dos">批量导入</a></p></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title19" id="229-监测导入状态"><h4 class="- topic/title title topictitle4" id="ariaid-title19">2.2.9. 监测导入状态</h4><div class="- topic/body body"><p class="- topic/p p">在数据导入的过程中，如果对导入的性能存在疑虑，可以通过一些工具观测系统资源使用情况，判断是否存在资源利用的瓶颈。在 Linux 系统的终端中输入 dstat 命令，可以查看硬盘写入情况。如下图所示：</p><img class="- topic/image image" src="images/LoadDataForPoc/hardWrite.jpg"/><br/><p class="- topic/p p">并行导入追求高速的写入性能，通过配置多块磁盘，可发挥硬盘并行 IO 的能力。通过单机配置文件 dolphindb.cfg 或集群配置文件 cluster.cfg 中的 volumes 参数进行磁盘配置。</p><p class="- topic/p p">并行导入时，通过观察硬盘的写入速度、内存消耗情况、CPU 利用率、集群间网络速率，查看资源使用情况。如果内存、CPU 和集群间网络都还有盈余，硬盘的 IO 还没有饱和，可以把 workerNum  配置修改的大一些，提升并行度。</p><p class="- topic/p p">总而言之，通过对并行任务的合理调度，充分利用某一类硬件的物理性能，达到硬件可以支持的最大导入速度。</p></div></article></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title20" id="3-附件"><h2 class="- topic/title title topictitle2" id="ariaid-title20">3. 附件</h2><div class="- topic/body body"><p class="- topic/p p">本章再以问答的形式，对导入时可能遇到的问题进行总结。</p><ol class="- topic/ol ol"><li class="- topic/li li"><p class="- topic/p p">只提交了一个文件的导入，长时间执行不完，硬盘也没有写入，这是什么原因？</p><p class="- topic/p p">答：这是因为单个 CSV 文件太大了，缓存不够用。这个缓存是专门为数据入库设置的一块内存，
详细的介绍见：<a class="- topic/xref xref" href="redoLog_cacheEngine.html">CacheEngine 与数据库日志教程</a> 与 <a class="- topic/xref xref" href="tsdb_explained.html">DolphinDB TSDB 存储引擎介绍</a>。</p><p class="- topic/p p">解决方法是：先把 OLAPCacheEngineSize 和 TSDBCacheEngineSize 两个参数的值修改为大于 CSV 文件的大小，再重启系统。</p></li><li class="- topic/li li"><p class="- topic/p p">导入时，时间是年月日时分秒结构的纯数字类型，如何转化为 DolphinDB 的时间日期格式？</p><p class="- topic/p p">答：解决方法见本篇文章 <a class="- topic/xref xref" href="#%E6%B8%85%E6%B4%97%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE">清洗转换数据</a> 的时间类型转换部分。</p></li><li class="- topic/li li"><p class="- topic/p p">导入时，时间是 epoch 格式，也就是指定时间减去 1970-01-01 00:00:00 的差值，如何转化为 DolphinDB 的时间日期格式？</p><p class="- topic/p p">答：解决方法见本篇文章 <a class="- topic/xref xref" href="#%E6%B8%85%E6%B4%97%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE">清洗转换数据</a> 的时间类型转换部分。</p></li><li class="- topic/li li"><p class="- topic/p p">导入时，股票代码列是纯数字，如何转成 SYMBOL 类型。</p><p class="- topic/p p">答：解决方法见本篇文章 <a class="- topic/xref xref" href="#%E6%B8%85%E6%B4%97%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE">清洗转换数据</a> 的股票代码类型转换部分。</p></li><li class="- topic/li li"><p class="- topic/p p">执行过程中，报 out of memory 错误，怎么处理？</p><p class="- topic/p p">答：这是因为导入过程中内存不够用了。如果使用的是社区版本 license，请联系负责支持的销售人员，获取试用版本 license。然后，查看 maxMemSize 参数的配置是否远小于系统内存，建议配置为系统内存的 80%。最后，检查 workerNum 配置，合理配置值的计算方法为：可用内存除以单个文件大小向下取整得到 workerNum 的值。</p></li><li class="- topic/li li"><p class="- topic/p p">nsf 系统导入时，报 Bad file descriptor 错误，怎么解决？</p><p class="- topic/p p">答：如果我们存储系统中存在 nfs 文件，那么 nfs 文件需要用 v3 版本，并设置 local_lock 参数为 all 的方式进行挂载。具体的挂载命令为：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>mount -t nfs -o v3,local_lock=all [IP]:/hdd/hdd0/nfs /hdd/hdd0/DolphinDB-test/</code></pre><p class="- topic/p p">如果不是这种挂载方式，需要先卸载，再使用这种方式重新挂载。</p></li><li class="- topic/li li"><p class="- topic/p p">如何在 DolphinDB 中 LoadTextEx 导入数据时，过滤无效数据？</p><p class="- topic/p p">答：过滤方法是在 transform 引用的函数中做清洗。解决方法详见 <a class="- topic/xref xref" href="#%E6%B8%85%E6%B4%97%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE">清洗转换数据</a> 的过滤无效数据部分。</p></li><li class="- topic/li li"><p class="- topic/p p">向 DolphinDB 数据库导入 CSV 数据时还要再加上 2 列怎么办？</p><p class="- topic/p p">答：增加方法是在 transform 引用的函数中做增加。解决方法详见 <a class="- topic/xref xref" href="#%E6%B8%85%E6%B4%97%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE">清洗转换数据</a> 的 增加列部分。</p></li><li class="- topic/li li"><p class="- topic/p p">符合如何导入部分列？</p><p class="- topic/p p">答：方法详见<a class="- topic/xref xref" href="#%E6%B8%85%E6%B4%97%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE">清洗转换数据</a> 导入部分列。</p></li><li class="- topic/li li"><p class="- topic/p p">数据如何去重复？</p><p class="- topic/p p">答：建表时指定 keepDuplicates 参数的值可以去重，包含以下选项：</p><ul class="- topic/ul ul"><li class="- topic/li li">ALL: 保留所有数据</li><li class="- topic/li li">LAST：仅保留最新数据</li><li class="- topic/li li">FIRST：仅保留第一条数据</li></ul></li></ol></div></article></article></main></div>
                        
                        
                        
                        
                        
                        
                    </div>
                    
                        <nav role="navigation" id="wh_topic_toc" aria-label="On this page" class="col-lg-2 d-none d-lg-block navbar d-print-none"> 
                            <div id="wh_topic_toc_content">
		                        
	                            <div class=" wh_topic_toc "><div class="wh_topic_label">在本页上</div><ul><li class="topic-item"><a href="#1-%E4%BB%BB%E5%8A%A1%E8%A7%84%E5%88%92" data-tocid="1-任务规划">1. 任务规划</a><ul><li class="topic-item"><a href="#11-%E6%95%B0%E6%8D%AE%E6%BA%90%E5%88%86%E6%9E%90" data-tocid="11-数据源分析">1.1. 数据源分析</a><ul><li class="topic-item"><a href="#111-%E5%AD%98%E5%82%A8-csv-%E6%96%87%E4%BB%B6" data-tocid="111-存储-csv-文件">1.1.1. 存储 CSV 文件</a></li><li class="topic-item"><a href="#112-%E5%AF%BC%E5%85%A5-csv-%E6%96%87%E4%BB%B6" data-tocid="112-导入-csv-文件">1.1.2. 导入 CSV 文件</a></li></ul></li><li class="topic-item"><a href="#12-%E8%A7%84%E5%88%92%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88" data-tocid="12-规划存储方案">1.2. 规划存储方案</a></li><li class="topic-item"><a href="#13-%E8%A7%84%E5%88%92%E5%88%86%E5%8C%BA" data-tocid="13-规划分区">1.3. 规划分区</a></li></ul></li><li class="topic-item"><a href="#2-%E5%AF%BC%E5%85%A5%E6%AD%A5%E9%AA%A4" data-tocid="2-导入步骤">2. 导入步骤</a><ul><li class="topic-item"><a href="#21-%E5%BB%BA%E5%BA%93%E5%BB%BA%E8%A1%A8" data-tocid="21-建库建表">2.1. 建库建表</a></li><li class="topic-item"><a href="#22-%E7%BC%96%E5%86%99%E5%AF%BC%E5%85%A5%E8%84%9A%E6%9C%AC" data-tocid="22-编写导入脚本">2.2. 编写导入脚本</a><ul><li class="topic-item"><a href="#221-%E5%AF%BC%E5%85%A5%E5%8D%95%E4%B8%AA%E6%96%87%E4%BB%B6" data-tocid="221-导入单个文件">2.2.1. 导入单个文件</a></li><li class="topic-item"><a href="#222-%E6%B8%85%E6%B4%97%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE" data-tocid="222-清洗转换数据">2.2.2. 清洗转换数据</a></li><li class="topic-item"><a href="#223-%E8%BD%AC%E6%8D%A2%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B" data-tocid="223-转换数据类型">2.2.3. 转换数据类型</a></li><li class="topic-item"><a href="#224-%E6%96%87%E4%BB%B6%E5%90%8D%E7%BB%99%E5%87%BA%E6%9F%90%E5%88%97%E4%BF%A1%E6%81%AF%E5%9C%A8-csv-%E6%96%87%E4%BB%B6%E7%9A%84%E5%9F%BA%E7%A1%80%E4%B8%8A%E5%A2%9E%E5%8A%A0%E6%AD%A4%E5%88%97" data-tocid="224-文件名给出某列信息在-csv-文件的基础上增加此列">2.2.4. 文件名给出某列信息，在 CSV 文件的基础上增加此列</a></li><li class="topic-item"><a href="#225-%E8%BF%87%E6%BB%A4%E6%95%B0%E6%8D%AE" data-tocid="225-过滤数据">2.2.5. 过滤数据</a></li><li class="topic-item"><a href="#226-%E8%BD%AC%E6%8D%A2%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%BD%AC%E6%8D%A2" data-tocid="226-转换字符编码转换">2.2.6. 转换字符编码转换</a></li><li class="topic-item"><a href="#227-%E5%AF%BC%E5%85%A5%E9%83%A8%E5%88%86%E5%88%97" data-tocid="227-导入部分列">2.2.7. 导入部分列</a></li><li class="topic-item"><a href="#228-%E5%B9%B6%E8%A1%8C%E5%AF%BC%E5%85%A5" data-tocid="228-并行导入">2.2.8. 并行导入</a></li><li class="topic-item"><a href="#229-%E7%9B%91%E6%B5%8B%E5%AF%BC%E5%85%A5%E7%8A%B6%E6%80%81" data-tocid="229-监测导入状态">2.2.9. 监测导入状态</a></li></ul></li></ul></li><li class="topic-item"><a href="#3-%E9%99%84%E4%BB%B6" data-tocid="3-附件">3. 附件</a></li></ul></div>
	                        	
                        	</div>
                        </nav>
                    
                </div>
            </div>
            
            
            
        </div> 
        <footer class="navbar navbar-default wh_footer">
  <div class=" footer-container mx-auto ">
<title>Copyright</title><p><b> ©2025 浙江智臾科技有限公司 浙ICP备18048711号-3</b></p>
  </div>
</footer>
        
        <div id="go2top" class="d-print-none">
            <span class="oxy-icon oxy-icon-up"></span>
        </div>
        
        <div id="modal_img_large" class="modal">
            <span class="close oxy-icon oxy-icon-remove"></span>
            <div id="modal_img_container"></div>
            <div id="caption"></div>
        </div>
        
        
        
    </body>
</html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh" lang="zh" data-whc_version="26.0">
    <head><link rel="shortcut icon" href="../favicon.ico"/><link rel="icon" href="../favicon.ico"/><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="description" content="实时流处理是指将业务系统产生的持续增长的动态数据进行实时的收集、清洗、统计、入库，并对结果进行实时的展示。在金融交易、物联网、互联网/移动互联网等应用场景中，复杂的业务需求对大数据处理的实时性提出了极高的要求。面向静态数据表的传统计算引擎无法胜任流数据领域的分析和计算任务。 ..."/><meta name="DC.rights.owner" content="(C) 版权 2025"/><meta name="copyright" content="(C) 版权 2025"/><meta name="generator" content="DITA-OT"/><meta name="DC.type" content="topic"/><meta name="DC.coverage" content=""/><meta name="DC.relation" content="../tutorials/about_tutorials.html"/><meta name="prodname" content="DolphinDB"/><meta name="brand" content="DolphinDB"/><meta name="DC.creator" content="DolphinDB"/><meta name="DC.publisher" content="DDB N/A DDB 200"/><meta name="DC.format" content="HTML5"/><meta name="DC.identifier" content="流数据功能应用"/><title>流数据功能应用</title><!--  Generated with Oxygen version 26.0, build number 2024012323.  --><meta name="wh-path2root" content="../"/><meta name="wh-toc-id" content="&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;?workdir /tmp/temp20250305183303418/tutorials?&gt;&lt;?workdir-uri file:/tmp/temp20250305183303418/tutorials/?&gt;&lt;?path2project ../?&gt;&lt;?path2project-uri ../?&gt;&lt;?path2rootmap-uri ../?&gt;&lt;topic xmlns:dita-ot=&#34;http://dita-ot.sourceforge.net/ns/201007/dita-ot&#34; xmlns:ditaarch=&#34;http://dita.oasis-open.org/architecture/2005/&#34; class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;流数据功能应用&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:1;1:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:1;1:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;流数据功能应用&lt;/title&gt;&lt;prolog class=&#34;- topic/prolog &#34;&gt;&lt;author class=&#34;- topic/author &#34; xtrc=&#34;author:1;12:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DolphinDB&lt;/author&gt;&lt;publisherinformation class=&#34;- topic/publisher bookmap/publisherinformation &#34; xtrc=&#34;publisherinformation:1;14:31&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt; &lt;person class=&#34;- topic/data bookmap/person &#34; xtrc=&#34;person:1;15:21&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DDB&lt;/person&gt; &lt;printlocation class=&#34;- topic/data bookmap/printlocation &#34; xtrc=&#34;printlocation:1;16:28&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;N/A&lt;/printlocation&gt; &lt;published class=&#34;- topic/data bookmap/published &#34; xtrc=&#34;published:1;17:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt; &lt;person class=&#34;- topic/data bookmap/person &#34; xtrc=&#34;person:2;18:25&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DDB&lt;/person&gt; &lt;publishtype class=&#34;- topic/data bookmap/publishtype &#34; value=&#34;HTML&#34; xtrc=&#34;publishtype:1;19:44&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;revisionid class=&#34;- topic/ph bookmap/revisionid &#34; xtrc=&#34;revisionid:1;20:29&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;200&lt;/revisionid&gt; &lt;summary class=&#34;- topic/ph bookmap/summary &#34; xtrc=&#34;summary:1;22:27&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;data class=&#34;- topic/data &#34; xtrc=&#34;data:1;23:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;/published&gt; &lt;data class=&#34;- topic/data &#34; xtrc=&#34;data:2;25:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;/publisherinformation&gt;&lt;metadata class=&#34;- topic/metadata &#34;&gt;&lt;audience class=&#34;- topic/audience &#34; xtrc=&#34;audience:2;39:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt;&lt;audience class=&#34;- topic/audience &#34; xtrc=&#34;audience:1;28:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt;&lt;category class=&#34;- topic/category &#34; xtrc=&#34;category:1;29:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt;&lt;prodinfo class=&#34;- topic/prodinfo &#34; xtrc=&#34;prodinfo:1;34:23&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt; &lt;prodname class=&#34;- topic/prodname &#34; xtrc=&#34;prodname:1;35:27&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DolphinDB&lt;/prodname&gt; &lt;brand class=&#34;- topic/brand &#34; xtrc=&#34;brand:1;36:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DolphinDB&lt;/brand&gt; &lt;/prodinfo&gt;&lt;/metadata&gt;&lt;/prolog&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:1;1:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:1;3:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;实时流处理是指将业务系统产生的持续增长的动态数据进行实时的收集、清洗、统计、入库，并对结果进行实时的展示。在金融交易、物联网、互联网/移动互联网等应用场景中，复杂的业务需求对大数据处理的实时性提出了极高的要求。面向静态数据表的传统计算引擎无法胜任流数据领域的分析和计算任务。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:2;5:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;DolphinDB内置的流数据框架支持流数据的发布、订阅、预处理、实时内存计算、复杂指标的滚动窗口计算、实时关联、异常数据检测等，是一个运行高效，使用便捷的流数据处理框架。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:3;7:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;与其它流数据系统相比，DolphinDB流数据处理系统的优点在于：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:1;9:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:1;9:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;吞吐量大，低延迟，高可用。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:2;10:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;与DolphinDB时序数据库无缝集成，提供一站式解决方案。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:3;11:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;天然具备流数据表对偶性，支持使用SQL语句进行数据注入和查询分析。&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:4;13:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;DolphinDB流数据处理系统提供了多种方便的功能，例如：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:2;15:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:4;15:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;内置流数据时间序列、横截面、异常检测、响应式状态、连接引擎&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:5;16:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;高频数据回放&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:6;17:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;流数据过滤&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;related-links class=&#34;- topic/related-links &#34;&gt;&lt;linkpool class=&#34;- topic/linkpool &#34; xtrc=&#34;topicref:57;83:43&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/chap_tutorials.ditamap&#34;&gt;&lt;link class=&#34;- topic/link &#34; format=&#34;dita&#34; href=&#34;../tutorials/about_tutorials.dita&#34; mapclass=&#34;- map/topicref bookmap/chapter &#34; role=&#34;parent&#34; scope=&#34;local&#34; type=&#34;topic&#34; xtrc=&#34;topicref:1;5:53&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/chap_tutorials.ditamap&#34;&gt;&lt;?ditaot usertext?&gt;&lt;linktext class=&#34;- topic/linktext &#34;&gt;&lt;?ditaot usertext?&gt;教程&lt;/linktext&gt;&lt;?ditaot usershortdesc?&gt;&lt;desc class=&#34;- topic/desc &#34;&gt;DolphinDB 产品使用教程&lt;/desc&gt;&lt;/link&gt;&lt;/linkpool&gt;&lt;/related-links&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;1-流程图及相关概念&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:2;19:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:2;19:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;1. 流程图及相关概念&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:2;19:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:5;21:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;DolphinDB流数据模块采用发布-订阅-消费的模式。流数据首先注入流数据表中，通过流数据表来发布数据，数据节点或者第三方的应用可以通过DolphinDB脚本或API来订阅及消费流数据。&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/streaming_frame.png&#34; placement=&#34;break&#34; xtrc=&#34;image:1;23:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;791&#34; dita-ot:image-height=&#34;408&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:6;25:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;上图展示了DolphinDB的流数据处理框架。把实时数据注入到发布节点流数据表后，发布的数据可同时供多方订阅消费：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:3;27:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:7;27:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;可由数据仓库订阅并保存，作为分析系统与报表系统的数据源。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:8;28:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;可由流数据计算引擎订阅，进行计算，并将结果输出到流数据表。计算结果既可以由Grafana等平台进行实时展示，也可以作为数据源再次发布，供二次订阅做事件处理。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:9;29:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;可由API订阅，例如第三方的Java应用程序可以通过Java API订阅流数据进行业务操作。&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;11-流数据表&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:3;31:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:3;31:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;1.1. 流数据表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:3;31:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:7;33:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;流数据表是一种特殊的内存表，用以存储及发布流数据。与普通内存表不同，流数据表支持同时读写，且只能添加记录，不可修改或删除记录。数据源发布一条消息等价于向流数据表插入一条记录。与普通内存表相同，可使用SQL语句对流数据表进行查询和分析。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;12-发布与订阅&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:4;35:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:4;35:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;1.2. 发布与订阅&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:4;35:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:8;37:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;采用经典的发布订阅模式。每当有新的流数据注入负责发布消息的流数据表时，会通知所有的订阅方处理新的流数据。数据节点使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:1;37:59&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable&lt;/codeph&gt;函数来订阅流数据。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;13-流数据计算引擎&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:5;39:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:5;39:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;1.3. 流数据计算引擎&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:5;39:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:9;41:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;流数据计算引擎是专门用于处理流数据实时计算和分析的模块。DolphinDB提供&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:2;41:40&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createTimeSeriesEngine&lt;/codeph&gt;,&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:3;41:65&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createDailyTimeSeriesEngine&lt;/codeph&gt;,&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:4;41:95&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createSessionWindowEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:5;41:124&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createAnomalyDetectionEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:6;41:156&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createReactiveStateEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:7;41:185&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createCrossSectionalEngine &lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:8;41:216&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createAsofJoinEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:9;41:240&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createEquiJoinEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:10;41:264&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createWindowJoinEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:11;41:290&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createLookupJoinEngine&lt;/codeph&gt;等函数创建流数据计算引擎对流数据进行实时计算，并将计算结果持续输出到指定的数据表中。&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:4;43:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:10;43:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;注：自 1.30.21/2.00.9 版本起，&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:12;43:26&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createEqualJoinEngine&lt;/codeph&gt; 更名为 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:13;43:54&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createEquiJoinEngine&lt;/codeph&gt;，原函数名可继续使用。*&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;2-核心功能&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:6;45:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:6;45:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;2. 核心功能&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:6;45:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:10;47:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;要开启支持流数据功能的模块，必须对发布节点指定 &lt;i class=&#34;+ topic/ph hi-d/i &#34; xtrc=&#34;i:1;47:25&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;maxPubConnections&lt;/i&gt; 配置参数，并对订阅节点指定 &lt;i class=&#34;+ topic/ph hi-d/i &#34; xtrc=&#34;i:2;47:59&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subPort&lt;/i&gt; 配置参数。以下为所有流数据相关配置参数。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:11;49:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;发布节点的配置参数：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:5;51:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:11;51:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;maxPubConnections: 发布节点可以连接的订阅节点数量上限，默认值为0。只有指定maxPubConnections为正整数后，该节点才可作为发布节点。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:12;52:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;persistenceDir: 保存发布消息的流数据表的文件夹路径。若需要保存流数据表，必须指定该参数。所有生产环境中都强烈推荐设定此参数。若不设定此参数，随着消息的积累，内存会最终耗尽。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:13;53:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;persistenceWorkerNum: 负责以异步模式保存流数据表的工作线程数。默认值为0。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:14;54:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;maxPersistenceQueueDepth: 以异步模式保存流数据表时消息队列的最大深度（记录数量）。默认值为10,000,000。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:15;55:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;maxMsgNumPerBlock: 发布消息时，每个消息块中最多可容纳的记录数量。默认值为1024。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:16;56:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;maxPubQueueDepthPerSite: 发布节点消息队列的最大深度（记录数量）。默认值为10,000,000。&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:12;58:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅节点的配置参数：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:6;60:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:17;60:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subPort: 订阅线程监听的端口号，默认值为0。只有指定该参数后，该节点才可作为订阅节点。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:18;61:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subExecutors: 订阅节点中消息处理线程的数量。默认值为0，表示解析消息线程也处理消息。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:19;62:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;maxSubConnections: 该订阅节点可以连接的的发布节点数量上限。默认值为64。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:20;63:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subExecutorPooling: 表示执行流计算的线程是否处于pooling模式的布尔值。默认值是false。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:21;64:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;maxSubQueueDepth: 订阅节点消息队列的最大深度（记录数量）。默认值为10,000,000。&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;21-流数据发布&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:7;66:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:7;66:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;2.1. 流数据发布&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:7;66:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:13;68:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:14;68:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;streamTable&lt;/codeph&gt;函数定义一个流数据表。实时数据写入该表后，向所有订阅端发布。由于通常有多个会话中的多个订阅端订阅同一个发布端，所以必须使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:15;68:77&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share&lt;/codeph&gt;函数将流数据表在所有会话中共享后才可发布流数据。未被共享的流数据表无法发布流数据。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:14;70:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;定义并共享流数据表pubTable：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:1;72:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:15;76:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:16;76:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;streamTable&lt;/codeph&gt;函数创建的流数据表是可以包含重复记录的。如果要创建包含主键的流数据表，可以使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:17;76:53&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;keyedStreamTable&lt;/codeph&gt;函数。包含主键的流数据表中，一旦写入某键值的数据，后续相同键值的数据不会写入此流数据表，将被丢弃。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:2;78:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share keyedStreamTable(`timestamp, 10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:16;82:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;可以用undef函数或者dropStreamTable删除上述语句创建的共享流数据表pubTable：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:3;84:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;undef(`pubTable, SHARED) dropStreamTable(`pubTable)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:17;89:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;undef函数能够将变量或者函数定义从内存中释放。但是，若要删除2.6节的持久化流数据表，则必须使用dropStreamTable函数。此外，用户需要在取消所有订阅后才能删除相应的流数据表，取消订阅请参考&lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;markdown&#34; format=&#34;dita&#34; href=&#34;#取消订阅&#34; xtrc=&#34;xref:1;89:103&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;?ditaot usertext?&gt;取消订阅&lt;/xref&gt;。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;22-流数据订阅&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:8;91:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:8;91:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;2.2. 流数据订阅&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:8;91:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:18;93:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅流数据通过 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:18;93:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable&lt;/codeph&gt; 函数来实现。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:4;95:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable([server],tableName,[actionName],[offset=-1],handler,[msgAsTable=false],[batchSize=0],[throttle=1],[hash=-1],[reconnect=false],[filter],[persistOffset=false],[timeTrigger=false],[handlerNeedMsgId=false],[raftGroup],[userId=&#34;&#34;],[password=&#34;&#34;])&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:19;99:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;参数说明：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:7;101:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:22;101:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:20;101:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;只有tableName和handler两个参数是必需的，其它所有参数均为可选参数。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:23;103:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:21;103:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;server 为字符串，表示流数据所在服务器的别名或远程连接handle。如果未指定或者为空字符串，表示流数据所在服务器是本地实例。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:22;105:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;实际情况中，发布者与订阅者所在节点的关系有以下三种可能。这三种情况下的server参数设置分别为：&lt;/p&gt;&lt;ol class=&#34;- topic/ol &#34; xtrc=&#34;ol:1;107:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:24;107:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:23;107:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;发布者与订阅者是同一节点，均为本地实例：参数server不设置或使用空字符串。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:5;109:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;, offset=0, handler=subTable, msgAsTable=true)&lt;/codeblock&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:25;113:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:24;113:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;发布者与订阅者是同一集群内的不同节点：参数server使用发布节点别名。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:6;115:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable(server=&#34;NODE2&#34;, tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;, offset=0, handler=subTable, msgAsTable=true)&lt;/codeblock&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:26;119:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:25;119:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;发布者与订阅者不在同一个集群内：参数server使用发布节点的远程连接handle。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:7;121:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;pubNodeHandler=xdb(&#34;192.168.1.13&#34;,8891) subscribeTable(server=pubNodeHandler, tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;, offset=0, handler=subTable, msgAsTable=true)&lt;/codeblock&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:8;126:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:27;126:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:26;126:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;tableName：被订阅的流数据表名。该表必须为共享的流数据表。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:8;128:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;, offset=0, handler=subTable, msgAsTable=true)&lt;/codeblock&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:28;132:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:27;132:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;actionName：一个字符串，表示订阅任务的名称。同一份流数据可以被多项任务订阅消费，既可用于实时运算，亦可存储到数据仓库供第三方应用做批处理。如果一个节点有多个订阅均订阅了同一张表，必须指定actionName。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:9;133:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;topic1 = subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;realtimeAnalytics&#34;, offset=0, handler=subTable, msgAsTable=true) topic2 = subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;saveToDataWarehouse&#34;, offset=0, handler=subTable, msgAsTable=true)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:28;137:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:19;137:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable&lt;/codeph&gt;函数的返回值是订阅主题，它是订阅表所在节点的别名、流数据表名称和订阅任务名称（如果指定了actionName）的组合，使用&#34;/&#34;分隔。若当前节点别名为NODE1，上述例子返回的两个topic内容如下:&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:29;139:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;topic1:&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:10;140:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;NODE1/pubTable/realtimeAnalytics&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:30;143:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;topic2:&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:11;144:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;NODE1/pubTable/saveToDataWarehouse&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:31;147:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;如果订阅主题已经存在，将抛出异常。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:29;149:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:32;149:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;offset：订阅任务从流数据表的哪一行开始。如果未指定或设为-1，订阅将会从未来的新数据开始。如果offset=-2，系统会自动获取持久化到磁盘上的offset，并从该位置开始订阅。offset的值永远与流数据表创建时的第一行对应。如果某些行因为内存限制被删除，在决定订阅开始的位置时，这些行仍然考虑在内。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:33;151:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;下例说明offset的作用。向pubTable写入100行数据，建立两个订阅：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:12;153:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable1 share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable2 vtimestamp = 1..100 vtemp = norm(2,0.4,100) tableInsert(pubTable,vtimestamp,vtemp) topic1 = subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;, offset=-1, handler=subTable1, msgAsTable=true) topic2 = subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act2&#34;, offset=50, handler=subTable2, msgAsTable=true)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:34;164:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;从结果可以看到，subTable1没有数据，而subTable2有50条数据。当offset为-1时，只有当新数据进入发布表时才能订阅到数据。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:30;166:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:35;166:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;handler：一元函数或数据表。若为函数，用于处理订阅数据，其唯一的参数是订阅的数据。订阅的数据可以以数据表或元组（订阅数据表的每个列是元组的一个元素）的形式注入handler。由于经常需要把订阅数据插入到数据表，为了方便使用，handler也可以是一个数据表，订阅数据直接插入到该表中。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:36;168:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;下例展示handler的两种用法。在act1订阅中，直接把订阅数据写入subTable1；在act2订阅中，订阅数据通过自定义函数&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:20;168:74&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;myHandler&lt;/codeph&gt;进行过滤后写入subTable2。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:13;170:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;def myhandler(msg){ t = select * from msg where temperature&amp;gt;0.2 if(size(t)&amp;gt;0) subTable2.append!(t) } share streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable1 share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable2 topic1 = subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;, offset=-1, handler=subTable1, msgAsTable=true) topic2 = subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act2&#34;, offset=-1, handler=myhandler, msgAsTable=true) vtimestamp = 1..10 vtemp = 2.0 2.2 2.3 2.4 2.5 2.6 2.7 0.13 0.23 2.9 tableInsert(pubTable,vtimestamp,vtemp)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:37;187:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;从结果可以看到写入pubTable10条数据，subTable1全部接收了；而subTable2接收到9条数据，因为&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:21;187:67&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;myhandler&lt;/codeph&gt;过滤掉了vtemp = 0.13这一条数据。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:31;189:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:38;189:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;msgAsTable：布尔值，表示订阅的数据以何种形式进入handler。若设为true，表示订阅的数据以table的形式注入handler，可使用SQL语句处理。默认值是false，表示订阅的数据是由列组成的元组。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:14;191:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;def myhandler1(table){ subTable1.append!(table) } def myhandler2(tuple){ tableInsert(subTable2,tuple[0],tuple[1]) } share streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable1 share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable2 topic1 = subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;, offset=-1, handler=myhandler1, msgAsTable=true) topic2 = subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act2&#34;, offset=-1, handler=myhandler2, msgAsTable=false) vtimestamp = 1..10 vtemp = 2.0 2.2 2.3 2.4 2.5 2.6 2.7 0.13 0.23 2.9 tableInsert(pubTable,vtimestamp,vtemp)&lt;/codeblock&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:32;210:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:39;210:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;batchSize：一个整数。若为正数，表示未处理消息的数量达到batchSize时，handler才会处理消息。若未指定或为非正数，每一批次的消息到达之后，handler就会马上处理。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:40;212:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;下例中，batchSize设置为11。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:15;214:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable1 topic1 = subscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;, offset=-1, handler=subTable1, msgAsTable=true, batchSize=11) vtimestamp = 1..10 vtemp = 2.0 2.2 2.3 2.4 2.5 2.6 2.7 0.13 0.23 2.9 tableInsert(pubTable,vtimestamp,vtemp) print size(subTable1)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:41;225:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;先向pubTable写入10条数据，订阅表subTable1此时为空。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:16;227:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;insert into pubTable values(11,3.1) print size(subTable1)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:42;232:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;接着向pubTable写入1条数据。订阅表subTable1此时有11条数据。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:33;234:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:43;234:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;throttle：一个浮点数，表示继上次handler处理消息之后，若batchSize条件一直未达到，多久后再次处理消息。以秒为单位，默认值为1。如果没有指定batchSize，throttle即使指定，也不起作用。若throttle小于配置参数subThrottle/1000，throttle的效果等同于其被指定为subThrottle/1000。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:44;236:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;handler处理一条数据与批量处理多条（例如1000条）数据的耗时差别很小。若每一条数据注入handler时都要处理一次，在写入速度极高的情况下有可能导致数据消费能力慢于数据写入速度，不仅不能及时处理所有数据，而且会造成数据不断堆积在订阅端缓冲区而耗光内存。合理设置batchSize与throttle参数，可通过调整handler处理消息的频率，以提升吞吐量。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:34;238:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:45;238:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;hash：一个非负整数，指定某个订阅线程处理消息。如果没有指定该参数，系统会自动分配一个线程，优先分配没有订阅的线程。若需要在多个订阅的处理过程中保持消息数据的同步，可以将多个订阅的hash值设置为相同，这样就能使用同一个线程来同步处理多个数据源，不会出现数据处理有先后而导致结果误差。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:35;240:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:46;240:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;reconnect是一个布尔值。默认值为false，表示如果网络异常等问题导致订阅中断，订阅端不会自动重新订阅；如果设为true，订阅端会在网络恢复正常时，自动从中断位置重新订阅。如果发布端崩溃或关闭导致订阅中断，那么订阅端会不断尝试重新订阅，直到能够重新与发布端建立连接。若发布端对流数据表启用了持久化，那么发布端重启后会首先读取硬盘上持久化的数据，直到发布端读取到订阅中断位置的数据，订阅端才能成功重新订阅。若发布端没有对流数据表启用持久化，那么重新订阅将会失败。订阅端不保存订阅信息，如果订阅端崩溃或关闭导致订阅中断，即使设置了reconnect=true，订阅端重启后也无法自动重新订阅。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:36;242:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:47;242:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;filter 参数需要配合&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:22;242:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;setStreamTableFilterColumn&lt;/codeph&gt;函数一起使用。使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:23;242:57&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;setStreamTableFilterColumn&lt;/codeph&gt;指定流数据表的过滤列，流数据表过滤列在filter中的数据才会发布到订阅端，不在filter中的数据不会发布。filter不支持过滤BOOL类型数据。filter 参数可以使用以下三种方法指定。其中范围过滤与哈希过滤于1.30.3版本发布。&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:9;244:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:37;244:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;值过滤：一个向量。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:38;245:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;范围过滤：一个数据对。范围包含下限值，但不包括上限值。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:39;246:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;哈希过滤：一个元组。第一个元素表示bucket的个数；第二个元素是一个标量或数据对，其中标量表示bucket的索引（从0开始），数据对表示bucket的索引范围（包含下限值，但不包括上限值）。&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:40;247:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:48;247:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;persistOffset是一个布尔值，表示是否持久化保存本次订阅已经处理的数据的偏移量，默认值为false。持久化保存的偏移量用于重订阅，可通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:24;247:80&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getTopicProcessedOffset&lt;/codeph&gt;函数获取。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:41;248:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:49;248:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;timeTrigger是一个布尔值。若设为true，表示即使没有新的消息进入，handler也会在throttle参数所设定的时间间隔被触发。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:42;249:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:50;249:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;handlerNeedMsgId是一个布尔值，默认值为false。若设为true，handler必须支持两个参数：一个是msgBody，一个是msgId。调用handler时，传入消息以及消息的偏移量。一个例子为函数&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:25;249:115&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;appendMsg&lt;/codeph&gt;。若设为false，handler仅支持一个参数：msgBody。调用handler时，只传入消息本身。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:43;250:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:51;250:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;raftGroup是 raft 组的 ID。设置该参数表示开启订阅端高可用，不设置则表示普通订阅。设置 &lt;i class=&#34;+ topic/ph hi-d/i &#34; xtrc=&#34;i:3;250:59&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;raftGroup&lt;/i&gt; 参数以指定 raft 组后，在对应 raft 组内 leader 发生切换时，新的 leader会 重新订阅。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;23-断线重连&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:9;252:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:9;252:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;2.3. 断线重连&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:9;252:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:52;254:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;DolphinDB的流数据订阅提供了自动重连的功能。如果要启用自动重连，发布端必须对流数据持久化。当reconnect参数设为true时，订阅端会记录流数据的offset，连接中断时订阅端会从offset开始重新订阅。如果订阅端关闭或者发布端没有对流数据持久化，订阅端无法自动重连。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;24-发布端数据过滤&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:10;256:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:10;256:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;2.4. 发布端数据过滤&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:10;256:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:53;258:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;发布端可以过滤数据，只发布符合条件的数据。使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:26;258:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;setStreamTableFilterColumn&lt;/codeph&gt;指定流数据表的过滤列（目前仅支持对一个列进行过滤），过滤列的值在filter中的数据会发布到订阅端，不在filter指定值中的数据不会发布。有关filter参数的介绍请见2.2小节。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:54;260:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;下例中，值过滤的filter值是一个向量。发布端上的流数据表trades只发布symbol为IBM或GOOG的数据：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:17;262:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share streamTable(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT]) as trades setStreamTableFilterColumn(trades, `symbol) trades_1=table(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT]) filter=symbol(`IBM`GOOG) subscribeTable(tableName=&#34;trades&#34;, actionName=&#34;trades_1&#34;, handler=append!{trades_1}, msgAsTable=true, filter=filter)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:55;272:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;范围过滤的filter值是一个数据对。发布端上的流数据表trades只发布price大于等于1且小于100的数据：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:18;274:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share streamTable(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT]) as trades setStreamTableFilterColumn(trades, `price) trades_1=table(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT]) subscribeTable(tableName=&#34;trades&#34;, actionName=&#34;trades_1&#34;, handler=append!{trades_1}, msgAsTable=true, filter=1:100)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:56;282:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;哈希过滤的filter值是一个元组。发布端上的流数据表trades对于symbol列使用哈希函数分为10个bucket，bucket索引从0开始，只发布索引大于等于1且小于5的数据：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:19;284:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share streamTable(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT]) as trades setStreamTableFilterColumn(trades, `symbol) trades_1=table(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT]) subscribeTable(tableName=&#34;trades&#34;, actionName=&#34;trades_1&#34;, handler=append!{trades_1}, msgAsTable=true, filter=(10,1:5))&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;25-取消订阅&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:11;292:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:11;292:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;2.5. 取消订阅&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:11;292:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:57;294:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;每一次订阅都由一个订阅主题topic作为唯一标识。如果订阅时topic已存在，那么会订阅失败，需要通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:27;294:52&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;unsubscribeTable&lt;/codeph&gt;函数取消订阅才能再次订阅。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:58;296:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;取消订阅示例如下：&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:59;298:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;取消订阅一个本地表：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:20;300:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;unsubscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:60;304:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;取消订阅一个远程表：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:21;306:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;unsubscribeTable(server=&#34;NODE_1&#34;, tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:61;310:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;取消订阅一个本地表，但保留offset，以便下次从这个offset继续订阅：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:22;312:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;unsubscribeTable(tableName=&#34;pubTable&#34;, actionName=&#34;act1&#34;, removeOffset=false)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:62;316:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;从节点的内存中删除给定topic的offset：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:23;318:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;removeTopicOffset(topic)&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;26-流数据持久化&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:12;322:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:12;322:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;2.6. 流数据持久化&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:12;322:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:63;324:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;默认情况下，流数据表把所有数据保存在内存中。基于以下三点考量，可将流数据持久化到磁盘。&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:10;326:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:44;326:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;流数据的备份和恢复。当节点出现异常重启时，持久化的数据会在重启时自动载入到流数据表。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:45;327:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;避免内存不足。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:46;328:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;可以从任意位置开始重新订阅数据。&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:64;330:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;可事先设定一个界限值。若流数据表的行数达到设定的界限值，前面一半的记录行会持久化到磁盘。持久化的数据支持重订阅，当订阅指定offset时，offset的计算包含持久化的数据。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:65;332:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;要持久化流数据表，在发布节点首先需要设置持久化路径参数persistenceDir:&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:24;334:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;persistenceDir = /da&#34;data_replay.md&#34;nableTableShareAndPersistence` 函数。下面的示例将pubTable共享为sharedPubTable，并把sharedPubTable持久化到磁盘。其中参数cacheSize=1000000，asynWrite与compress默认值均为true，表示当流数据表数据量达到100万行时启用持久化，将其中50%的数据采用异步方式压缩保存到磁盘。 &lt;/codeblock&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:25;338:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;pubTable=streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) enableTableShareAndPersistence(table=pubTable, tableName=`sharedPubTable, cacheSize=1000000, preCache=500000)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:66;343:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;若执行&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:28;343:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;enableTableShareAndPersistence&lt;/codeph&gt;时，磁盘上已经存在sharedPubTable表的持久化数据，那么系统会加载最新的preCache=500000行记录到内存中。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:67;345:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;对于持久化是否启用异步，需要在持久化数据一致性和性能之间作权衡。当流数据的一致性要求较高时，可以使用同步方式，这样可以保证持久化完成以后，数据才会进入发布队列；若对实时性要求较高，不希望磁盘IO影响到流数据的实时性，则可启用异步方式。只有启用异步方式时，持久化工作线程数persistenceWorkerNum配置项才会起作用。若有多个发布表需要持久化，增加persistenceWorkerNum的配置值可以提升异步保存的效率。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:68;347:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当不需要保存在磁盘上的流数据时，通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:29;347:19&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;clearTablePersistence&lt;/codeph&gt;函数可以删除持久化数据：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:26;349:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;clearTablePersistence(pubTable)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:69;353:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;关闭持久化，可以使用 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:30;353:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;disableTablePersistence&lt;/codeph&gt; 函数：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:27;355:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;disableTablePersistence(pubTable)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:70;359:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:31;359:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getPersistenceMeta&lt;/codeph&gt;函数获取流数据表的持久化细节情况：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:28;361:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getPersistenceMeta(pubTable);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:71;365:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;输出的结果是一个字典，有以下内容：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:29;367:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;//内存中的数据记录数 sizeInMemory-&amp;gt;0 //启用异步持久化 asynWrite-&amp;gt;true //流数据表总记录数 totalSize-&amp;gt;0 //启用压缩存储 compress-&amp;gt;true //当前内存中数据相对总记录数的偏移量，在持久化运行过程中遵循公式 memoryOffset = totalSize - sizeInMemory memoryOffset-&amp;gt;0 //已经持久化到磁盘的数据记录数 sizeOnDisk-&amp;gt;0 //日志文件的保留时间，默认值是1440分钟，即一天。 retentionMinutes-&amp;gt;1440 //持久化路径 persistenceDir-&amp;gt;/hdd/persistencePath/pubTable //hashValue是对本表做持久化的工作线程标识。 hashValue-&amp;gt;0 //磁盘上第一条数据相对总记录数的偏移量。例如，若diskOffset=10000，表示目前磁盘上的持久化流数据从第10000条记录开始。 diskOffset-&amp;gt;0&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:72;390:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;调用dropStreamTable函数删除持久化流数据表，内存中和磁盘上的流数据均会被清除：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:30;392:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;dropStreamTable(`pubTable);&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;3-数据回放&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:13;396:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:13;396:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;3. 数据回放&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:13;396:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:73;398:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;DolphinDB提供了&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:32;398:13&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;replay&lt;/codeph&gt;函数，可以将历史数据按照时间顺序导入流数据表中。具体教程请参考&lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;data_replay.md&#34; xtrc=&#34;xref:2;398:52&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;流数据回放教程&lt;/xref&gt;。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;4-流数据计算引擎&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:14;400:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:14;400:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;4. 流数据计算引擎&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:14;400:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:74;402:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;DolphinDB提供&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:33;402:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createTimeSeriesEngine&lt;/codeph&gt;,&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:34;402:37&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createDailyTimeSeriesEngine&lt;/codeph&gt;,&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:35;402:67&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createSessionWindowEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:36;402:96&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createAnomalyDetectionEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:37;402:128&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createReactiveStateEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:38;402:157&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createCrossSectionalEngine &lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:39;402:188&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createAsofJoinEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:40;402:212&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createEquiJoinEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:41;402:236&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createWindowJoinEngine&lt;/codeph&gt;, &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:42;402:262&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createLookupJoinEngine&lt;/codeph&gt;等函数创建流数据计算引擎对流数据进行实时计算。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:75;404:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;创建响应式状态引擎：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:31;406:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;rse = createReactiveStateEngine(name=&#34;reactiveDemo&#34;, metrics =&amp;lt;cumsum(price)&amp;gt;, dummyTable=tickStream, outputTable=result, keyColumn=&#34;sym&#34;, snapshotDir= &#34;/home/data/snapshot&#34;, snapshotIntervalInMsgCount=20000)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:76;410:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;调用dropStreamEngine函数释放流数据引擎：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:32;412:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;dropStreamEngine(&#34;reactiveDemo&#34;)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:77;416:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;此外，DolphinDB流计算引擎还包括流水线处理、并行处理、快照机制等重要特性。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:78;418:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:1;418:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;注意&lt;/b&gt;：DolphinDB 1.30.21/2.00.9 及之前的版本不支持对流计算引擎的并发访问（例如，两个输入表并发写入同一引擎）。 如需使用此功能，要求 server 版本号必须高于 1.30.21/2.00.9，且必须使用 share 语句/函数共享引擎，例如 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:43;418:139&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share(engine, name)&lt;/codeph&gt; 或 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:44;418:163&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share engien as name&lt;/codeph&gt;（要求引擎共享后的名称和引擎名称相同）。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;41-流水线处理&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:15;420:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:15;420:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;4.1. 流水线处理&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:15;420:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:79;422:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;DolphinDB内置的流计算引擎均实现了数据表（table）的接口，因此多个引擎流水线处理变得异常简单，只要将后一个引擎作为前一个引擎的输出即可。引入流水线处理，可以解决更为复杂的因子计算问题。譬如，因子计算经常需要使用面板数据，完成时间序列和横截面两个维度的计算，只要把响应式状态引擎和横截面两个引擎串联处理即可完成。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:80;424:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;下面的例子是World Quant 101个Alpha因子中的1号因子公式的流数据实现。rank函数是一个横截面操作。rank的参数部分用响应式状态引擎实现。rank函数本身用横截面引擎实现。横截面引擎作为状态引擎的输出。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:33;426:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;Alpha#001公式：rank(Ts_ArgMax(SignedPower((returns&amp;lt;0?stddev(returns,20):close), 2), 5))-0.5 //创建横截面引擎，计算每个股票的rank dummy = table(1:0, `sym`time`maxIndex, [SYMBOL, TIMESTAMP, DOUBLE]) resultTable = streamTable(10000:0, `time`sym`factor1, [TIMESTAMP, SYMBOL, DOUBLE]) ccsRank = createCrossSectionalAggregator(name=&#34;alpha1CCS&#34;, metrics=&amp;lt;[sym, rank(maxIndex, percent=true) - 0.5]&amp;gt;, dummyTable=dummy, outputTable=resultTable, keyColumn=`sym, triggeringPattern='keyCount', triggeringInterval=3000, timeColumn=`time, useSystemTime=false) @state def wqAlpha1TS(close){ ret = ratios(close) - 1 v = iif(ret &amp;lt; 0, mstd(ret, 20), close) return mimax(signum(v)*v*v, 5) } //创建响应式状态引擎，输出到前面的横截面引擎ccsRank input = table(1:0, `sym`time`close, [SYMBOL, TIMESTAMP, DOUBLE]) rse = createReactiveStateEngine(name=&#34;alpha1&#34;, metrics=&amp;lt;[time, wqAlpha1TS(close)]&amp;gt;, dummyTable=input, outputTable=ccsRank, keyColumn=&#34;sym&#34;)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:81;446:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;流水线处理（也称为引擎多级级联）和多个流数据表的级联处理有很大的区别。两者可以完成相同的任务，但是效率上有很大的区别。后者涉及多个流数据表与多次订阅。前者实际上只有一次订阅，所有的计算均在一个线程中依次顺序完成，因而有更好的性能。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:82;448:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;上面的例子是由用户来区分哪一部分是横截面操作，哪一部分是时间序列操作以实现多个引擎的流水线。在1.30.16/2.00.4及之后的版本中，新增函数 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:45;448:75&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;streamEngineParser&lt;/codeph&gt;，支持将metrics自动分解成多个内置流计算引擎的流水线。在&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:46;448:126&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;streamEngineParser&lt;/codeph&gt;中以行函数（rowRank，rowSum等）表示横截面操作的语义，以rolling函数表示时间序列操作，从而系统能够自动识别一个因子中的横截面操作和时间序列操作，进一步自动构建引擎流水线。因此，上述因子可以用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:47;448:250&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;streamEngineParser&lt;/codeph&gt;更简洁的实现，metrics几乎等同于因子的数学公式表达，而不需要考虑不同类型引擎的选择：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:34;450:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;@state def wqAlpha1TS(close){ ret = ratios(close) - 1 v = iif(ret &amp;lt; 0, mstd(ret, 20), close) return mimax(signum(v)*v*v, 5) } //构建计算因子 metrics=&amp;lt;[sym, rowRank(wqAlpha1TS(close), percent=true)- 0.5]&amp;gt; streamEngine=streamEngineParser(name=`alpha1_parser, metrics=metrics, dummyTable=input, outputTable=resultTable, keyColumn=`sym, timeColumn=`time, triggeringPattern='keyCount', triggeringInterval=3000)&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;42-并行处理&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:16;464:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:16;464:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;4.2. 并行处理&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:16;464:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:83;466:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当需要处理大量消息时，可在DolphinDB消息订阅函数&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:48;466:29&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable&lt;/codeph&gt;中指定可选参数filter与hash，让多个订阅客户端并行处理消息。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:84;468:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;下面是响应式状态引擎并行计算因子的例子。假设配置参数subExecutors=4，创建4个状态引擎，每个状态引擎根据流表的股票代码的哈希值来订阅不同股票的数据，并且指定不同的订阅线程来处理，最终将结果输出到同一个输出表中。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:35;470:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share streamTable(1:0, `sym`price, [STRING,DOUBLE]) as tickStream setStreamTableFilterColumn(tickStream, `sym) share streamTable(1000:0, `sym`factor1, [STRING,DOUBLE]) as resultStream for(i in 0..3){ rse = createReactiveStateEngine(name=&#34;reactiveDemo&#34;+string(i), metrics =&amp;lt;cumsum(price)&amp;gt;, dummyTable=tickStream, outputTable=resultStream, keyColumn=&#34;sym&#34;) subscribeTable(tableName=`tickStream, actionName=&#34;sub&#34;+string(i), handler=tableInsert{rse}, msgAsTable = true, hash = i, filter = (4,i)) }&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:85;481:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;需要注意的是，如果多个状态引擎是同一个输出表，该输出表必须是一个共享表。没有共享的表不是线程安全的，并行写入可能会导致系统崩溃。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;43-快照机制&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:17;483:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:17;483:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;4.3. 快照机制&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:17;483:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:86;485:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;为了满足生产环境业务持续性的需要，DolphinDB内置的流式计算引擎除连接引擎外均支持快照（snapshot）输出。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:87;487:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;以响应式状态引擎为例，该引擎的快照包括已处理的最后一条消息的ID以及引擎当前的状态（中间计算结果）。当系统出现异常，重新初始化状态引擎时，可恢复到最后一个快照的状态，并且从已处理的消息的下一条开始订阅。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:36;489:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share streamTable(1:0, `sym`price, [STRING,DOUBLE]) as tickStream result = table(1000:0, `sym`factor1, [STRING,DOUBLE]) rse = createReactiveStateEngine(name=&#34;reactiveDemo&#34;, metrics =&amp;lt;cumsum(price)&amp;gt;, dummyTable=tickStream, outputTable=result, keyColumn=&#34;sym&#34;, snapshotDir= &#34;/home/data/snapshot&#34;, snapshotIntervalInMsgCount=20000) msgId = getSnapshotMsgId(rse) if(msgId &amp;gt;= 0) msgId += 1 subscribeTable(tableName=`tickStream, actionName=&#34;factors&#34;, offset=msgId, handler=appendMsg{rse}, handlerNeedMsgId=true)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:88;498:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;响应式状态引擎要启用快照机制，创建时需要指定两个额外的参数snapshotDir和snapshotIntervalInMsgCount。snapshotDir用于指定存储快照的目录。snapshotIntervalInMsgCount指定处理多少条消息后产生一个快照。引擎初始化时，系统会检查快照目录下是否存在一个以引擎名称命名，后缀为snapshot的文件。以上面的代码为例，如果存在文件/home/data/snapshot/reactiveDemo.snapshot，加载这个快照。函数getSnapshotMsgId可以获取最近一个快照对应的msgId。如果不存在快照，返回-1。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:89;500:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;状态引擎要启用快照机制，调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:49;500:15&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable&lt;/codeph&gt;函数也需相应的修改：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:11;502:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:47;502:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;首先必须指定消息的offset。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:48;503:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;其次，handler必须使用appendMsg函数。appendMsg函数接受两个参数，msgBody和msgId。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:49;504:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;再次，参数handlerNeedMsgId必须指定为true。&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:90;506:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;上例为普通订阅在宕机后重新提交订阅并从快照处恢复流数据处理。在5高可用章节中，通过高可用流订阅自定恢复订阅时将不再需要通过getSnapshotMsgId函数获取msgId来指定offset，也不需要使用appendMsg函数。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;5-高可用&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:18;508:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:18;508:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;5. 高可用&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:18;508:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;51-流数据高可用&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:19;510:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:19;510:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;5.1. 流数据高可用&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:19;510:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:91;512:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;为满足流数据服务不中断的需求，DolphinDB采用了基于Raft协议的高可用多副本架构，以提供流数据的高可用功能。具体教程请参考&lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;haStreaming.md&#34; xtrc=&#34;xref:3;512:66&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;流数据高可用教程&lt;/xref&gt;。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;52-流计算引擎高可用&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:20;514:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:20;514:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;5.2. 流计算引擎高可用&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:20;514:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:92;516:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在流数据和流数据订阅高可用的基础上，DolphinDB还支持了流计算引擎的高可用，以保证实时流处理不中断。若引擎开启高可用，在 leader 节点创建流数据引擎后，会同步在 follower 节点创建该引擎。引擎通过快照机制每次保存的 snapshot 也会同步到 follower。当 leader 节点宕机时，会自动切换新 leader 节点重新订阅流数据表，并且自动根据 snapshot 恢复到最后一个快照的状态并从此处继续实时处理。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:93;518:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;下面的例子中在Raft组2上创建了两个高可用流数据表，创建了一个高可用状态引擎，并提交了高可用流订阅。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:37;520:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;haStreamTable(raftGroup=2, table=table(1:0, `sym`price, [STRING,DOUBLE]), tableName=&#34;haTickStream&#34;, cacheLimit=10000) haStreamTable(raftGroup=2, table=table(1:0, `sym`factor1, [STRING,DOUBLE]), tableName=&#34;result&#34;, cacheLimit=10000) ret = createReactiveStateEngine(name=&#34;haReact&#34;, metrics=&amp;lt;cumsum(price)&amp;gt;, dummyTable=objByName(&#34;haTickStream&#34;), outputTable=objByName(&#34;result&#34;), keyColumn=`sym, snapshotDir= &#34;/home/data/snapshot&#34;, snapshotIntervalInMsgCount=20000, raftGroup=2) subscribeTable(tableName=&#34;haTickStream&#34;, actionName=&#34;haFactors&#34;, offset=-1, handler=getStreamEngine(&#34;haReact&#34;), msgAsTable=true, reconnect=true, persistOffset=true, handlerNeedMsgId=true, raftGroup=2)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:94;528:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:50;528:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;createReactiveStateEngine&lt;/codeph&gt;创建引擎时需要注意：启动引擎高可用必须指定参数 raftGroup ，并且必须同时指定参数 snapshotDir 和 snapshotIntervalInMsgCount 。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:95;530:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在调用调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:51;530:6&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable&lt;/codeph&gt;时提交订阅时需要注意：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:12;532:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:50;532:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:96;532:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;开启订阅端高可用，必须指定参数 raftGroup。若指定了 raftGroup，则只能在 leader 上执行。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:51;533:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:97;533:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;启动计算引擎高可用，必须指定 handlerNeedMsgId 为true。此时， handler 只能是计算引擎，即 handler = engine(创建引擎时返回的句柄变量)或 handler = getStreamEngine(引擎名称)。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:52;535:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:98;535:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅高可用流数据表，需要设置 reconnect 为 true，以保证 leader 发生切换时可以成功连接新的 leader。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:53;536:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:99;536:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅高可用流数据表，需要设置 persistOffset 为 true，以防止订阅端丢失数据。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;6-流数据api&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:21;538:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:21;538:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;6. 流数据API&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:21;538:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:100;540:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;流数据的消费者可能是DolphinDB内置的计算引擎，也可能是第三方的消息队列或者第三方程序。DolphinDB提供了streaming API供第三方程序来订阅流数据。当有新数据注入时，API的订阅者能够及时接收到通知，这使得DolphinDB的流数据框架可与第三方的应用进行深入的整合。DolphinDB的API（Java, Python, C++, C#）提供了接口来订阅流数据。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;61-python-api&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:22;542:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:22;542:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;6.1. Python API&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:22;542:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:101;544:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;Python API提供流数据订阅的相关方法，用于订阅DolphinDB服务端的数据。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;611-python客户端流数据订阅示例&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:23;546:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:23;546:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;6.1.1. Python客户端流数据订阅示例&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:23;546:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:102;548:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;下面简单介绍一下Python API提供的流数据订阅的相关方法与使用示例。&lt;/p&gt;&lt;ol class=&#34;- topic/ol &#34; xtrc=&#34;ol:2;550:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:54;550:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:103;550:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;指定客户端的订阅端口号&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:104;552:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;使用Python API提供的&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:52;552:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;enableStreaming&lt;/codeph&gt;函数启用流数据功能：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:38;554:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;import dolphindb as ddb conn = ddb.session() conn.enableStreaming(8000)&lt;/codeblock&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:55;560:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:105;560:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;调用订阅函数&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:106;562:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;使用Python API提供的&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:53;562:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribe&lt;/codeph&gt;函数来订阅DolphinDB中的流数据表。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:107;564:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;示例：&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:108;566:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在DolphinDB中创建共享的流数据表，并插入一些随机数据：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:39;568:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;share streamTable(1:0,`id`price`qty,[INT,DOUBLE,INT]) as trades trades.append!(table(1..10 as id,rand(10.0,10) as price,rand(10,10) as qty))&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:109;573:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在Python中订阅trades表：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:40;574:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;def printMsg(msg): print(msg) conn.subscribe(&#34;192.168.1.103&#34;, 8941, printMsg, &#34;trades&#34;, &#34;sub_trades&#34;, 0) [1, 0.47664969926699996, 8] [2, 5.543625105638057, 4] [3, 8.10016839299351, 4] [4, 5.821204076055437, 9] [5, 9.768875930458307, 0] [6, 3.7460641632787883, 7] [7, 2.4479272053577006, 6] [8, 9.394394161645323, 5] [9, 5.966209815815091, 6] [10, 0.03534660907462239, 2]&lt;/codeblock&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:56;592:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:110;592:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;取消订阅&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:41;594:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;conn.unsubscribe(&#34;192.168.1.103&#34;, 8941,&#34;trades&#34;,&#34;sub_trades&#34;)&lt;/codeblock&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;612-dolphindb服务端流数据订阅示例&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:24;598:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:24;598:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;6.1.2. DolphinDB服务端流数据订阅示例&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:24;598:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:111;600:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;DolphinDB可以订阅来自Python客户端的流数据。下面的例子中，我们在Python客户端订阅第三方数据到多个DataFrame中，通过DolphinDB的流数据订阅功能将多个表中的数据写入到分布式表中。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:112;602:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;首先，在DolphinDB服务端执行以下脚本，创建数据库和表：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:42;604:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;login('admin','123456') // 定义表结构 n=20000000 colNames =`Code`Date`DiffAskVol`DiffAskVolSum`DiffBidVol`DiffBidVolSum`FirstDerivedAskPrice`FirstDerivedAskVolume`FirstDerivedBidPrice`FirstDerivedBidVolume colTypes = [SYMBOL,DATE,INT,INT,INT,INT,FLOAT,INT,FLOAT,INT] // 创建数据库与分布式表 dbPath= &#34;dfs://ticks&#34; if(existsDatabase(dbPath)) dropDatabase(dbPath) db=database(dbPath,VALUE, 2000.01.01..2030.12.31) dfsTB=db.createPartitionedTable(table(n:0, colNames, colTypes),`tick,`Date)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:113;620:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;下面，我们将定义两个流数据表&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:54;620:15&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;mem_stream_d&lt;/codeph&gt;和&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:55;620:30&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;mem_stream_f&lt;/codeph&gt;，客户端往流数据表写入数据，由服务端订阅数据。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:43;622:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;// 定义mem_tb_d表,并开启流数据持久化，将共享表命名为mem_stream_d mem_tb_d=streamTable(n:0, colNames, colTypes) enableTableShareAndPersistence(mem_tb_d,'mem_stream_d',false,true,n) // 定义mem_tb_f表,并开启流数据持久化，将共享表命名为mem_stream_f mem_tb_f=streamTable(n:0,colNames, colTypes) enableTableShareAndPersistence(mem_tb_f,'mem_stream_f',false,true,n)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:114;632:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:2;632:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;注意&lt;/b&gt;：由于表的分区字段是按照日期进行分区，而客户端往&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:56;632:31&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;mem_stream_d&lt;/codeph&gt;和&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:57;632:46&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;mem_stream_f&lt;/codeph&gt;表中写的数据会有日期上的重叠，若直接由分布式表&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:58;632:83&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;tick&lt;/codeph&gt;同时订阅这两个表的数据，就会造成这两个表同时往同一个日期分区写数据，导致写入失败。因此，我们需要定义另一个流表&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:59;632:144&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;ticks_stream&lt;/codeph&gt;来汇集&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:60;632:161&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;mem_stream_d&lt;/codeph&gt;和&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:61;632:176&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;mem_stream_f&lt;/codeph&gt;表的数据，最后串行写入&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:62;632:201&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;tick&lt;/codeph&gt;分布式表。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:44;634:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;// 定义ftb表，并开启流数据持久化，将共享表命名为ticks_stream ftb=streamTable(n:0, colNames, colTypes) enableTableShareAndPersistence(ftb,'ticks_stream',false,true,n) go // ticks_stream订阅mem_stream_d表的数据 def saveToTicksStreamd(mutable TB, msg): TB.append!(select * from msg) subscribeTable(, 'mem_stream_d', 'action_to_ticksStream_tde', 0, saveToTicksStreamd{ticks_stream}, true, 100) // ticks_stream同时订阅mem_stream_f表的数据 def saveToTicksStreamf(mutable TB, msg): TB.append!(select * from msg) subscribeTable(, 'mem_stream_f', 'action_to_ticksStream_tfe', 0, saveToTicksStreamf{ticks_stream}, true, 100) // dfsTB订阅ticks_stream表的数据 def saveToDFS(mutable TB, msg): TB.append!(select * from msg) subscribeTable(, 'ticks_stream', 'action_to_dfsTB', 0, saveToDFS{dfsTB}, true, 100, 5)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:115;653:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;上述几个步骤中，我们定义了一个数据库并创建分布式表&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:63;653:26&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;tick&lt;/codeph&gt;，以及三个流数据表，分别为&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:64;653:45&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;mem_stream_d&lt;/codeph&gt;、&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:65;653:60&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;mem_stream_f&lt;/codeph&gt;和&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:66;653:75&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;ticks_stream&lt;/codeph&gt;。客户端将第三方订阅而来的数据不断地追加到&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:67;653:110&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;mem_stream_d&lt;/codeph&gt;和&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:68;653:125&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;mem_stream_f&lt;/codeph&gt;表中，而写入这两个表的数据会被汇集到&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:69;653:157&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;ticks_stream&lt;/codeph&gt;表。最后，&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:70;653:176&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;ticks_stream&lt;/codeph&gt;表内的数据顺序地写入分布式表&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:71;653:204&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;tick&lt;/codeph&gt;中。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:116;655:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;下面，我们将第三方订阅到的数据上传到DolphinDB，通过DolphinDB流数据订阅功能将数据追加到分布式表。我们假定Python客户端从第三方订阅到的数据已经保存在两个名为&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:72;655:90&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;dfd&lt;/codeph&gt;和&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:73;655:96&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;dff&lt;/codeph&gt;的DataFrame中：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;Python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:45;657:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;n = 10000 dfd = pd.DataFrame({'Code': np.repeat(['SH000001', 'SH000002', 'SH000003', 'SH000004', 'SH000005'], n/5), 'Date': np.repeat(pd.date_range('1990.01.01', periods=10000, freq='D'), n/10000), 'DiffAskVol': np.random.choice(100, n), 'DiffAskVolSum': np.random.choice(100, n), 'DiffBidVol': np.random.choice(100, n), 'DiffBidVolSum': np.random.choice(100, n), 'FirstDerivedAskPrice': np.random.choice(100, n)*0.9, 'FirstDerivedAskVolume': np.random.choice(100, n), 'FirstDerivedBidPrice': np.random.choice(100, n)*0.9, 'FirstDerivedBidVolume': np.random.choice(100, n)}) n = 20000 dff = pd.DataFrame({'Code': np.repeat(['SZ000001', 'SZ000002', 'SZ000003', 'SZ000004', 'SZ000005'], n/5), 'Date': np.repeat(pd.date_range('1990.01.01', periods=10000, freq='D'), n/10000), 'DiffAskVol': np.random.choice(100, n), 'DiffAskVolSum': np.random.choice(100, n), 'DiffBidVol': np.random.choice(100, n), 'DiffBidVolSum': np.random.choice(100, n), 'FirstDerivedAskPrice': np.random.choice(100, n)*0.9, 'FirstDerivedAskVolume': np.random.choice(100, n), 'FirstDerivedBidPrice': np.random.choice(100, n)*0.9, 'FirstDerivedBidVolume': np.random.choice(100, n)})&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:117;683:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:3;683:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;注意&lt;/b&gt;： 在向流数据表追加一个带有时间列的表时，我们需要对时间列进行时间类型转换：首先将整个DataFrame上传到DolphinDB服务器，再通过select语句将其中的列取出，并转换时间类型列的数据类型，最后通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:74;683:112&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;tableInsert&lt;/codeph&gt;语句追加表。具体原因与向内存表追加一个DataFrame类似，请参见DolphinDB Python API教程。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;Python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:46;685:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;dbDir = &#34;dfs://ticks&#34; tableName = 'tick' s.upload({'dfd': dfd, 'dff': dff}) inserts = &#34;&#34;&#34;tableInsert(mem_stream_d,select Code,date(Date) as Date,DiffAskVol,DiffAskVolSum,DiffBidVol,DiffBidVolSum,FirstDerivedAskPrice,FirstDerivedAskVolume,FirstDerivedBidPrice,FirstDerivedBidVolume from dfd); tableInsert(mem_stream_f,select Code,date(Date) as Date,DiffAskVol,DiffAskVolSum,DiffBidVol,DiffBidVolSum,FirstDerivedAskPrice,FirstDerivedAskVolume,FirstDerivedBidPrice,FirstDerivedBidVolume from dff)&#34;&#34;&#34; s.run(inserts) s.run(&#34;select count(*) from loadTable('{dbPath}', `{tbName})&#34;.format(dbPath=dbDir,tbName=tableName)) // output count 0 30000&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:118;699:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在DolphinDB 服务端执行以下脚本结束订阅：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:47;701:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;def clears(tbName,action) { unsubscribeTable(tableName=tbName, actionName=action) clearTablePersistence(objByName(tbName)) undef(tbName,SHARED) } clears(`ticks_stream, `action_to_dfsTB) clears(`mem_stream_d,`action_to_ticksStream_tde) clears(`mem_stream_f,`action_to_ticksStream_tfe)&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;7-状态监控&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:25;713:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:25;713:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;7. 状态监控&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:25;713:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:119;715:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当通过订阅方式对流数据进行实时处理时，所有的计算都在后台进行，用户无法直观的看到运行的情况。DolphinDB提供以下函数监控流数据处理及流计算引擎的状态：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:13;717:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:57;717:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getStreamingStat：全方位监控流数据处理过程。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:58;718:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getStreamEngineStat：可以查看系统中定义的全部流计算引擎、各个引擎的内存占用等状态，每一类引擎对应一张表。&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;71-流数据处理状态&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:26;720:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:26;720:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;7.1. 流数据处理状态&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:26;720:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:120;722:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:75;722:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getStreamingStat&lt;/codeph&gt; 函数返回一个dictionary，包含以下五个表：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:14;724:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:59;724:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;pubConns：列出该节点所有的订阅节点信息，发布队列情况，以及流数据表名称。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:60;725:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subConns：列出每个本地节点订阅的所有发布节点的连接状态和有关接收消息的统计信息。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:61;726:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;persistWorkers：只有持久化启用后，才能通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:76;726:31&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getStreamingStat&lt;/codeph&gt;获取persistWorkers表。这张表的记录数等于persistenceWorkerNum配置值。若要并行处理持久化数据表的任务，可设置persistenceWorkerNum&amp;gt;1。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:62;727:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subWorkers：表监控流数据订阅工作线程。当有流数据进入时，可以通过该表观察到已处理数据的信息。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:63;728:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;pubTables：表监控流数据表被订阅情况&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:64;729:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:121;730:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:77;730:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable&lt;/codeph&gt;函数后，通过 getStreamingStat().pubTables 可以立刻查看到对应的订阅任务。在工作线程实际处理到数据后，才可以在 getStreamingStat().subWorkers 中查看到对应的工作线程的状态。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;72-流计算状态&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:27;732:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:27;732:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;7.2. 流计算状态&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:27;732:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:122;734:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:78;734:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscribeTable&lt;/codeph&gt;函数后，用 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:79;734:26&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getStreamingStat().pubTables&lt;/codeph&gt; 可以立刻查看到对应的订阅任务，在工作线程实际处理到数据后，才可以在 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:80;734:91&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getStreamingStat().subWorkers&lt;/codeph&gt; 中查看到对应的工作线程的状态。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;721-pubconns表&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:28;736:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:28;736:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;7.2.1. pubConns表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:28;736:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:123;738:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;pubConns表监控本地发布节点和它的所有订阅节点之间的连接状态。每一行表示本地发布节点的一个订阅节点。它包含以下列：&lt;/p&gt;&lt;table class=&#34;- topic/table &#34; xtrc=&#34;table:1;740:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;tgroup class=&#34;- topic/tgroup &#34; cols=&#34;2&#34; xtrc=&#34;tgroup:1;740:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col1&#34; colnum=&#34;1&#34; xtrc=&#34;colspec:1;740:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col2&#34; colnum=&#34;2&#34; xtrc=&#34;colspec:2;740:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;thead class=&#34;- topic/thead &#34; xtrc=&#34;thead:1;740:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:1;740:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;1&#34; xtrc=&#34;entry:1;740:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;列名称&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;1&#34; xtrc=&#34;entry:2;740:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;说明&lt;/entry&gt;&lt;/row&gt;&lt;/thead&gt;&lt;tbody class=&#34;- topic/tbody &#34; xtrc=&#34;tbody:1;742:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:2;742:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;2&#34; xtrc=&#34;entry:3;742:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;client&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;2&#34; xtrc=&#34;entry:4;742:8&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅节点的IP和端口信息&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:3;743:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;3&#34; xtrc=&#34;entry:5;743:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;queueDepthLimit&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;3&#34; xtrc=&#34;entry:6;743:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;发布节点消息队列允许的最大深度（消息数）。每个发布节点只有一个发布消息队列。&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:4;744:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;4&#34; xtrc=&#34;entry:7;744:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;queueDepth&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;4&#34; xtrc=&#34;entry:8;744:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;发布节点消息队列深度（消息数）&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:5;745:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;5&#34; xtrc=&#34;entry:9;745:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;tables&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;5&#34; xtrc=&#34;entry:10;745:8&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;该节点上的所有共享的流数据表。若多表，彼此通过逗号分隔。&lt;/entry&gt;&lt;/row&gt;&lt;/tbody&gt;&lt;/tgroup&gt;&lt;/table&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:124;747:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在GUI中运行getStreamingStat().pubConns查看表内容：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/pubconn.png&#34; placement=&#34;break&#34; xtrc=&#34;image:2;749:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;341&#34; dita-ot:image-height=&#34;78&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:125;751:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;pubConns表会列出该节点所有的订阅节点信息，发布队列情况，以及流数据表名称。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;722-subconns表&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:29;753:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:29;753:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;7.2.2. subConns表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:29;753:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:126;755:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subConns表监控本地订阅节点与其订阅的发布节点之间的连接状态。每个订阅的发布节点为表中一行。&lt;/p&gt;&lt;table class=&#34;- topic/table &#34; xtrc=&#34;table:2;757:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;tgroup class=&#34;- topic/tgroup &#34; cols=&#34;2&#34; xtrc=&#34;tgroup:2;757:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col1&#34; colnum=&#34;1&#34; xtrc=&#34;colspec:3;757:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col2&#34; colnum=&#34;2&#34; xtrc=&#34;colspec:4;757:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;thead class=&#34;- topic/thead &#34; xtrc=&#34;thead:2;757:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:6;757:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;1&#34; xtrc=&#34;entry:11;757:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;列名称&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;1&#34; xtrc=&#34;entry:12;757:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;说明&lt;/entry&gt;&lt;/row&gt;&lt;/thead&gt;&lt;tbody class=&#34;- topic/tbody &#34; xtrc=&#34;tbody:2;759:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:7;759:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;2&#34; xtrc=&#34;entry:13;759:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;publisher&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;2&#34; xtrc=&#34;entry:14;759:11&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;发布节点别名&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:8;760:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;3&#34; xtrc=&#34;entry:15;760:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;cumMsgCount&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;3&#34; xtrc=&#34;entry:16;760:13&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;累计接收消息数&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:9;761:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;4&#34; xtrc=&#34;entry:17;761:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;cumMsgLatency&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;4&#34; xtrc=&#34;entry:18;761:15&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;累计接收消息的平均延迟时间(毫秒)。延迟时间指的是消息从进入发布队列到进入订阅队列的耗时。&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:10;762:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;5&#34; xtrc=&#34;entry:19;762:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;lastMsgLatency&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;5&#34; xtrc=&#34;entry:20;762:16&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;最后一次接收数据延迟时间(毫秒)&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:11;763:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;6&#34; xtrc=&#34;entry:21;763:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;lastUpdate&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;6&#34; xtrc=&#34;entry:22;763:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;最后一次接收数据时刻&lt;/entry&gt;&lt;/row&gt;&lt;/tbody&gt;&lt;/tgroup&gt;&lt;/table&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:127;765:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在GUI中运行getStreamingStat().subConns查看表内容：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/subconn.png&#34; placement=&#34;break&#34; xtrc=&#34;image:3;767:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;541&#34; dita-ot:image-height=&#34;83&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:128;769:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;这张表列出每个本地节点订阅的所有发布节点的连接状态和有关接收消息的统计信息。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;723-persistworkers表&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:30;771:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:30;771:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;7.2.3. persistWorkers表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:30;771:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:129;773:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;persistWorkers表监控流数据表持久化工作线程，每个工作线程为一行。&lt;/p&gt;&lt;table class=&#34;- topic/table &#34; xtrc=&#34;table:3;775:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;tgroup class=&#34;- topic/tgroup &#34; cols=&#34;2&#34; xtrc=&#34;tgroup:3;775:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col1&#34; colnum=&#34;1&#34; xtrc=&#34;colspec:5;775:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col2&#34; colnum=&#34;2&#34; xtrc=&#34;colspec:6;775:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;thead class=&#34;- topic/thead &#34; xtrc=&#34;thead:3;775:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:12;775:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;1&#34; xtrc=&#34;entry:23;775:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;列名称&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;1&#34; xtrc=&#34;entry:24;775:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;说明&lt;/entry&gt;&lt;/row&gt;&lt;/thead&gt;&lt;tbody class=&#34;- topic/tbody &#34; xtrc=&#34;tbody:3;777:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:13;777:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;2&#34; xtrc=&#34;entry:25;777:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;workerId&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;2&#34; xtrc=&#34;entry:26;777:10&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;工作线程编号&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:14;778:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;3&#34; xtrc=&#34;entry:27;778:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;queueDepthLimit&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;3&#34; xtrc=&#34;entry:28;778:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;持久化消息队列深度限制&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:15;779:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;4&#34; xtrc=&#34;entry:29;779:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;queueDepth&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;4&#34; xtrc=&#34;entry:30;779:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;持久化消息队列深度&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:16;780:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;5&#34; xtrc=&#34;entry:31;780:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;tables&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;5&#34; xtrc=&#34;entry:32;780:8&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;持久化表名。若多表，彼此通过逗号分隔。&lt;/entry&gt;&lt;/row&gt;&lt;/tbody&gt;&lt;/tgroup&gt;&lt;/table&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:130;782:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;只有持久化启用后，才能通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:81;782:14&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getStreamingStat&lt;/codeph&gt;获取persistWorkers表。这张表的记录数等于persistenceWorkerNum配置值。以下例子在GUI中运行getStreamingStat().persistWorkers查看持久化两张数据表的线程。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:131;784:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当persistenceWorkerNum=1时：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/persistworker.png&#34; placement=&#34;break&#34; xtrc=&#34;image:4;786:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;292&#34; dita-ot:image-height=&#34;81&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;&gt;&lt;alt class=&#34;- topic/alt &#34; xtrc=&#34;alt:1;786:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;image&lt;/alt&gt;&lt;/image&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:132;788:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当persistenceWorkerNum=3时：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/persisWorders_2.png&#34; placement=&#34;break&#34; xtrc=&#34;image:5;790:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;290&#34; dita-ot:image-height=&#34;123&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;&gt;&lt;alt class=&#34;- topic/alt &#34; xtrc=&#34;alt:2;790:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;image&lt;/alt&gt;&lt;/image&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:133;792:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;从图上可以直观的看出，若要并行处理持久化数据表的任务，可设置persistenceWorkerNum&amp;gt;1。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;724-subworkers表&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:31;794:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:31;794:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;7.2.4. subWorkers表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:31;794:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:134;796:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subWorkers表监控流数据订阅工作线程，每条记录代表一个订阅主题。&lt;/p&gt;&lt;table class=&#34;- topic/table &#34; xtrc=&#34;table:4;798:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;tgroup class=&#34;- topic/tgroup &#34; cols=&#34;2&#34; xtrc=&#34;tgroup:4;798:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col1&#34; colnum=&#34;1&#34; xtrc=&#34;colspec:7;798:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col2&#34; colnum=&#34;2&#34; xtrc=&#34;colspec:8;798:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;thead class=&#34;- topic/thead &#34; xtrc=&#34;thead:4;798:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:17;798:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;1&#34; xtrc=&#34;entry:33;798:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;列名称&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;1&#34; xtrc=&#34;entry:34;798:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;说明&lt;/entry&gt;&lt;/row&gt;&lt;/thead&gt;&lt;tbody class=&#34;- topic/tbody &#34; xtrc=&#34;tbody:4;800:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:18;800:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;2&#34; xtrc=&#34;entry:35;800:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;workerId&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;2&#34; xtrc=&#34;entry:36;800:10&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;工作线程编号&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:19;801:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;3&#34; xtrc=&#34;entry:37;801:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;topic&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;3&#34; xtrc=&#34;entry:38;801:7&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅主题&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:20;802:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;4&#34; xtrc=&#34;entry:39;802:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;queueDepthLimit&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;4&#34; xtrc=&#34;entry:40;802:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅消息队列最大限制&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:21;803:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;5&#34; xtrc=&#34;entry:41;803:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;queueDepth&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;5&#34; xtrc=&#34;entry:42;803:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅消息队列深度&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:22;804:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;6&#34; xtrc=&#34;entry:43;804:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;processedMsgCount&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;6&#34; xtrc=&#34;entry:44;804:19&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;已进入handler的消息数量&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:23;805:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;7&#34; xtrc=&#34;entry:45;805:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;failedMsgCount&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;7&#34; xtrc=&#34;entry:46;805:16&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;handler处理异常的消息数量&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:24;806:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;8&#34; xtrc=&#34;entry:47;806:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;lastErrMsg&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;8&#34; xtrc=&#34;entry:48;806:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;上次handler处理异常的信息&lt;/entry&gt;&lt;/row&gt;&lt;/tbody&gt;&lt;/tgroup&gt;&lt;/table&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:135;808:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;配置项subExecutors与subExecutorPooling这两个配置项的对流数据处理的影响，在这张表上可以得到充分的展现。在GUI中使用getStreamingStat().subWorkers查看。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:136;810:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当subExecutorPooling=false,subExecutors=1时，内容如下：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/subworker_1.png&#34; placement=&#34;break&#34; xtrc=&#34;image:6;812:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;1099&#34; dita-ot:image-height=&#34;95&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:137;814:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;此时，所有表的订阅消息共用一个线程队列。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:138;816:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当subExecutorPooling=false,subExecutors=2时，内容如下：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/subworker_2.png&#34; placement=&#34;break&#34; xtrc=&#34;image:7;818:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;1091&#34; dita-ot:image-height=&#34;94&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:139;820:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;此时，各个表订阅消息分配到两个线程队列独立处理。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:140;822:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当subExecutorPooling=true,subExecutors=2时，内容如下：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/subworker_pool.png&#34; placement=&#34;break&#34; xtrc=&#34;image:8;824:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;1096&#34; dita-ot:image-height=&#34;137&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:141;826:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;此时，各个表的订阅消息共享由两个线程组成的线程池。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:142;828:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当有流数据进入时，可以通过这个表观察到已处理数据量等信息：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/subworker_msg.png&#34; placement=&#34;break&#34; xtrc=&#34;image:9;830:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;1083&#34; dita-ot:image-height=&#34;98&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;725-pubtables表&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:32;832:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:32;832:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;7.2.5. pubTables表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:32;832:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:143;834:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;pubTables表监控流数据表被订阅情况，每条记录代表流数据表一个订阅连接。&lt;/p&gt;&lt;table class=&#34;- topic/table &#34; xtrc=&#34;table:5;836:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;tgroup class=&#34;- topic/tgroup &#34; cols=&#34;2&#34; xtrc=&#34;tgroup:5;836:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col1&#34; colnum=&#34;1&#34; xtrc=&#34;colspec:9;836:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col2&#34; colnum=&#34;2&#34; xtrc=&#34;colspec:10;836:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;/&gt;&lt;thead class=&#34;- topic/thead &#34; xtrc=&#34;thead:5;836:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:25;836:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;1&#34; xtrc=&#34;entry:49;836:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;列名称&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;1&#34; xtrc=&#34;entry:50;836:5&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;说明&lt;/entry&gt;&lt;/row&gt;&lt;/thead&gt;&lt;tbody class=&#34;- topic/tbody &#34; xtrc=&#34;tbody:5;838:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:26;838:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;2&#34; xtrc=&#34;entry:51;838:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;tableName&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;2&#34; xtrc=&#34;entry:52;838:11&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;发布表名称&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:27;839:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;3&#34; xtrc=&#34;entry:53;839:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;subscriber&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;3&#34; xtrc=&#34;entry:54;839:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅方的host和port&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:28;840:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;4&#34; xtrc=&#34;entry:55;840:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;msgOffset&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;4&#34; xtrc=&#34;entry:56;840:11&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅线程当前订阅消息的offset&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrc=&#34;row:29;841:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;5&#34; xtrc=&#34;entry:57;841:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;actions&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;5&#34; xtrc=&#34;entry:58;841:9&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;订阅的action。若有多个action，此处用逗号分割&lt;/entry&gt;&lt;/row&gt;&lt;/tbody&gt;&lt;/tgroup&gt;&lt;/table&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:144;843:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;比如存流数据发布表名称为pubTable1，发布了100条记录。 有一个订阅从offset=0开始，action名称为&#34; act_getdata&#34;。那么当订阅完成之后，用getStreamingStat().pubTables 查看内容为：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/pubtables1.png&#34; placement=&#34;break&#34; xtrc=&#34;image:10;846:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;352&#34; dita-ot:image-height=&#34;75&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;73-流数据引擎状态&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:33;848:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:33;848:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;7.3. 流数据引擎状态&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:33;848:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:145;850:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;调用 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:82;850:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;getStreamEngineStat&lt;/codeph&gt; 会返回一个字典，其key为引擎类型名称，value为一个表，包含key对应引擎的状态。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:146;852:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;以getStreamEngineStat().DailyTimeSeriesEngine为例，查看内容为：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/streaming/getStreamEngineStat.png&#34; placement=&#34;break&#34; xtrc=&#34;image:11;854:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; dita-ot:image-width=&#34;1252&#34; dita-ot:image-height=&#34;59&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:147;856:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;在上例中，系统中仅有一个DailyTimeSeriesEngine，其引擎名为engine1，目前占用了大约32KB内存。引擎的内存占用主要是因为随着订阅的流数据不断注入引擎，存放在内存中的数据越来越多。在创建引擎时可以通过参数 garbageSize 控制清理历史数据的频率以控制引擎中的内存占用。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:148;858:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;对于不再使用的引擎建议及时释放。通过dropStreamEngine函数释放引擎会释放掉对应的内存，若流数据引擎的句柄仍在内存中也需要释放：创建引擎时返回的句柄变量 = NULL。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;8-性能调优&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:34;860:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:34;860:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;8. 性能调优&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:34;860:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:149;862:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当数据流量极大而系统来不及处理时，系统监控中会看到订阅端subWorkers表的queueDepth数值极高，此时系统&#34;../tools/grafana.md&#34;入端逐级反馈数据压力。当订阅端队列深度达到上限时开始阻止发布端数据进入，此时发布端的队列开始累积。当发布端的队列深度达到上限时，系统会阻止流数据注入端写入数据。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:150;864:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;可以通过以下几种方式来优化系统对流数据的处理性能：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:15;866:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:65;866:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:151;866:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;调整订阅参数中的batchSize和throttle参数，来平衡发布端和订阅端的缓存，让流数据输入速度与数据处理速度达到一个动态的平衡。若要充分发挥数据批量处理的性能优势，可以设定batchSize参数等待流数据积累到一定量时才进行消费，但是这样会带来一定程度的内存占用，而且当batchSize参数较大的时候，可能会发生数据量没有达到batchSize而长期滞留在缓冲区的情况。对于这个问题，可以选择一个合适的throttle参数值。它的作用是即使batchSize未满足，也能将缓冲区的数据消费掉。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:66;868:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:152;868:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;通过调整subExecutors配置参数增加订阅端计算的并行度，以加快订阅端队列的消费速度。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:67;870:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:153;870:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;当有多个executor时，若每个executor处理不同的订阅，而且不同订阅的数据流的频率或者处理复杂度差异极大，容易导致低负载的executor资源闲置。通过设置subExecutorPooling=true，可以让所有executor作为一个共享线程池，共同处理所有订阅的消息。在这种共享池模式下，所有订阅的消息进入同一个队列，多个executor从队列中读取消息并行处理。需要指出，共享线程池处理流数据的一个副作用是不能保证消息按到达的时间顺序处理。当消息需要按照抵达时间顺序被处理时，不应开启此设置。系统默认采用哈希算法为每一个订阅分配一个executor。若需要保证两个流数据表的时序同步，可在订阅函数subscribeTable中对两个订阅使用相同的hash值，来指定用同一个线程来处理这两个订阅数据流。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:68;872:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:154;872:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;若流数据表启用同步持久化，那么磁盘的I/O可能会成为瓶颈。可参考2.6小节采用异步方式持久化数据，同时设置一个合理的持久化队列(maxPersistenceQueueDepth参数，默认值为1000万条消息)。也可使用SSD硬盘替换HDD硬盘以提高写入性能。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:69;874:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:155;874:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;如果数据发布端(publisher)成为系统的瓶颈，譬如订阅的客户端太多可能导致发布瓶颈，可以采用以下两种处理办法。首先通过多级级联降低每一个发布节点的订阅数量，对延迟不敏感的应用可以订阅二级甚至三级的发布节点。其次调整部分参数来平衡延迟和吞吐量两个指标。参数maxMsgNumPerBlock设置批量发送消息时批的大小，默认值是1024。一般情况下，较大的批量值能提升吞吐量，但会增加网络延迟。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:70;876:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:156;876:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;若输入流数据的流量波动较大，高峰期导致消费队列积压至队列峰值(默认1000万)，那么可以修改配置项maxPubQueueDepthPerSite和maxSubQueueDepth以增加发布端和订阅端的最大队列深度，提高系统数据流大幅波动的能力。鉴于队列深度增加时内存消耗会增加，应估算并监控内存使用量以合理配置内存。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;9-可视化&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:35;878:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:35;878:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;9. 可视化&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:35;878:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:157;880:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;流数据可视化可分为两种类型：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:16;882:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:71;882:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:158;882:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;实时值监控：定时刷新流数据在滑动窗口的聚合计算值，通常用于指标的监控和预警。&lt;/p&gt;&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:72;884:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:159;884:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;趋势监控：把新产生的数据附加到原有的数据上并以可视化图表的方式实时更新。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:160;886:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34;&gt;很多数据可视化的平台都能支持流数据的实时监控，比如当前流行的开源数据可视化框架Grafana。DolphinDB database 已经实现了Grafana的服务端和客户端的接口，具体配置可以参考 &lt;xref class=&#34;- topic/xref &#34; dita-ot:orig-format=&#34;md&#34; format=&#34;dita&#34; href=&#34;../tools/grafana.md&#34; xtrc=&#34;xref:4;886:100&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/streaming_tutorial.md&#34; type=&#34;topic&#34;&gt;&lt;?ditaot usertext?&gt;Grafana教程&lt;/xref&gt;。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;"/><meta name="wh-source-relpath" content="tutorials/streaming_tutorial.md"/><meta name="wh-out-relpath" content="tutorials/streaming_tutorial.html"/>

    <link rel="stylesheet" type="text/css" href="../oxygen-webhelp/app/commons.css?buildId=2024012323"/>
    <link rel="stylesheet" type="text/css" href="../oxygen-webhelp/app/topic.css?buildId=2024012323"/>

    <script src="../oxygen-webhelp/app/options/properties.js?buildId=20250305183303"></script>
    <script src="../oxygen-webhelp/app/localization/strings.js?buildId=2024012323"></script>
    <script src="../oxygen-webhelp/app/search/index/keywords.js?buildId=20250305183303"></script>
    <script defer="defer" src="../oxygen-webhelp/app/commons.js?buildId=2024012323"></script>
    <script defer="defer" src="../oxygen-webhelp/app/topic.js?buildId=2024012323"></script>
<link rel="stylesheet" type="text/css" href="../oxygen-webhelp/template/styles.css?buildId=2024012323"/><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script></head>

    <body id="流数据功能应用" class="wh_topic_page frmBody">
        <a href="#wh_topic_body" class="sr-only sr-only-focusable">
            跳转到主要内容
        </a>
        
        
        
        
        <header class="navbar navbar-default wh_header">
    <div class="container-fluid">
        <div xmlns:whc="http://www.oxygenxml.com/webhelp/components" class="wh_header_flex_container navbar-nav navbar-expand-md navbar-dark">
            <div class="wh_logo_and_publication_title_container">
                <div class="wh_logo_and_publication_title">
                    
                    <a href="https://docs.dolphindb.cn/zh/index.html" class=" wh_logo d-none d-sm-block "><img src="../logo.png" alt="  DolphinDB 文档中心  "/></a>
                    <div class=" wh_publication_title "><a href="../index.html"><span class="booktitle">  <span class="ph mainbooktitle">DolphinDB 文档中心</span>  </span></a></div>
                    
                </div>
                
                
            </div>

            <div class="wh_top_menu_and_indexterms_link collapse navbar-collapse" id="wh_top_menu_and_indexterms_link">
                
                
                
                
            </div>
        <div class=" wh_search_input navbar-form wh_topic_page_search search " role="form">
            
            
            
            <form id="searchForm" method="get" role="search" action="../search.html"><div><input type="search" placeholder="搜索 " class="wh_search_textfield" id="textToSearch" name="searchQuery" aria-label="搜索查询" required="required"/><button type="submit" class="wh_search_button" aria-label="搜索"><span class="search_input_text">搜索</span></button></div></form>
            
            <script src="/vendors/react/umd/react.production.min.js" defer="defer"></script>
<script src="/vendors/react-dom/umd/react-dom.production.min.js" defer="defer"></script>
<script src="/vendors/dayjs/dayjs.min.js" defer="defer"></script>
<script src="/vendors/antd/dist/antd.min.js" defer="defer"></script>
<script src="/vendors/@ant-design/icons/dist/index.umd.min.js" defer="defer"></script>
<script src="/zh/index.js" type="module"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" defer="defer"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer="defer"><!--


--></script>
<script defer="defer"><!--

// 从主页重定向
const currentUrl = window.location.href;

// 判断当前URL是否包含index.html并且路径最后部分是index.html
if (currentUrl.endsWith('index.html')) {
    // 处理根目录下的index.html跳转
    const baseUrl = currentUrl.split('/index.html')[0]; // 获取index.html之前的部分
    const redirectUrl = `${baseUrl}/about/ddb_intro.html`; // 构建跳转路径
    window.location.href = redirectUrl; // 执行跳转
}

--></script>
            
        </div></div>
    </div>
</header>
        
        
         
        
        
        
        <div class="container-fluid" id="wh_topic_container">
            <div class="row">

                <nav class="wh_tools d-print-none navbar-expand-md" aria-label="Tools">
                    
                    <div data-tooltip-position="bottom" class=" wh_breadcrumb "><ol class="d-print-none"><li><span class="home"><a href="../index.html"><span>主页</span></a></span></li><li><div class="topicref" data-id="about_tutorials"><div class="title"><a href="../tutorials/about_tutorials.html"><span class="keyword label">教程</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 产品使用教程</p></div></div></div></li><li><div class="topicref"><div class="title"><a href="../tutorials/streaming-real-time-correlation-processing_2.html">流数据</a></div></div></li><li class="active"><div class="topicref" data-id="流数据功能应用"><div class="title"><a href="../tutorials/streaming_tutorial.html">流数据功能应用</a></div></div></li></ol></div>
                    
                    
                    
                    <div class="wh_right_tools">
                        <button class="wh_hide_highlight" aria-label="切换搜索突出显示" title="切换搜索突出显示"></button>
                        <button class="webhelp_expand_collapse_sections" data-next-state="collapsed" aria-label="折叠截面" title="折叠截面"></button>
                        
                        
                        
                        
                        <div class=" wh_print_link print d-none d-md-inline-block "><button onClick="window.print()" title="打印此页" aria-label="打印此页"></button></div>
                        
                        <button type="button" id="wh_toc_button" class="custom-toggler navbar-toggler collapsed wh_toggle_button navbar-light" aria-expanded="false" aria-label="Toggle publishing table of content" aria-controls="wh_publication_toc">
                            <span class="navbar-toggler-icon"></span>
                        </button>
                    </div>
                    
                </nav>
            </div>
            
            
            
            
            <div class="wh_content_area">
                <div class="row">
                    
                        <nav id="wh_publication_toc" class="col-lg-3 col-md-3 col-sm-12 d-md-block d-none d-print-none" aria-label="Table of Contents Container">
                            <div id="wh_publication_toc_content">
		                        
                            	<div class=" wh_publication_toc " data-tooltip-position="right"><span class="expand-button-action-labels"><span id="button-expand-action" role="button" aria-label="Expand"></span><span id="button-collapse-action" role="button" aria-label="Collapse"></span><span id="button-pending-action" role="button" aria-label="Pending"></span></span><ul role="tree" aria-label="Table of Contents"><li role="treeitem"><div data-tocid="ddb_intro-d9713e87" class="topicref" data-id="ddb_intro" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../about/ddb_intro.html" id="ddb_intro-d9713e87-link">关于DolphinDB</a></div></div></li><li role="treeitem"><div data-tocid="chap1_getstarted-d9713e136" class="topicref" data-id="chap1_getstarted" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../getstarted/chap1_getstarted.html" id="chap1_getstarted-d9713e136-link">快速上手</a><div class="wh-tooltip"><p class="shortdesc">如何快速部署 DolphinDB、建库建表、写入和查询数据</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="sectionddb_deployment-d9713e189" class="topicref" data-id="sectionddb_deployment" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action sectionddb_deployment-d9713e189-link" class="wh-expand-btn"></span><div class="title"><a href="../deploy/deploy_intro.html" id="sectionddb_deployment-d9713e189-link"><span class="keyword label">部署</span></a><div class="wh-tooltip"><p class="shortdesc">如何在不同的场景中部署 DolphinDB</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="new_chap_database_manage_new_chap_dbmanage_landing_page-d9713e2259" class="topicref" data-id="new_chap_database_manage_new_chap_dbmanage_landing_page" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action new_chap_database_manage_new_chap_dbmanage_landing_page-d9713e2259-link" class="wh-expand-btn"></span><div class="title"><a href="../db_distr_comp/cfg/db_intro.html" id="new_chap_database_manage_new_chap_dbmanage_landing_page-d9713e2259-link"><span class="keyword label">数据库</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 数据库的基本概念</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="chap7_tutorials_streaming-d9713e3760" class="topicref" data-id="chap7_tutorials_streaming" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action chap7_tutorials_streaming-d9713e3760-link" class="wh-expand-btn"></span><div class="title"><a href="../stream/str_intro.html" id="chap7_tutorials_streaming-d9713e3760-link"><span class="keyword label">流数据</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 流数据引擎及流数据计算的基本概念</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e7513" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e7513-link" class="wh-expand-btn"></span><div class="title"><a href="../db_distr_comp/db_oper/import_data.html" id="tocId-d9713e7513-link">数据迁移</a><div class="wh-tooltip"><p class="shortdesc">如何从不同数据源向 DolphinDB 迁移数据</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="chap7_tutorials_system_management-d9713e7940" class="topicref" data-id="chap7_tutorials_system_management" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action chap7_tutorials_system_management-d9713e7940-link" class="wh-expand-btn"></span><div class="title"><a href="../sys_man/om_intro.html" id="chap7_tutorials_system_management-d9713e7940-link"><span class="keyword label">系统运维</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 的系统运维功能及方法</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="troubleshooting-d9713e8780" class="topicref" data-id="troubleshooting" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action troubleshooting-d9713e8780-link" class="wh-expand-btn"></span><div class="title"><a href="../error_codes/troubleshooting.html" id="troubleshooting-d9713e8780-link">故障排查</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="about_language_resources-d9713e20911" class="topicref" data-id="about_language_resources" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action about_language_resources-d9713e20911-link" class="wh-expand-btn"></span><div class="title"><a href="../progr/progr_intro.html" id="about_language_resources-d9713e20911-link"><span class="keyword label">编程语言</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 编程基本概念与方法、SQL 在 DolphinDB 的应用</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="functions_references-d9713e30925" class="topicref" data-id="functions_references" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action functions_references-d9713e30925-link" class="wh-expand-btn"></span><div class="title"><a href="../funcs/funcs_intro.html" id="functions_references-d9713e30925-link"><span class="keyword label">函数参考</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 函数分类、语法、详解及示例</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="api_protocol-d9713e94064" class="topicref" data-id="api_protocol" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action api_protocol-d9713e94064-link" class="wh-expand-btn"></span><div class="title"><a href="../api/connapi_intro.html" id="api_protocol-d9713e94064-link"><span class="keyword label">连接器 &amp; API</span></a><div class="wh-tooltip"><p class="shortdesc">面向不同编程语言的 DolphinDB API 及连接器，相关协议和用法</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="chap6_plugin-d9713e94210" class="topicref" data-id="chap6_plugin" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action chap6_plugin-d9713e94210-link" class="wh-expand-btn"></span><div class="title"><a href="../plugins/plg_intro.html" id="chap6_plugin-d9713e94210-link"><span class="keyword label">插件</span></a><div class="wh-tooltip"><p class="shortdesc">多个应用场景的插件使用说明和插件开发指导</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="third_party-d9713e97904" class="topicref" data-id="third_party" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action third_party-d9713e97904-link" class="wh-expand-btn"></span><div class="title"><a href="../third_party.html" id="third_party-d9713e97904-link">第三方工具</a></div></div></li><li role="treeitem" aria-expanded="true"><div data-tocid="about_tutorials-d9713e98227" class="topicref" data-id="about_tutorials" data-state="expanded"><span role="button" tabindex="0" aria-labelledby="button-collapse-action about_tutorials-d9713e98227-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/about_tutorials.html" id="about_tutorials-d9713e98227-link"><span class="keyword label">教程</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 产品使用教程</p></div></div></div><ul role="group" class="navbar-nav nav-list"><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e98280" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e98280-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/new_users_finance.html" id="tocId-d9713e98280-link">新用户入门</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e98327" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e98327-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/database.html" id="tocId-d9713e98327-link">数据库</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e99111" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e99111-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/std_sql_ddb.html" id="tocId-d9713e99111-link">编程</a></div></div></li><li role="treeitem" aria-expanded="true"><div data-tocid="tocId-d9713e100448" class="topicref" data-state="expanded"><span role="button" tabindex="0" aria-labelledby="button-collapse-action tocId-d9713e100448-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming-real-time-correlation-processing_2.html" id="tocId-d9713e100448-link">流数据</a></div></div><ul role="group" class="navbar-nav nav-list"><li role="treeitem"><div data-tocid="多数据源流式实时关联处理-d9713e100449" class="topicref" data-id="多数据源流式实时关联处理" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming-real-time-correlation-processing_2.html" id="多数据源流式实时关联处理-d9713e100449-link">多数据源流式实时关联处理</a></div></div></li><li role="treeitem"><div data-tocid="流数据引擎解析器-d9713e100495" class="topicref" data-id="流数据引擎解析器" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/StreamEngineParser.html" id="流数据引擎解析器-d9713e100495-link">流数据引擎解析器</a></div></div></li><li role="treeitem"><div data-tocid="流数据高可用-d9713e100541" class="topicref" data-id="流数据高可用" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/haStreaming.html" id="流数据高可用-d9713e100541-link">流数据高可用</a></div></div></li><li role="treeitem"><div data-tocid="节点启动时的流计算自动订阅-d9713e100587" class="topicref" data-id="节点启动时的流计算自动订阅" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming_auto_sub_2.html" id="节点启动时的流计算自动订阅-d9713e100587-link">节点启动时的流计算自动订阅</a></div></div></li><li role="treeitem"><div data-tocid="cep-引擎入门初级高频量价因子策略的实现-d9713e100633" class="topicref" data-id="cep-引擎入门初级高频量价因子策略的实现" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/getting_started_with_cep_engine.html" id="cep-引擎入门初级高频量价因子策略的实现-d9713e100633-link">CEP 引擎入门：初级高频量价因子策略的实现</a></div></div></li><li role="treeitem"><div data-tocid="cep-引擎应用股票中高频-cta-策略实现与并行回测-d9713e100679" class="topicref" data-id="cep-引擎应用股票中高频-cta-策略实现与并行回测" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/cta_strategy_implementation_and_backtesting.html" id="cep-引擎应用股票中高频-cta-策略实现与并行回测-d9713e100679-link">CEP 引擎应用：股票中高频 CTA 策略实现与并行回测</a></div></div></li><li role="treeitem"><div data-tocid="流计算时延统计与性能优化-d9713e100725" class="topicref" data-id="流计算时延统计与性能优化" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming_timer.html" id="流计算时延统计与性能优化-d9713e100725-link">流计算时延统计与性能优化</a></div></div></li><li role="treeitem"><div data-tocid="响应式状态引擎-d9713e100771" class="topicref" data-id="响应式状态引擎" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/reactive_state_engine.html" id="响应式状态引擎-d9713e100771-link">响应式状态引擎</a></div></div></li><li role="treeitem" class="active"><div data-tocid="流数据功能应用-d9713e100817" class="topicref" data-id="流数据功能应用" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming_tutorial.html" id="流数据功能应用-d9713e100817-link">流数据功能应用</a></div></div></li><li role="treeitem"><div data-tocid="数据回放-d9713e100863" class="topicref" data-id="数据回放" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/data_replay.html" id="数据回放-d9713e100863-link">数据回放</a></div></div></li><li role="treeitem"><div data-tocid="使用-dolphindb-class-来开发流计算状态算子-d9713e100909" class="topicref" data-id="使用-dolphindb-class-来开发流计算状态算子" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/stateful_stream_operators.html" id="使用-dolphindb-class-来开发流计算状态算子-d9713e100909-link">使用 DolphinDB Class 来开发流计算状态算子</a></div></div></li></ul></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e100955" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e100955-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/scheduledJob_2.html" id="tocId-d9713e100955-link">系统运维</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="模块概述-d9713e101923" class="topicref" data-id="模块概述" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action 模块概述-d9713e101923-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/tu_modules.html" id="模块概述-d9713e101923-link">模块</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e102568" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e102568-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/OHLC_2.html" id="tocId-d9713e102568-link">金融场景案例</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e104827" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e104827-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming_engine_anomaly_alerts_2.html" id="tocId-d9713e104827-link">物联网场景案例</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e105795" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e105795-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/dolphindb_tensor_libtorch_tutorial.html" id="tocId-d9713e105795-link">机器学习</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e105842" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e105842-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/api_performance.html" id="tocId-d9713e105842-link">测试报告</a></div></div></li></ul></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e105982" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e105982-link" class="wh-expand-btn"></span><div class="title"><a href="../rn/server/3_00_2.html" id="tocId-d9713e105982-link">版本说明</a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 版本发布历史</p></div></div></div></li></ul></div>
		                        
                            </div>
                        </nav>
                    
                    
                    <div class="col-lg-7 col-md-9 col-sm-12" id="wh_topic_body">
                        <button id="wh_close_publication_toc_button" class="close-toc-button d-none" aria-label="Toggle publishing table of content" aria-controls="wh_publication_toc" aria-expanded="true">
                            <span class="close-toc-icon-container">
                                <span class="close-toc-icon"></span>     
                            </span>
                        </button>
                        <button id="wh_close_topic_toc_button" class="close-toc-button d-none" aria-label="Toggle topic table of content" aria-controls="wh_topic_toc" aria-expanded="true">
                            <span class="close-toc-icon-container">
                                <span class="close-toc-icon"></span>     
                            </span>
                        </button>
                        
                        <div class=" wh_topic_content body "><main role="main"><article class="- topic/topic topic" role="article" aria-labelledby="ariaid-title1"><h1 class="- topic/title title topictitle1" id="ariaid-title1">流数据功能应用</h1><div class="- topic/body body"><p class="- topic/p p">实时流处理是指将业务系统产生的持续增长的动态数据进行实时的收集、清洗、统计、入库，并对结果进行实时的展示。在金融交易、物联网、互联网/移动互联网等应用场景中，复杂的业务需求对大数据处理的实时性提出了极高的要求。面向静态数据表的传统计算引擎无法胜任流数据领域的分析和计算任务。</p><p class="- topic/p p">DolphinDB内置的流数据框架支持流数据的发布、订阅、预处理、实时内存计算、复杂指标的滚动窗口计算、实时关联、异常数据检测等，是一个运行高效，使用便捷的流数据处理框架。</p><p class="- topic/p p">与其它流数据系统相比，DolphinDB流数据处理系统的优点在于：</p><ul class="- topic/ul ul"><li class="- topic/li li">吞吐量大，低延迟，高可用。</li><li class="- topic/li li">与DolphinDB时序数据库无缝集成，提供一站式解决方案。</li><li class="- topic/li li">天然具备流数据表对偶性，支持使用SQL语句进行数据注入和查询分析。</li></ul><p class="- topic/p p">DolphinDB流数据处理系统提供了多种方便的功能，例如：</p><ul class="- topic/ul ul"><li class="- topic/li li">内置流数据时间序列、横截面、异常检测、响应式状态、连接引擎</li><li class="- topic/li li">高频数据回放</li><li class="- topic/li li">流数据过滤</li></ul></div><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title2" id="1-流程图及相关概念"><h2 class="- topic/title title topictitle2" id="ariaid-title2">1. 流程图及相关概念</h2><div class="- topic/body body"><p class="- topic/p p">DolphinDB流数据模块采用发布-订阅-消费的模式。流数据首先注入流数据表中，通过流数据表来发布数据，数据节点或者第三方的应用可以通过DolphinDB脚本或API来订阅及消费流数据。</p><br/><img class="- topic/image image" src="images/streaming/streaming_frame.png"/><br/><p class="- topic/p p">上图展示了DolphinDB的流数据处理框架。把实时数据注入到发布节点流数据表后，发布的数据可同时供多方订阅消费：</p><ul class="- topic/ul ul"><li class="- topic/li li">可由数据仓库订阅并保存，作为分析系统与报表系统的数据源。</li><li class="- topic/li li">可由流数据计算引擎订阅，进行计算，并将结果输出到流数据表。计算结果既可以由Grafana等平台进行实时展示，也可以作为数据源再次发布，供二次订阅做事件处理。</li><li class="- topic/li li">可由API订阅，例如第三方的Java应用程序可以通过Java API订阅流数据进行业务操作。</li></ul></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title3" id="11-流数据表"><h3 class="- topic/title title topictitle3" id="ariaid-title3">1.1. 流数据表</h3><div class="- topic/body body"><p class="- topic/p p">流数据表是一种特殊的内存表，用以存储及发布流数据。与普通内存表不同，流数据表支持同时读写，且只能添加记录，不可修改或删除记录。数据源发布一条消息等价于向流数据表插入一条记录。与普通内存表相同，可使用SQL语句对流数据表进行查询和分析。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title4" id="12-发布与订阅"><h3 class="- topic/title title topictitle3" id="ariaid-title4">1.2. 发布与订阅</h3><div class="- topic/body body"><p class="- topic/p p">采用经典的发布订阅模式。每当有新的流数据注入负责发布消息的流数据表时，会通知所有的订阅方处理新的流数据。数据节点使用<code class="+ topic/ph pr-d/codeph ph codeph">subscribeTable</code>函数来订阅流数据。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title5" id="13-流数据计算引擎"><h3 class="- topic/title title topictitle3" id="ariaid-title5">1.3. 流数据计算引擎</h3><div class="- topic/body body"><p class="- topic/p p">流数据计算引擎是专门用于处理流数据实时计算和分析的模块。DolphinDB提供<code class="+ topic/ph pr-d/codeph ph codeph">createTimeSeriesEngine</code>,<code class="+ topic/ph pr-d/codeph ph codeph">createDailyTimeSeriesEngine</code>,<code class="+ topic/ph pr-d/codeph ph codeph">createSessionWindowEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createAnomalyDetectionEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createReactiveStateEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createCrossSectionalEngine </code>, <code class="+ topic/ph pr-d/codeph ph codeph">createAsofJoinEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createEquiJoinEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createWindowJoinEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createLookupJoinEngine</code>等函数创建流数据计算引擎对流数据进行实时计算，并将计算结果持续输出到指定的数据表中。</p><ul class="- topic/ul ul"><li class="- topic/li li">注：自 1.30.21/2.00.9 版本起，<code class="+ topic/ph pr-d/codeph ph codeph">createEqualJoinEngine</code> 更名为 <code class="+ topic/ph pr-d/codeph ph codeph">createEquiJoinEngine</code>，原函数名可继续使用。*</li></ul></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title6" id="2-核心功能"><h2 class="- topic/title title topictitle2" id="ariaid-title6">2. 核心功能</h2><div class="- topic/body body"><p class="- topic/p p">要开启支持流数据功能的模块，必须对发布节点指定 <em class="+ topic/ph hi-d/i ph i">maxPubConnections</em> 配置参数，并对订阅节点指定 <em class="+ topic/ph hi-d/i ph i">subPort</em> 配置参数。以下为所有流数据相关配置参数。</p><p class="- topic/p p">发布节点的配置参数：</p><ul class="- topic/ul ul"><li class="- topic/li li">maxPubConnections: 发布节点可以连接的订阅节点数量上限，默认值为0。只有指定maxPubConnections为正整数后，该节点才可作为发布节点。</li><li class="- topic/li li">persistenceDir: 保存发布消息的流数据表的文件夹路径。若需要保存流数据表，必须指定该参数。所有生产环境中都强烈推荐设定此参数。若不设定此参数，随着消息的积累，内存会最终耗尽。</li><li class="- topic/li li">persistenceWorkerNum: 负责以异步模式保存流数据表的工作线程数。默认值为0。</li><li class="- topic/li li">maxPersistenceQueueDepth: 以异步模式保存流数据表时消息队列的最大深度（记录数量）。默认值为10,000,000。</li><li class="- topic/li li">maxMsgNumPerBlock: 发布消息时，每个消息块中最多可容纳的记录数量。默认值为1024。</li><li class="- topic/li li">maxPubQueueDepthPerSite: 发布节点消息队列的最大深度（记录数量）。默认值为10,000,000。</li></ul><p class="- topic/p p">订阅节点的配置参数：</p><ul class="- topic/ul ul"><li class="- topic/li li">subPort: 订阅线程监听的端口号，默认值为0。只有指定该参数后，该节点才可作为订阅节点。</li><li class="- topic/li li">subExecutors: 订阅节点中消息处理线程的数量。默认值为0，表示解析消息线程也处理消息。</li><li class="- topic/li li">maxSubConnections: 该订阅节点可以连接的的发布节点数量上限。默认值为64。</li><li class="- topic/li li">subExecutorPooling: 表示执行流计算的线程是否处于pooling模式的布尔值。默认值是false。</li><li class="- topic/li li">maxSubQueueDepth: 订阅节点消息队列的最大深度（记录数量）。默认值为10,000,000。</li></ul></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title7" id="21-流数据发布"><h3 class="- topic/title title topictitle3" id="ariaid-title7">2.1. 流数据发布</h3><div class="- topic/body body"><p class="- topic/p p">使用<code class="+ topic/ph pr-d/codeph ph codeph">streamTable</code>函数定义一个流数据表。实时数据写入该表后，向所有订阅端发布。由于通常有多个会话中的多个订阅端订阅同一个发布端，所以必须使用<code class="+ topic/ph pr-d/codeph ph codeph">share</code>函数将流数据表在所有会话中共享后才可发布流数据。未被共享的流数据表无法发布流数据。</p><p class="- topic/p p">定义并共享流数据表pubTable：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>share streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable</code></pre><p class="- topic/p p"><code class="+ topic/ph pr-d/codeph ph codeph">streamTable</code>函数创建的流数据表是可以包含重复记录的。如果要创建包含主键的流数据表，可以使用<code class="+ topic/ph pr-d/codeph ph codeph">keyedStreamTable</code>函数。包含主键的流数据表中，一旦写入某键值的数据，后续相同键值的数据不会写入此流数据表，将被丢弃。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>share keyedStreamTable(`timestamp, 10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable</code></pre><p class="- topic/p p">可以用undef函数或者dropStreamTable删除上述语句创建的共享流数据表pubTable：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>undef(`pubTable, SHARED)
dropStreamTable(`pubTable)</code></pre><p class="- topic/p p">undef函数能够将变量或者函数定义从内存中释放。但是，若要删除2.6节的持久化流数据表，则必须使用dropStreamTable函数。此外，用户需要在取消所有订阅后才能删除相应的流数据表，取消订阅请参考<a class="- topic/xref xref" href="#%E5%8F%96%E6%B6%88%E8%AE%A2%E9%98%85">取消订阅</a>。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title8" id="22-流数据订阅"><h3 class="- topic/title title topictitle3" id="ariaid-title8">2.2. 流数据订阅</h3><div class="- topic/body body"><p class="- topic/p p">订阅流数据通过 <code class="+ topic/ph pr-d/codeph ph codeph">subscribeTable</code> 函数来实现。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>subscribeTable([server],tableName,[actionName],[offset=-1],handler,[msgAsTable=false],[batchSize=0],[throttle=1],[hash=-1],[reconnect=false],[filter],[persistOffset=false],[timeTrigger=false],[handlerNeedMsgId=false],[raftGroup],[userId=""],[password=""])</code></pre><p class="- topic/p p">参数说明：</p><ul class="- topic/ul ul"><li class="- topic/li li"><p class="- topic/p p">只有tableName和handler两个参数是必需的，其它所有参数均为可选参数。</p></li><li class="- topic/li li"><p class="- topic/p p">server 为字符串，表示流数据所在服务器的别名或远程连接handle。如果未指定或者为空字符串，表示流数据所在服务器是本地实例。</p></li></ul><p class="- topic/p p">实际情况中，发布者与订阅者所在节点的关系有以下三种可能。这三种情况下的server参数设置分别为：</p><ol class="- topic/ol ol"><li class="- topic/li li"><p class="- topic/p p">发布者与订阅者是同一节点，均为本地实例：参数server不设置或使用空字符串。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>subscribeTable(tableName="pubTable", actionName="act1", offset=0, handler=subTable, msgAsTable=true)</code></pre></li><li class="- topic/li li"><p class="- topic/p p">发布者与订阅者是同一集群内的不同节点：参数server使用发布节点别名。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>subscribeTable(server="NODE2", tableName="pubTable", actionName="act1", offset=0, handler=subTable, msgAsTable=true)</code></pre></li><li class="- topic/li li"><p class="- topic/p p">发布者与订阅者不在同一个集群内：参数server使用发布节点的远程连接handle。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>pubNodeHandler=xdb("192.168.1.13",8891)
subscribeTable(server=pubNodeHandler, tableName="pubTable", actionName="act1", offset=0, handler=subTable, msgAsTable=true)</code></pre><ul class="- topic/ul ul"><li class="- topic/li li"><p class="- topic/p p">tableName：被订阅的流数据表名。该表必须为共享的流数据表。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>subscribeTable(tableName="pubTable", actionName="act1", offset=0, handler=subTable, msgAsTable=true)</code></pre></li><li class="- topic/li li"><p class="- topic/p p">actionName：一个字符串，表示订阅任务的名称。同一份流数据可以被多项任务订阅消费，既可用于实时运算，亦可存储到数据仓库供第三方应用做批处理。如果一个节点有多个订阅均订阅了同一张表，必须指定actionName。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>topic1 = subscribeTable(tableName="pubTable", actionName="realtimeAnalytics", offset=0, handler=subTable, msgAsTable=true)
topic2 = subscribeTable(tableName="pubTable", actionName="saveToDataWarehouse", offset=0, handler=subTable, msgAsTable=true)</code></pre><p class="- topic/p p"><code class="+ topic/ph pr-d/codeph ph codeph">subscribeTable</code>函数的返回值是订阅主题，它是订阅表所在节点的别名、流数据表名称和订阅任务名称（如果指定了actionName）的组合，使用"/"分隔。若当前节点别名为NODE1，上述例子返回的两个topic内容如下:</p><p class="- topic/p p">topic1:</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>NODE1/pubTable/realtimeAnalytics</code></pre><p class="- topic/p p">topic2:</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>NODE1/pubTable/saveToDataWarehouse</code></pre><p class="- topic/p p">如果订阅主题已经存在，将抛出异常。</p></li><li class="- topic/li li"><p class="- topic/p p">offset：订阅任务从流数据表的哪一行开始。如果未指定或设为-1，订阅将会从未来的新数据开始。如果offset=-2，系统会自动获取持久化到磁盘上的offset，并从该位置开始订阅。offset的值永远与流数据表创建时的第一行对应。如果某些行因为内存限制被删除，在决定订阅开始的位置时，这些行仍然考虑在内。</p><p class="- topic/p p">下例说明offset的作用。向pubTable写入100行数据，建立两个订阅：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>share streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable
share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable1
share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable2
vtimestamp = 1..100
vtemp = norm(2,0.4,100)
tableInsert(pubTable,vtimestamp,vtemp)
topic1 = subscribeTable(tableName="pubTable", actionName="act1", offset=-1, handler=subTable1, msgAsTable=true)
topic2 = subscribeTable(tableName="pubTable", actionName="act2", offset=50, handler=subTable2, msgAsTable=true)</code></pre><p class="- topic/p p">从结果可以看到，subTable1没有数据，而subTable2有50条数据。当offset为-1时，只有当新数据进入发布表时才能订阅到数据。</p></li><li class="- topic/li li"><p class="- topic/p p">handler：一元函数或数据表。若为函数，用于处理订阅数据，其唯一的参数是订阅的数据。订阅的数据可以以数据表或元组（订阅数据表的每个列是元组的一个元素）的形式注入handler。由于经常需要把订阅数据插入到数据表，为了方便使用，handler也可以是一个数据表，订阅数据直接插入到该表中。</p><p class="- topic/p p">下例展示handler的两种用法。在act1订阅中，直接把订阅数据写入subTable1；在act2订阅中，订阅数据通过自定义函数<code class="+ topic/ph pr-d/codeph ph codeph">myHandler</code>进行过滤后写入subTable2。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def myhandler(msg){
	t = select * from msg where temperature&gt;0.2
	if(size(t)&gt;0)
		subTable2.append!(t)
}
share streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable
share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable1
share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable2
topic1 = subscribeTable(tableName="pubTable", actionName="act1", offset=-1, handler=subTable1, msgAsTable=true)
topic2 = subscribeTable(tableName="pubTable", actionName="act2", offset=-1, handler=myhandler, msgAsTable=true)

vtimestamp = 1..10
vtemp = 2.0 2.2 2.3 2.4 2.5 2.6 2.7 0.13 0.23 2.9
tableInsert(pubTable,vtimestamp,vtemp)</code></pre><p class="- topic/p p">从结果可以看到写入pubTable10条数据，subTable1全部接收了；而subTable2接收到9条数据，因为<code class="+ topic/ph pr-d/codeph ph codeph">myhandler</code>过滤掉了vtemp = 0.13这一条数据。</p></li><li class="- topic/li li"><p class="- topic/p p">msgAsTable：布尔值，表示订阅的数据以何种形式进入handler。若设为true，表示订阅的数据以table的形式注入handler，可使用SQL语句处理。默认值是false，表示订阅的数据是由列组成的元组。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def myhandler1(table){
	subTable1.append!(table)
}
def myhandler2(tuple){
	tableInsert(subTable2,tuple[0],tuple[1])
}
share streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable
share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable1
share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable2

topic1 = subscribeTable(tableName="pubTable", actionName="act1", offset=-1, handler=myhandler1, msgAsTable=true)
topic2 = subscribeTable(tableName="pubTable", actionName="act2", offset=-1, handler=myhandler2, msgAsTable=false)

vtimestamp = 1..10
vtemp = 2.0 2.2 2.3 2.4 2.5 2.6 2.7 0.13 0.23 2.9
tableInsert(pubTable,vtimestamp,vtemp)</code></pre></li><li class="- topic/li li"><p class="- topic/p p">batchSize：一个整数。若为正数，表示未处理消息的数量达到batchSize时，handler才会处理消息。若未指定或为非正数，每一批次的消息到达之后，handler就会马上处理。</p><p class="- topic/p p">下例中，batchSize设置为11。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>share streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE]) as pubTable
share streamTable(10000:0,`ts`temp, [TIMESTAMP,DOUBLE]) as subTable1
topic1 = subscribeTable(tableName="pubTable", actionName="act1", offset=-1, handler=subTable1, msgAsTable=true, batchSize=11)
vtimestamp = 1..10
vtemp = 2.0 2.2 2.3 2.4 2.5 2.6 2.7 0.13 0.23 2.9
tableInsert(pubTable,vtimestamp,vtemp)

print size(subTable1)</code></pre><p class="- topic/p p">先向pubTable写入10条数据，订阅表subTable1此时为空。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>insert into pubTable values(11,3.1)
print size(subTable1)</code></pre><p class="- topic/p p">接着向pubTable写入1条数据。订阅表subTable1此时有11条数据。</p></li><li class="- topic/li li"><p class="- topic/p p">throttle：一个浮点数，表示继上次handler处理消息之后，若batchSize条件一直未达到，多久后再次处理消息。以秒为单位，默认值为1。如果没有指定batchSize，throttle即使指定，也不起作用。若throttle小于配置参数subThrottle/1000，throttle的效果等同于其被指定为subThrottle/1000。</p><p class="- topic/p p">handler处理一条数据与批量处理多条（例如1000条）数据的耗时差别很小。若每一条数据注入handler时都要处理一次，在写入速度极高的情况下有可能导致数据消费能力慢于数据写入速度，不仅不能及时处理所有数据，而且会造成数据不断堆积在订阅端缓冲区而耗光内存。合理设置batchSize与throttle参数，可通过调整handler处理消息的频率，以提升吞吐量。</p></li><li class="- topic/li li"><p class="- topic/p p">hash：一个非负整数，指定某个订阅线程处理消息。如果没有指定该参数，系统会自动分配一个线程，优先分配没有订阅的线程。若需要在多个订阅的处理过程中保持消息数据的同步，可以将多个订阅的hash值设置为相同，这样就能使用同一个线程来同步处理多个数据源，不会出现数据处理有先后而导致结果误差。</p></li><li class="- topic/li li"><p class="- topic/p p">reconnect是一个布尔值。默认值为false，表示如果网络异常等问题导致订阅中断，订阅端不会自动重新订阅；如果设为true，订阅端会在网络恢复正常时，自动从中断位置重新订阅。如果发布端崩溃或关闭导致订阅中断，那么订阅端会不断尝试重新订阅，直到能够重新与发布端建立连接。若发布端对流数据表启用了持久化，那么发布端重启后会首先读取硬盘上持久化的数据，直到发布端读取到订阅中断位置的数据，订阅端才能成功重新订阅。若发布端没有对流数据表启用持久化，那么重新订阅将会失败。订阅端不保存订阅信息，如果订阅端崩溃或关闭导致订阅中断，即使设置了reconnect=true，订阅端重启后也无法自动重新订阅。</p></li><li class="- topic/li li"><p class="- topic/p p">filter 参数需要配合<code class="+ topic/ph pr-d/codeph ph codeph">setStreamTableFilterColumn</code>函数一起使用。使用<code class="+ topic/ph pr-d/codeph ph codeph">setStreamTableFilterColumn</code>指定流数据表的过滤列，流数据表过滤列在filter中的数据才会发布到订阅端，不在filter中的数据不会发布。filter不支持过滤BOOL类型数据。filter 参数可以使用以下三种方法指定。其中范围过滤与哈希过滤于1.30.3版本发布。</p><ul class="- topic/ul ul"><li class="- topic/li li">值过滤：一个向量。</li><li class="- topic/li li">范围过滤：一个数据对。范围包含下限值，但不包括上限值。</li><li class="- topic/li li">哈希过滤：一个元组。第一个元素表示bucket的个数；第二个元素是一个标量或数据对，其中标量表示bucket的索引（从0开始），数据对表示bucket的索引范围（包含下限值，但不包括上限值）。</li></ul></li><li class="- topic/li li"><p class="- topic/p p">persistOffset是一个布尔值，表示是否持久化保存本次订阅已经处理的数据的偏移量，默认值为false。持久化保存的偏移量用于重订阅，可通过<code class="+ topic/ph pr-d/codeph ph codeph">getTopicProcessedOffset</code>函数获取。</p></li><li class="- topic/li li"><p class="- topic/p p">timeTrigger是一个布尔值。若设为true，表示即使没有新的消息进入，handler也会在throttle参数所设定的时间间隔被触发。</p></li><li class="- topic/li li"><p class="- topic/p p">handlerNeedMsgId是一个布尔值，默认值为false。若设为true，handler必须支持两个参数：一个是msgBody，一个是msgId。调用handler时，传入消息以及消息的偏移量。一个例子为函数<code class="+ topic/ph pr-d/codeph ph codeph">appendMsg</code>。若设为false，handler仅支持一个参数：msgBody。调用handler时，只传入消息本身。</p></li><li class="- topic/li li"><p class="- topic/p p">raftGroup是 raft 组的 ID。设置该参数表示开启订阅端高可用，不设置则表示普通订阅。设置 <em class="+ topic/ph hi-d/i ph i">raftGroup</em> 参数以指定 raft 组后，在对应 raft 组内 leader 发生切换时，新的 leader会 重新订阅。</p></li></ul></li></ol></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title9" id="23-断线重连"><h3 class="- topic/title title topictitle3" id="ariaid-title9">2.3. 断线重连</h3><div class="- topic/body body"><p class="- topic/p p">DolphinDB的流数据订阅提供了自动重连的功能。如果要启用自动重连，发布端必须对流数据持久化。当reconnect参数设为true时，订阅端会记录流数据的offset，连接中断时订阅端会从offset开始重新订阅。如果订阅端关闭或者发布端没有对流数据持久化，订阅端无法自动重连。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title10" id="24-发布端数据过滤"><h3 class="- topic/title title topictitle3" id="ariaid-title10">2.4. 发布端数据过滤</h3><div class="- topic/body body"><p class="- topic/p p">发布端可以过滤数据，只发布符合条件的数据。使用<code class="+ topic/ph pr-d/codeph ph codeph">setStreamTableFilterColumn</code>指定流数据表的过滤列（目前仅支持对一个列进行过滤），过滤列的值在filter中的数据会发布到订阅端，不在filter指定值中的数据不会发布。有关filter参数的介绍请见2.2小节。</p><p class="- topic/p p">下例中，值过滤的filter值是一个向量。发布端上的流数据表trades只发布symbol为IBM或GOOG的数据：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>share streamTable(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT]) as trades
setStreamTableFilterColumn(trades, `symbol)
trades_1=table(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT])

filter=symbol(`IBM`GOOG)

subscribeTable(tableName="trades", actionName="trades_1", handler=append!{trades_1}, msgAsTable=true, filter=filter)</code></pre><p class="- topic/p p">范围过滤的filter值是一个数据对。发布端上的流数据表trades只发布price大于等于1且小于100的数据：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>share streamTable(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT]) as trades
setStreamTableFilterColumn(trades, `price)
trades_1=table(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT])

subscribeTable(tableName="trades", actionName="trades_1", handler=append!{trades_1}, msgAsTable=true, filter=1:100)</code></pre><p class="- topic/p p">哈希过滤的filter值是一个元组。发布端上的流数据表trades对于symbol列使用哈希函数分为10个bucket，bucket索引从0开始，只发布索引大于等于1且小于5的数据：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>share streamTable(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT]) as trades
setStreamTableFilterColumn(trades, `symbol)
trades_1=table(10000:0,`time`symbol`price, [TIMESTAMP,SYMBOL,INT])

subscribeTable(tableName="trades", actionName="trades_1", handler=append!{trades_1}, msgAsTable=true, filter=(10,1:5))</code></pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title11" id="25-取消订阅"><h3 class="- topic/title title topictitle3" id="ariaid-title11">2.5. 取消订阅</h3><div class="- topic/body body"><p class="- topic/p p">每一次订阅都由一个订阅主题topic作为唯一标识。如果订阅时topic已存在，那么会订阅失败，需要通过<code class="+ topic/ph pr-d/codeph ph codeph">unsubscribeTable</code>函数取消订阅才能再次订阅。</p><p class="- topic/p p">取消订阅示例如下：</p><p class="- topic/p p">取消订阅一个本地表：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>unsubscribeTable(tableName="pubTable", actionName="act1")</code></pre><p class="- topic/p p">取消订阅一个远程表：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>unsubscribeTable(server="NODE_1", tableName="pubTable", actionName="act1")</code></pre><p class="- topic/p p">取消订阅一个本地表，但保留offset，以便下次从这个offset继续订阅：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>unsubscribeTable(tableName="pubTable", actionName="act1", removeOffset=false)</code></pre><p class="- topic/p p">从节点的内存中删除给定topic的offset：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>removeTopicOffset(topic)</code></pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title12" id="26-流数据持久化"><h3 class="- topic/title title topictitle3" id="ariaid-title12">2.6. 流数据持久化</h3><div class="- topic/body body"><p class="- topic/p p">默认情况下，流数据表把所有数据保存在内存中。基于以下三点考量，可将流数据持久化到磁盘。</p><ul class="- topic/ul ul"><li class="- topic/li li">流数据的备份和恢复。当节点出现异常重启时，持久化的数据会在重启时自动载入到流数据表。</li><li class="- topic/li li">避免内存不足。</li><li class="- topic/li li">可以从任意位置开始重新订阅数据。</li></ul><p class="- topic/p p">可事先设定一个界限值。若流数据表的行数达到设定的界限值，前面一半的记录行会持久化到磁盘。持久化的数据支持重订阅，当订阅指定offset时，offset的计算包含持久化的数据。</p><p class="- topic/p p">要持久化流数据表，在发布节点首先需要设置持久化路径参数persistenceDir:</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>persistenceDir = /da"data_replay.md"nableTableShareAndPersistence` 函数。下面的示例将pubTable共享为sharedPubTable，并把sharedPubTable持久化到磁盘。其中参数cacheSize=1000000，asynWrite与compress默认值均为true，表示当流数据表数据量达到100万行时启用持久化，将其中50%的数据采用异步方式压缩保存到磁盘。
</code></pre><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>pubTable=streamTable(10000:0,`timestamp`temperature, [TIMESTAMP,DOUBLE])
enableTableShareAndPersistence(table=pubTable, tableName=`sharedPubTable, cacheSize=1000000, preCache=500000)</code></pre><p class="- topic/p p">若执行<code class="+ topic/ph pr-d/codeph ph codeph">enableTableShareAndPersistence</code>时，磁盘上已经存在sharedPubTable表的持久化数据，那么系统会加载最新的preCache=500000行记录到内存中。</p><p class="- topic/p p">对于持久化是否启用异步，需要在持久化数据一致性和性能之间作权衡。当流数据的一致性要求较高时，可以使用同步方式，这样可以保证持久化完成以后，数据才会进入发布队列；若对实时性要求较高，不希望磁盘IO影响到流数据的实时性，则可启用异步方式。只有启用异步方式时，持久化工作线程数persistenceWorkerNum配置项才会起作用。若有多个发布表需要持久化，增加persistenceWorkerNum的配置值可以提升异步保存的效率。</p><p class="- topic/p p">当不需要保存在磁盘上的流数据时，通过<code class="+ topic/ph pr-d/codeph ph codeph">clearTablePersistence</code>函数可以删除持久化数据：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>clearTablePersistence(pubTable)</code></pre><p class="- topic/p p">关闭持久化，可以使用 <code class="+ topic/ph pr-d/codeph ph codeph">disableTablePersistence</code> 函数：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>disableTablePersistence(pubTable)</code></pre><p class="- topic/p p">使用<code class="+ topic/ph pr-d/codeph ph codeph">getPersistenceMeta</code>函数获取流数据表的持久化细节情况：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>getPersistenceMeta(pubTable);</code></pre><p class="- topic/p p">输出的结果是一个字典，有以下内容：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>//内存中的数据记录数
sizeInMemory-&gt;0
//启用异步持久化
asynWrite-&gt;true
//流数据表总记录数
totalSize-&gt;0
//启用压缩存储
compress-&gt;true
//当前内存中数据相对总记录数的偏移量，在持久化运行过程中遵循公式 memoryOffset = totalSize - sizeInMemory
memoryOffset-&gt;0
//已经持久化到磁盘的数据记录数
sizeOnDisk-&gt;0
//日志文件的保留时间，默认值是1440分钟，即一天。
retentionMinutes-&gt;1440
//持久化路径
persistenceDir-&gt;/hdd/persistencePath/pubTable
//hashValue是对本表做持久化的工作线程标识。
hashValue-&gt;0
//磁盘上第一条数据相对总记录数的偏移量。例如，若diskOffset=10000，表示目前磁盘上的持久化流数据从第10000条记录开始。
diskOffset-&gt;0</code></pre><p class="- topic/p p">调用dropStreamTable函数删除持久化流数据表，内存中和磁盘上的流数据均会被清除：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dropStreamTable(`pubTable);</code></pre></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title13" id="3-数据回放"><h2 class="- topic/title title topictitle2" id="ariaid-title13">3. 数据回放</h2><div class="- topic/body body"><p class="- topic/p p">DolphinDB提供了<code class="+ topic/ph pr-d/codeph ph codeph">replay</code>函数，可以将历史数据按照时间顺序导入流数据表中。具体教程请参考<a class="- topic/xref xref" href="data_replay.html">流数据回放教程</a>。</p></div></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title14" id="4-流数据计算引擎"><h2 class="- topic/title title topictitle2" id="ariaid-title14">4. 流数据计算引擎</h2><div class="- topic/body body"><p class="- topic/p p">DolphinDB提供<code class="+ topic/ph pr-d/codeph ph codeph">createTimeSeriesEngine</code>,<code class="+ topic/ph pr-d/codeph ph codeph">createDailyTimeSeriesEngine</code>,<code class="+ topic/ph pr-d/codeph ph codeph">createSessionWindowEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createAnomalyDetectionEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createReactiveStateEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createCrossSectionalEngine </code>, <code class="+ topic/ph pr-d/codeph ph codeph">createAsofJoinEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createEquiJoinEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createWindowJoinEngine</code>, <code class="+ topic/ph pr-d/codeph ph codeph">createLookupJoinEngine</code>等函数创建流数据计算引擎对流数据进行实时计算。</p><p class="- topic/p p">创建响应式状态引擎：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>rse = createReactiveStateEngine(name="reactiveDemo", metrics =&lt;cumsum(price)&gt;, dummyTable=tickStream, outputTable=result, keyColumn="sym", snapshotDir= "/home/data/snapshot", snapshotIntervalInMsgCount=20000)</code></pre><p class="- topic/p p">调用dropStreamEngine函数释放流数据引擎：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dropStreamEngine("reactiveDemo")</code></pre><p class="- topic/p p">此外，DolphinDB流计算引擎还包括流水线处理、并行处理、快照机制等重要特性。</p><p class="- topic/p p"><strong class="+ topic/ph hi-d/b ph b">注意</strong>：DolphinDB 1.30.21/2.00.9 及之前的版本不支持对流计算引擎的并发访问（例如，两个输入表并发写入同一引擎）。 如需使用此功能，要求 server 版本号必须高于 1.30.21/2.00.9，且必须使用 share 语句/函数共享引擎，例如 <code class="+ topic/ph pr-d/codeph ph codeph">share(engine, name)</code> 或 <code class="+ topic/ph pr-d/codeph ph codeph">share engien as name</code>（要求引擎共享后的名称和引擎名称相同）。</p></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title15" id="41-流水线处理"><h3 class="- topic/title title topictitle3" id="ariaid-title15">4.1. 流水线处理</h3><div class="- topic/body body"><p class="- topic/p p">DolphinDB内置的流计算引擎均实现了数据表（table）的接口，因此多个引擎流水线处理变得异常简单，只要将后一个引擎作为前一个引擎的输出即可。引入流水线处理，可以解决更为复杂的因子计算问题。譬如，因子计算经常需要使用面板数据，完成时间序列和横截面两个维度的计算，只要把响应式状态引擎和横截面两个引擎串联处理即可完成。</p><p class="- topic/p p">下面的例子是World Quant 101个Alpha因子中的1号因子公式的流数据实现。rank函数是一个横截面操作。rank的参数部分用响应式状态引擎实现。rank函数本身用横截面引擎实现。横截面引擎作为状态引擎的输出。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>Alpha#001公式：rank(Ts_ArgMax(SignedPower((returns&lt;0?stddev(returns,20):close), 2), 5))-0.5

//创建横截面引擎，计算每个股票的rank
dummy = table(1:0, `sym`time`maxIndex, [SYMBOL, TIMESTAMP, DOUBLE])
resultTable = streamTable(10000:0, `time`sym`factor1, [TIMESTAMP, SYMBOL, DOUBLE])
ccsRank = createCrossSectionalAggregator(name="alpha1CCS", metrics=&lt;[sym, rank(maxIndex, percent=true) - 0.5]&gt;,  dummyTable=dummy, outputTable=resultTable,  keyColumn=`sym, triggeringPattern='keyCount', triggeringInterval=3000, timeColumn=`time, useSystemTime=false)

@state
def wqAlpha1TS(close){
    ret = ratios(close) - 1
    v = iif(ret &lt; 0, mstd(ret, 20), close)
    return mimax(signum(v)*v*v, 5)
}

//创建响应式状态引擎，输出到前面的横截面引擎ccsRank
input = table(1:0, `sym`time`close, [SYMBOL, TIMESTAMP, DOUBLE])
rse = createReactiveStateEngine(name="alpha1", metrics=&lt;[time, wqAlpha1TS(close)]&gt;, dummyTable=input, outputTable=ccsRank, keyColumn="sym")</code></pre><p class="- topic/p p">流水线处理（也称为引擎多级级联）和多个流数据表的级联处理有很大的区别。两者可以完成相同的任务，但是效率上有很大的区别。后者涉及多个流数据表与多次订阅。前者实际上只有一次订阅，所有的计算均在一个线程中依次顺序完成，因而有更好的性能。</p><p class="- topic/p p">上面的例子是由用户来区分哪一部分是横截面操作，哪一部分是时间序列操作以实现多个引擎的流水线。在1.30.16/2.00.4及之后的版本中，新增函数 <code class="+ topic/ph pr-d/codeph ph codeph">streamEngineParser</code>，支持将metrics自动分解成多个内置流计算引擎的流水线。在<code class="+ topic/ph pr-d/codeph ph codeph">streamEngineParser</code>中以行函数（rowRank，rowSum等）表示横截面操作的语义，以rolling函数表示时间序列操作，从而系统能够自动识别一个因子中的横截面操作和时间序列操作，进一步自动构建引擎流水线。因此，上述因子可以用<code class="+ topic/ph pr-d/codeph ph codeph">streamEngineParser</code>更简洁的实现，metrics几乎等同于因子的数学公式表达，而不需要考虑不同类型引擎的选择：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>@state
def wqAlpha1TS(close){
    ret = ratios(close) - 1
    v = iif(ret &lt; 0, mstd(ret, 20), close)
    return mimax(signum(v)*v*v, 5)
}

//构建计算因子
metrics=&lt;[sym, rowRank(wqAlpha1TS(close), percent=true)- 0.5]&gt;

streamEngine=streamEngineParser(name=`alpha1_parser, metrics=metrics, dummyTable=input, outputTable=resultTable, keyColumn=`sym, timeColumn=`time, triggeringPattern='keyCount', triggeringInterval=3000)</code></pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title16" id="42-并行处理"><h3 class="- topic/title title topictitle3" id="ariaid-title16">4.2. 并行处理</h3><div class="- topic/body body"><p class="- topic/p p">当需要处理大量消息时，可在DolphinDB消息订阅函数<code class="+ topic/ph pr-d/codeph ph codeph">subscribeTable</code>中指定可选参数filter与hash，让多个订阅客户端并行处理消息。</p><p class="- topic/p p">下面是响应式状态引擎并行计算因子的例子。假设配置参数subExecutors=4，创建4个状态引擎，每个状态引擎根据流表的股票代码的哈希值来订阅不同股票的数据，并且指定不同的订阅线程来处理，最终将结果输出到同一个输出表中。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>share streamTable(1:0, `sym`price, [STRING,DOUBLE]) as tickStream
setStreamTableFilterColumn(tickStream, `sym)
share streamTable(1000:0, `sym`factor1, [STRING,DOUBLE]) as resultStream

for(i in 0..3){
    rse = createReactiveStateEngine(name="reactiveDemo"+string(i), metrics =&lt;cumsum(price)&gt;, dummyTable=tickStream, outputTable=resultStream, keyColumn="sym")
    subscribeTable(tableName=`tickStream, actionName="sub"+string(i), handler=tableInsert{rse}, msgAsTable = true, hash = i, filter = (4,i))
}</code></pre><p class="- topic/p p">需要注意的是，如果多个状态引擎是同一个输出表，该输出表必须是一个共享表。没有共享的表不是线程安全的，并行写入可能会导致系统崩溃。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title17" id="43-快照机制"><h3 class="- topic/title title topictitle3" id="ariaid-title17">4.3. 快照机制</h3><div class="- topic/body body"><p class="- topic/p p">为了满足生产环境业务持续性的需要，DolphinDB内置的流式计算引擎除连接引擎外均支持快照（snapshot）输出。</p><p class="- topic/p p">以响应式状态引擎为例，该引擎的快照包括已处理的最后一条消息的ID以及引擎当前的状态（中间计算结果）。当系统出现异常，重新初始化状态引擎时，可恢复到最后一个快照的状态，并且从已处理的消息的下一条开始订阅。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>share streamTable(1:0, `sym`price, [STRING,DOUBLE]) as tickStream
result = table(1000:0, `sym`factor1, [STRING,DOUBLE])
rse = createReactiveStateEngine(name="reactiveDemo", metrics =&lt;cumsum(price)&gt;, dummyTable=tickStream, outputTable=result, keyColumn="sym", snapshotDir= "/home/data/snapshot", snapshotIntervalInMsgCount=20000)
msgId = getSnapshotMsgId(rse)
if(msgId &gt;= 0) msgId += 1
subscribeTable(tableName=`tickStream, actionName="factors", offset=msgId, handler=appendMsg{rse}, handlerNeedMsgId=true)</code></pre><p class="- topic/p p">响应式状态引擎要启用快照机制，创建时需要指定两个额外的参数snapshotDir和snapshotIntervalInMsgCount。snapshotDir用于指定存储快照的目录。snapshotIntervalInMsgCount指定处理多少条消息后产生一个快照。引擎初始化时，系统会检查快照目录下是否存在一个以引擎名称命名，后缀为snapshot的文件。以上面的代码为例，如果存在文件/home/data/snapshot/reactiveDemo.snapshot，加载这个快照。函数getSnapshotMsgId可以获取最近一个快照对应的msgId。如果不存在快照，返回-1。</p><p class="- topic/p p">状态引擎要启用快照机制，调用<code class="+ topic/ph pr-d/codeph ph codeph">subscribeTable</code>函数也需相应的修改：</p><ul class="- topic/ul ul"><li class="- topic/li li">首先必须指定消息的offset。</li><li class="- topic/li li">其次，handler必须使用appendMsg函数。appendMsg函数接受两个参数，msgBody和msgId。</li><li class="- topic/li li">再次，参数handlerNeedMsgId必须指定为true。</li></ul><p class="- topic/p p">上例为普通订阅在宕机后重新提交订阅并从快照处恢复流数据处理。在5高可用章节中，通过高可用流订阅自定恢复订阅时将不再需要通过getSnapshotMsgId函数获取msgId来指定offset，也不需要使用appendMsg函数。</p></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title18" id="5-高可用"><h2 class="- topic/title title topictitle2" id="ariaid-title18">5. 高可用</h2><div class="- topic/body body"></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title19" id="51-流数据高可用"><h3 class="- topic/title title topictitle3" id="ariaid-title19">5.1. 流数据高可用</h3><div class="- topic/body body"><p class="- topic/p p">为满足流数据服务不中断的需求，DolphinDB采用了基于Raft协议的高可用多副本架构，以提供流数据的高可用功能。具体教程请参考<a class="- topic/xref xref" href="haStreaming.html">流数据高可用教程</a>。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title20" id="52-流计算引擎高可用"><h3 class="- topic/title title topictitle3" id="ariaid-title20">5.2. 流计算引擎高可用</h3><div class="- topic/body body"><p class="- topic/p p">在流数据和流数据订阅高可用的基础上，DolphinDB还支持了流计算引擎的高可用，以保证实时流处理不中断。若引擎开启高可用，在 leader 节点创建流数据引擎后，会同步在 follower 节点创建该引擎。引擎通过快照机制每次保存的 snapshot 也会同步到 follower。当 leader 节点宕机时，会自动切换新 leader 节点重新订阅流数据表，并且自动根据 snapshot 恢复到最后一个快照的状态并从此处继续实时处理。</p><p class="- topic/p p">下面的例子中在Raft组2上创建了两个高可用流数据表，创建了一个高可用状态引擎，并提交了高可用流订阅。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>haStreamTable(raftGroup=2, table=table(1:0, `sym`price, [STRING,DOUBLE]), tableName="haTickStream", cacheLimit=10000)
haStreamTable(raftGroup=2, table=table(1:0, `sym`factor1, [STRING,DOUBLE]), tableName="result", cacheLimit=10000)		

ret = createReactiveStateEngine(name="haReact", metrics=&lt;cumsum(price)&gt;, dummyTable=objByName("haTickStream"), outputTable=objByName("result"), keyColumn=`sym, snapshotDir= "/home/data/snapshot", snapshotIntervalInMsgCount=20000, raftGroup=2)
subscribeTable(tableName="haTickStream", actionName="haFactors", offset=-1, handler=getStreamEngine("haReact"), msgAsTable=true, reconnect=true, persistOffset=true, handlerNeedMsgId=true, raftGroup=2)</code></pre><p class="- topic/p p">在调用<code class="+ topic/ph pr-d/codeph ph codeph">createReactiveStateEngine</code>创建引擎时需要注意：启动引擎高可用必须指定参数 raftGroup ，并且必须同时指定参数 snapshotDir 和 snapshotIntervalInMsgCount 。</p><p class="- topic/p p">在调用调用<code class="+ topic/ph pr-d/codeph ph codeph">subscribeTable</code>时提交订阅时需要注意：</p><ul class="- topic/ul ul"><li class="- topic/li li"><p class="- topic/p p">开启订阅端高可用，必须指定参数 raftGroup。若指定了 raftGroup，则只能在 leader 上执行。</p></li><li class="- topic/li li"><p class="- topic/p p">启动计算引擎高可用，必须指定 handlerNeedMsgId 为true。此时， handler 只能是计算引擎，即 handler = engine(创建引擎时返回的句柄变量)或 handler = getStreamEngine(引擎名称)。</p></li><li class="- topic/li li"><p class="- topic/p p">订阅高可用流数据表，需要设置 reconnect 为 true，以保证 leader 发生切换时可以成功连接新的 leader。</p></li><li class="- topic/li li"><p class="- topic/p p">订阅高可用流数据表，需要设置 persistOffset 为 true，以防止订阅端丢失数据。</p></li></ul></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title21" id="6-流数据api"><h2 class="- topic/title title topictitle2" id="ariaid-title21">6. 流数据API</h2><div class="- topic/body body"><p class="- topic/p p">流数据的消费者可能是DolphinDB内置的计算引擎，也可能是第三方的消息队列或者第三方程序。DolphinDB提供了streaming API供第三方程序来订阅流数据。当有新数据注入时，API的订阅者能够及时接收到通知，这使得DolphinDB的流数据框架可与第三方的应用进行深入的整合。DolphinDB的API（Java, Python, C++, C#）提供了接口来订阅流数据。</p></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title22" id="61-python-api"><h3 class="- topic/title title topictitle3" id="ariaid-title22">6.1. Python API</h3><div class="- topic/body body"><p class="- topic/p p">Python API提供流数据订阅的相关方法，用于订阅DolphinDB服务端的数据。</p></div><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title23" id="611-python客户端流数据订阅示例"><h4 class="- topic/title title topictitle4" id="ariaid-title23">6.1.1. Python客户端流数据订阅示例</h4><div class="- topic/body body"><p class="- topic/p p">下面简单介绍一下Python API提供的流数据订阅的相关方法与使用示例。</p><ol class="- topic/ol ol"><li class="- topic/li li"><p class="- topic/p p">指定客户端的订阅端口号</p><p class="- topic/p p">使用Python API提供的<code class="+ topic/ph pr-d/codeph ph codeph">enableStreaming</code>函数启用流数据功能：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>import dolphindb as ddb
conn = ddb.session()
conn.enableStreaming(8000)</code></pre></li><li class="- topic/li li"><p class="- topic/p p">调用订阅函数</p><p class="- topic/p p">使用Python API提供的<code class="+ topic/ph pr-d/codeph ph codeph">subscribe</code>函数来订阅DolphinDB中的流数据表。</p><p class="- topic/p p">示例：</p><p class="- topic/p p">在DolphinDB中创建共享的流数据表，并插入一些随机数据：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>share streamTable(1:0,`id`price`qty,[INT,DOUBLE,INT]) as trades
trades.append!(table(1..10 as id,rand(10.0,10) as price,rand(10,10) as qty))</code></pre><p class="- topic/p p">在Python中订阅trades表：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def printMsg(msg):
    print(msg)

conn.subscribe("192.168.1.103", 8941, printMsg, "trades", "sub_trades", 0)

[1, 0.47664969926699996, 8]
[2, 5.543625105638057, 4]
[3, 8.10016839299351, 4]
[4, 5.821204076055437, 9]
[5, 9.768875930458307, 0]
[6, 3.7460641632787883, 7]
[7, 2.4479272053577006, 6]
[8, 9.394394161645323, 5]
[9, 5.966209815815091, 6]
[10, 0.03534660907462239, 2]</code></pre></li><li class="- topic/li li"><p class="- topic/p p">取消订阅</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>conn.unsubscribe("192.168.1.103", 8941,"trades","sub_trades")</code></pre></li></ol></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title24" id="612-dolphindb服务端流数据订阅示例"><h4 class="- topic/title title topictitle4" id="ariaid-title24">6.1.2. DolphinDB服务端流数据订阅示例</h4><div class="- topic/body body"><p class="- topic/p p">DolphinDB可以订阅来自Python客户端的流数据。下面的例子中，我们在Python客户端订阅第三方数据到多个DataFrame中，通过DolphinDB的流数据订阅功能将多个表中的数据写入到分布式表中。</p><p class="- topic/p p">首先，在DolphinDB服务端执行以下脚本，创建数据库和表：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>login('admin','123456')

// 定义表结构
n=20000000
colNames =`Code`Date`DiffAskVol`DiffAskVolSum`DiffBidVol`DiffBidVolSum`FirstDerivedAskPrice`FirstDerivedAskVolume`FirstDerivedBidPrice`FirstDerivedBidVolume
colTypes = [SYMBOL,DATE,INT,INT,INT,INT,FLOAT,INT,FLOAT,INT]

// 创建数据库与分布式表
dbPath= "dfs://ticks"
if(existsDatabase(dbPath))
   dropDatabase(dbPath)
db=database(dbPath,VALUE, 2000.01.01..2030.12.31)
dfsTB=db.createPartitionedTable(table(n:0, colNames, colTypes),`tick,`Date)</code></pre><p class="- topic/p p">下面，我们将定义两个流数据表<code class="+ topic/ph pr-d/codeph ph codeph">mem_stream_d</code>和<code class="+ topic/ph pr-d/codeph ph codeph">mem_stream_f</code>，客户端往流数据表写入数据，由服务端订阅数据。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>// 定义mem_tb_d表,并开启流数据持久化，将共享表命名为mem_stream_d
mem_tb_d=streamTable(n:0, colNames, colTypes)
enableTableShareAndPersistence(mem_tb_d,'mem_stream_d',false,true,n)

// 定义mem_tb_f表,并开启流数据持久化，将共享表命名为mem_stream_f
mem_tb_f=streamTable(n:0,colNames, colTypes)
enableTableShareAndPersistence(mem_tb_f,'mem_stream_f',false,true,n)</code></pre><p class="- topic/p p"><strong class="+ topic/ph hi-d/b ph b">注意</strong>：由于表的分区字段是按照日期进行分区，而客户端往<code class="+ topic/ph pr-d/codeph ph codeph">mem_stream_d</code>和<code class="+ topic/ph pr-d/codeph ph codeph">mem_stream_f</code>表中写的数据会有日期上的重叠，若直接由分布式表<code class="+ topic/ph pr-d/codeph ph codeph">tick</code>同时订阅这两个表的数据，就会造成这两个表同时往同一个日期分区写数据，导致写入失败。因此，我们需要定义另一个流表<code class="+ topic/ph pr-d/codeph ph codeph">ticks_stream</code>来汇集<code class="+ topic/ph pr-d/codeph ph codeph">mem_stream_d</code>和<code class="+ topic/ph pr-d/codeph ph codeph">mem_stream_f</code>表的数据，最后串行写入<code class="+ topic/ph pr-d/codeph ph codeph">tick</code>分布式表。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>// 定义ftb表，并开启流数据持久化，将共享表命名为ticks_stream
ftb=streamTable(n:0, colNames, colTypes)
enableTableShareAndPersistence(ftb,'ticks_stream',false,true,n)
go

// ticks_stream订阅mem_stream_d表的数据
def saveToTicksStreamd(mutable TB, msg): TB.append!(select * from msg)
subscribeTable(, 'mem_stream_d', 'action_to_ticksStream_tde', 0, saveToTicksStreamd{ticks_stream}, true, 100)

// ticks_stream同时订阅mem_stream_f表的数据
def saveToTicksStreamf(mutable TB, msg): TB.append!(select * from msg)
subscribeTable(, 'mem_stream_f', 'action_to_ticksStream_tfe', 0, saveToTicksStreamf{ticks_stream}, true, 100)

// dfsTB订阅ticks_stream表的数据
def saveToDFS(mutable TB, msg): TB.append!(select * from msg)
subscribeTable(, 'ticks_stream', 'action_to_dfsTB', 0, saveToDFS{dfsTB}, true, 100, 5)</code></pre><p class="- topic/p p">上述几个步骤中，我们定义了一个数据库并创建分布式表<code class="+ topic/ph pr-d/codeph ph codeph">tick</code>，以及三个流数据表，分别为<code class="+ topic/ph pr-d/codeph ph codeph">mem_stream_d</code>、<code class="+ topic/ph pr-d/codeph ph codeph">mem_stream_f</code>和<code class="+ topic/ph pr-d/codeph ph codeph">ticks_stream</code>。客户端将第三方订阅而来的数据不断地追加到<code class="+ topic/ph pr-d/codeph ph codeph">mem_stream_d</code>和<code class="+ topic/ph pr-d/codeph ph codeph">mem_stream_f</code>表中，而写入这两个表的数据会被汇集到<code class="+ topic/ph pr-d/codeph ph codeph">ticks_stream</code>表。最后，<code class="+ topic/ph pr-d/codeph ph codeph">ticks_stream</code>表内的数据顺序地写入分布式表<code class="+ topic/ph pr-d/codeph ph codeph">tick</code>中。</p><p class="- topic/p p">下面，我们将第三方订阅到的数据上传到DolphinDB，通过DolphinDB流数据订阅功能将数据追加到分布式表。我们假定Python客户端从第三方订阅到的数据已经保存在两个名为<code class="+ topic/ph pr-d/codeph ph codeph">dfd</code>和<code class="+ topic/ph pr-d/codeph ph codeph">dff</code>的DataFrame中：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock Python"><code>n = 10000
dfd = pd.DataFrame({'Code': np.repeat(['SH000001', 'SH000002', 'SH000003', 'SH000004', 'SH000005'], n/5),
                    'Date': np.repeat(pd.date_range('1990.01.01', periods=10000, freq='D'), n/10000),
                    'DiffAskVol': np.random.choice(100, n),
                    'DiffAskVolSum': np.random.choice(100, n),
                    'DiffBidVol': np.random.choice(100, n),
                    'DiffBidVolSum': np.random.choice(100, n),
                    'FirstDerivedAskPrice': np.random.choice(100, n)*0.9,
                    'FirstDerivedAskVolume': np.random.choice(100, n),
                    'FirstDerivedBidPrice': np.random.choice(100, n)*0.9,
                    'FirstDerivedBidVolume': np.random.choice(100, n)})

n = 20000
dff = pd.DataFrame({'Code': np.repeat(['SZ000001', 'SZ000002', 'SZ000003', 'SZ000004', 'SZ000005'], n/5),
                    'Date': np.repeat(pd.date_range('1990.01.01', periods=10000, freq='D'), n/10000),
                    'DiffAskVol': np.random.choice(100, n),
                    'DiffAskVolSum': np.random.choice(100, n),
                    'DiffBidVol': np.random.choice(100, n),
                    'DiffBidVolSum': np.random.choice(100, n),
                    'FirstDerivedAskPrice': np.random.choice(100, n)*0.9,
                    'FirstDerivedAskVolume': np.random.choice(100, n),
                    'FirstDerivedBidPrice': np.random.choice(100, n)*0.9,
                    'FirstDerivedBidVolume': np.random.choice(100, n)})</code></pre><p class="- topic/p p"><strong class="+ topic/ph hi-d/b ph b">注意</strong>： 在向流数据表追加一个带有时间列的表时，我们需要对时间列进行时间类型转换：首先将整个DataFrame上传到DolphinDB服务器，再通过select语句将其中的列取出，并转换时间类型列的数据类型，最后通过<code class="+ topic/ph pr-d/codeph ph codeph">tableInsert</code>语句追加表。具体原因与向内存表追加一个DataFrame类似，请参见DolphinDB Python API教程。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock Python"><code>dbDir = "dfs://ticks"
tableName = 'tick'
s.upload({'dfd': dfd, 'dff': dff})
inserts = """tableInsert(mem_stream_d,select Code,date(Date) as Date,DiffAskVol,DiffAskVolSum,DiffBidVol,DiffBidVolSum,FirstDerivedAskPrice,FirstDerivedAskVolume,FirstDerivedBidPrice,FirstDerivedBidVolume from dfd);
tableInsert(mem_stream_f,select Code,date(Date) as Date,DiffAskVol,DiffAskVolSum,DiffBidVol,DiffBidVolSum,FirstDerivedAskPrice,FirstDerivedAskVolume,FirstDerivedBidPrice,FirstDerivedBidVolume from dff)"""
s.run(inserts)
s.run("select count(*) from loadTable('{dbPath}', `{tbName})".format(dbPath=dbDir,tbName=tableName))

// output
   count
0  30000</code></pre><p class="- topic/p p">在DolphinDB 服务端执行以下脚本结束订阅：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def clears(tbName,action)
{
	unsubscribeTable(tableName=tbName, actionName=action)
	clearTablePersistence(objByName(tbName))
	undef(tbName,SHARED)
}
clears(`ticks_stream, `action_to_dfsTB)
clears(`mem_stream_d,`action_to_ticksStream_tde)
clears(`mem_stream_f,`action_to_ticksStream_tfe)</code></pre></div></article></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title25" id="7-状态监控"><h2 class="- topic/title title topictitle2" id="ariaid-title25">7. 状态监控</h2><div class="- topic/body body"><p class="- topic/p p">当通过订阅方式对流数据进行实时处理时，所有的计算都在后台进行，用户无法直观的看到运行的情况。DolphinDB提供以下函数监控流数据处理及流计算引擎的状态：</p><ul class="- topic/ul ul"><li class="- topic/li li">getStreamingStat：全方位监控流数据处理过程。</li><li class="- topic/li li">getStreamEngineStat：可以查看系统中定义的全部流计算引擎、各个引擎的内存占用等状态，每一类引擎对应一张表。</li></ul></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title26" id="71-流数据处理状态"><h3 class="- topic/title title topictitle3" id="ariaid-title26">7.1. 流数据处理状态</h3><div class="- topic/body body"><p class="- topic/p p"><code class="+ topic/ph pr-d/codeph ph codeph">getStreamingStat</code> 函数返回一个dictionary，包含以下五个表：</p><ul class="- topic/ul ul"><li class="- topic/li li">pubConns：列出该节点所有的订阅节点信息，发布队列情况，以及流数据表名称。</li><li class="- topic/li li">subConns：列出每个本地节点订阅的所有发布节点的连接状态和有关接收消息的统计信息。</li><li class="- topic/li li">persistWorkers：只有持久化启用后，才能通过<code class="+ topic/ph pr-d/codeph ph codeph">getStreamingStat</code>获取persistWorkers表。这张表的记录数等于persistenceWorkerNum配置值。若要并行处理持久化数据表的任务，可设置persistenceWorkerNum&gt;1。</li><li class="- topic/li li">subWorkers：表监控流数据订阅工作线程。当有流数据进入时，可以通过该表观察到已处理数据的信息。</li><li class="- topic/li li">pubTables：表监控流数据表被订阅情况</li><li class="- topic/li li"></li></ul><p class="- topic/p p">在调用<code class="+ topic/ph pr-d/codeph ph codeph">subscribeTable</code>函数后，通过 getStreamingStat().pubTables 可以立刻查看到对应的订阅任务。在工作线程实际处理到数据后，才可以在 getStreamingStat().subWorkers 中查看到对应的工作线程的状态。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title27" id="72-流计算状态"><h3 class="- topic/title title topictitle3" id="ariaid-title27">7.2. 流计算状态</h3><div class="- topic/body body"><p class="- topic/p p">在调用<code class="+ topic/ph pr-d/codeph ph codeph">subscribeTable</code>函数后，用 <code class="+ topic/ph pr-d/codeph ph codeph">getStreamingStat().pubTables</code> 可以立刻查看到对应的订阅任务，在工作线程实际处理到数据后，才可以在 <code class="+ topic/ph pr-d/codeph ph codeph">getStreamingStat().subWorkers</code> 中查看到对应的工作线程的状态。</p></div><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title28" id="721-pubconns表"><h4 class="- topic/title title topictitle4" id="ariaid-title28">7.2.1. pubConns表</h4><div class="- topic/body body"><p class="- topic/p p">pubConns表监控本地发布节点和它的所有订阅节点之间的连接状态。每一行表示本地发布节点的一个订阅节点。它包含以下列：</p><div class="table-container"><table class="- topic/table table" data-cols="2"><caption></caption><colgroup><col/><col/></colgroup><thead class="- topic/thead thead"><tr class="- topic/row"><th class="- topic/entry entry colsep-0 rowsep-0" id="721-pubconns表__entry__1">列名称</th><th class="- topic/entry entry colsep-0 rowsep-0" id="721-pubconns表__entry__2">说明</th></tr></thead><tbody class="- topic/tbody tbody"><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="721-pubconns表__entry__1">client</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="721-pubconns表__entry__2">订阅节点的IP和端口信息</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="721-pubconns表__entry__1">queueDepthLimit</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="721-pubconns表__entry__2">发布节点消息队列允许的最大深度（消息数）。每个发布节点只有一个发布消息队列。</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="721-pubconns表__entry__1">queueDepth</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="721-pubconns表__entry__2">发布节点消息队列深度（消息数）</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="721-pubconns表__entry__1">tables</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="721-pubconns表__entry__2">该节点上的所有共享的流数据表。若多表，彼此通过逗号分隔。</td></tr></tbody></table></div><p class="- topic/p p">在GUI中运行getStreamingStat().pubConns查看表内容：</p><br/><img class="- topic/image image" src="images/streaming/pubconn.png"/><br/><p class="- topic/p p">pubConns表会列出该节点所有的订阅节点信息，发布队列情况，以及流数据表名称。</p></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title29" id="722-subconns表"><h4 class="- topic/title title topictitle4" id="ariaid-title29">7.2.2. subConns表</h4><div class="- topic/body body"><p class="- topic/p p">subConns表监控本地订阅节点与其订阅的发布节点之间的连接状态。每个订阅的发布节点为表中一行。</p><div class="table-container"><table class="- topic/table table" data-cols="2"><caption></caption><colgroup><col/><col/></colgroup><thead class="- topic/thead thead"><tr class="- topic/row"><th class="- topic/entry entry colsep-0 rowsep-0" id="722-subconns表__entry__1">列名称</th><th class="- topic/entry entry colsep-0 rowsep-0" id="722-subconns表__entry__2">说明</th></tr></thead><tbody class="- topic/tbody tbody"><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="722-subconns表__entry__1">publisher</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="722-subconns表__entry__2">发布节点别名</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="722-subconns表__entry__1">cumMsgCount</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="722-subconns表__entry__2">累计接收消息数</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="722-subconns表__entry__1">cumMsgLatency</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="722-subconns表__entry__2">累计接收消息的平均延迟时间(毫秒)。延迟时间指的是消息从进入发布队列到进入订阅队列的耗时。</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="722-subconns表__entry__1">lastMsgLatency</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="722-subconns表__entry__2">最后一次接收数据延迟时间(毫秒)</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="722-subconns表__entry__1">lastUpdate</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="722-subconns表__entry__2">最后一次接收数据时刻</td></tr></tbody></table></div><p class="- topic/p p">在GUI中运行getStreamingStat().subConns查看表内容：</p><br/><img class="- topic/image image" src="images/streaming/subconn.png"/><br/><p class="- topic/p p">这张表列出每个本地节点订阅的所有发布节点的连接状态和有关接收消息的统计信息。</p></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title30" id="723-persistworkers表"><h4 class="- topic/title title topictitle4" id="ariaid-title30">7.2.3. persistWorkers表</h4><div class="- topic/body body"><p class="- topic/p p">persistWorkers表监控流数据表持久化工作线程，每个工作线程为一行。</p><div class="table-container"><table class="- topic/table table" data-cols="2"><caption></caption><colgroup><col/><col/></colgroup><thead class="- topic/thead thead"><tr class="- topic/row"><th class="- topic/entry entry colsep-0 rowsep-0" id="723-persistworkers表__entry__1">列名称</th><th class="- topic/entry entry colsep-0 rowsep-0" id="723-persistworkers表__entry__2">说明</th></tr></thead><tbody class="- topic/tbody tbody"><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="723-persistworkers表__entry__1">workerId</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="723-persistworkers表__entry__2">工作线程编号</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="723-persistworkers表__entry__1">queueDepthLimit</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="723-persistworkers表__entry__2">持久化消息队列深度限制</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="723-persistworkers表__entry__1">queueDepth</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="723-persistworkers表__entry__2">持久化消息队列深度</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="723-persistworkers表__entry__1">tables</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="723-persistworkers表__entry__2">持久化表名。若多表，彼此通过逗号分隔。</td></tr></tbody></table></div><p class="- topic/p p">只有持久化启用后，才能通过<code class="+ topic/ph pr-d/codeph ph codeph">getStreamingStat</code>获取persistWorkers表。这张表的记录数等于persistenceWorkerNum配置值。以下例子在GUI中运行getStreamingStat().persistWorkers查看持久化两张数据表的线程。</p><p class="- topic/p p">当persistenceWorkerNum=1时：</p><br/><img class="- topic/image image" src="images/streaming/persistworker.png" alt="image"/><br/><p class="- topic/p p">当persistenceWorkerNum=3时：</p><br/><img class="- topic/image image" src="images/streaming/persisWorders_2.png" alt="image"/><br/><p class="- topic/p p">从图上可以直观的看出，若要并行处理持久化数据表的任务，可设置persistenceWorkerNum&gt;1。</p></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title31" id="724-subworkers表"><h4 class="- topic/title title topictitle4" id="ariaid-title31">7.2.4. subWorkers表</h4><div class="- topic/body body"><p class="- topic/p p">subWorkers表监控流数据订阅工作线程，每条记录代表一个订阅主题。</p><div class="table-container"><table class="- topic/table table" data-cols="2"><caption></caption><colgroup><col/><col/></colgroup><thead class="- topic/thead thead"><tr class="- topic/row"><th class="- topic/entry entry colsep-0 rowsep-0" id="724-subworkers表__entry__1">列名称</th><th class="- topic/entry entry colsep-0 rowsep-0" id="724-subworkers表__entry__2">说明</th></tr></thead><tbody class="- topic/tbody tbody"><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__1">workerId</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__2">工作线程编号</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__1">topic</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__2">订阅主题</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__1">queueDepthLimit</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__2">订阅消息队列最大限制</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__1">queueDepth</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__2">订阅消息队列深度</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__1">processedMsgCount</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__2">已进入handler的消息数量</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__1">failedMsgCount</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__2">handler处理异常的消息数量</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__1">lastErrMsg</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="724-subworkers表__entry__2">上次handler处理异常的信息</td></tr></tbody></table></div><p class="- topic/p p">配置项subExecutors与subExecutorPooling这两个配置项的对流数据处理的影响，在这张表上可以得到充分的展现。在GUI中使用getStreamingStat().subWorkers查看。</p><p class="- topic/p p">当subExecutorPooling=false,subExecutors=1时，内容如下：</p><br/><img class="- topic/image image" src="images/streaming/subworker_1.png"/><br/><p class="- topic/p p">此时，所有表的订阅消息共用一个线程队列。</p><p class="- topic/p p">当subExecutorPooling=false,subExecutors=2时，内容如下：</p><br/><img class="- topic/image image" src="images/streaming/subworker_2.png"/><br/><p class="- topic/p p">此时，各个表订阅消息分配到两个线程队列独立处理。</p><p class="- topic/p p">当subExecutorPooling=true,subExecutors=2时，内容如下：</p><br/><img class="- topic/image image" src="images/streaming/subworker_pool.png"/><br/><p class="- topic/p p">此时，各个表的订阅消息共享由两个线程组成的线程池。</p><p class="- topic/p p">当有流数据进入时，可以通过这个表观察到已处理数据量等信息：</p><br/><img class="- topic/image image" src="images/streaming/subworker_msg.png"/><br/></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title32" id="725-pubtables表"><h4 class="- topic/title title topictitle4" id="ariaid-title32">7.2.5. pubTables表</h4><div class="- topic/body body"><p class="- topic/p p">pubTables表监控流数据表被订阅情况，每条记录代表流数据表一个订阅连接。</p><div class="table-container"><table class="- topic/table table" data-cols="2"><caption></caption><colgroup><col/><col/></colgroup><thead class="- topic/thead thead"><tr class="- topic/row"><th class="- topic/entry entry colsep-0 rowsep-0" id="725-pubtables表__entry__1">列名称</th><th class="- topic/entry entry colsep-0 rowsep-0" id="725-pubtables表__entry__2">说明</th></tr></thead><tbody class="- topic/tbody tbody"><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="725-pubtables表__entry__1">tableName</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="725-pubtables表__entry__2">发布表名称</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="725-pubtables表__entry__1">subscriber</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="725-pubtables表__entry__2">订阅方的host和port</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="725-pubtables表__entry__1">msgOffset</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="725-pubtables表__entry__2">订阅线程当前订阅消息的offset</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="725-pubtables表__entry__1">actions</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="725-pubtables表__entry__2">订阅的action。若有多个action，此处用逗号分割</td></tr></tbody></table></div><p class="- topic/p p">比如存流数据发布表名称为pubTable1，发布了100条记录。 有一个订阅从offset=0开始，action名称为"
act_getdata"。那么当订阅完成之后，用getStreamingStat().pubTables 查看内容为：</p><br/><img class="- topic/image image" src="images/streaming/pubtables1.png"/><br/></div></article></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title33" id="73-流数据引擎状态"><h3 class="- topic/title title topictitle3" id="ariaid-title33">7.3. 流数据引擎状态</h3><div class="- topic/body body"><p class="- topic/p p">调用 <code class="+ topic/ph pr-d/codeph ph codeph">getStreamEngineStat</code> 会返回一个字典，其key为引擎类型名称，value为一个表，包含key对应引擎的状态。</p><p class="- topic/p p">以getStreamEngineStat().DailyTimeSeriesEngine为例，查看内容为：</p><br/><img class="- topic/image image" src="images/streaming/getStreamEngineStat.png"/><br/><p class="- topic/p p">在上例中，系统中仅有一个DailyTimeSeriesEngine，其引擎名为engine1，目前占用了大约32KB内存。引擎的内存占用主要是因为随着订阅的流数据不断注入引擎，存放在内存中的数据越来越多。在创建引擎时可以通过参数 garbageSize 控制清理历史数据的频率以控制引擎中的内存占用。</p><p class="- topic/p p">对于不再使用的引擎建议及时释放。通过dropStreamEngine函数释放引擎会释放掉对应的内存，若流数据引擎的句柄仍在内存中也需要释放：创建引擎时返回的句柄变量 = NULL。</p></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title34" id="8-性能调优"><h2 class="- topic/title title topictitle2" id="ariaid-title34">8. 性能调优</h2><div class="- topic/body body"><p class="- topic/p p">当数据流量极大而系统来不及处理时，系统监控中会看到订阅端subWorkers表的queueDepth数值极高，此时系统"../tools/grafana.md"入端逐级反馈数据压力。当订阅端队列深度达到上限时开始阻止发布端数据进入，此时发布端的队列开始累积。当发布端的队列深度达到上限时，系统会阻止流数据注入端写入数据。</p><p class="- topic/p p">可以通过以下几种方式来优化系统对流数据的处理性能：</p><ul class="- topic/ul ul"><li class="- topic/li li"><p class="- topic/p p">调整订阅参数中的batchSize和throttle参数，来平衡发布端和订阅端的缓存，让流数据输入速度与数据处理速度达到一个动态的平衡。若要充分发挥数据批量处理的性能优势，可以设定batchSize参数等待流数据积累到一定量时才进行消费，但是这样会带来一定程度的内存占用，而且当batchSize参数较大的时候，可能会发生数据量没有达到batchSize而长期滞留在缓冲区的情况。对于这个问题，可以选择一个合适的throttle参数值。它的作用是即使batchSize未满足，也能将缓冲区的数据消费掉。</p></li><li class="- topic/li li"><p class="- topic/p p">通过调整subExecutors配置参数增加订阅端计算的并行度，以加快订阅端队列的消费速度。</p></li><li class="- topic/li li"><p class="- topic/p p">当有多个executor时，若每个executor处理不同的订阅，而且不同订阅的数据流的频率或者处理复杂度差异极大，容易导致低负载的executor资源闲置。通过设置subExecutorPooling=true，可以让所有executor作为一个共享线程池，共同处理所有订阅的消息。在这种共享池模式下，所有订阅的消息进入同一个队列，多个executor从队列中读取消息并行处理。需要指出，共享线程池处理流数据的一个副作用是不能保证消息按到达的时间顺序处理。当消息需要按照抵达时间顺序被处理时，不应开启此设置。系统默认采用哈希算法为每一个订阅分配一个executor。若需要保证两个流数据表的时序同步，可在订阅函数subscribeTable中对两个订阅使用相同的hash值，来指定用同一个线程来处理这两个订阅数据流。</p></li><li class="- topic/li li"><p class="- topic/p p">若流数据表启用同步持久化，那么磁盘的I/O可能会成为瓶颈。可参考2.6小节采用异步方式持久化数据，同时设置一个合理的持久化队列(maxPersistenceQueueDepth参数，默认值为1000万条消息)。也可使用SSD硬盘替换HDD硬盘以提高写入性能。</p></li><li class="- topic/li li"><p class="- topic/p p">如果数据发布端(publisher)成为系统的瓶颈，譬如订阅的客户端太多可能导致发布瓶颈，可以采用以下两种处理办法。首先通过多级级联降低每一个发布节点的订阅数量，对延迟不敏感的应用可以订阅二级甚至三级的发布节点。其次调整部分参数来平衡延迟和吞吐量两个指标。参数maxMsgNumPerBlock设置批量发送消息时批的大小，默认值是1024。一般情况下，较大的批量值能提升吞吐量，但会增加网络延迟。</p></li><li class="- topic/li li"><p class="- topic/p p">若输入流数据的流量波动较大，高峰期导致消费队列积压至队列峰值(默认1000万)，那么可以修改配置项maxPubQueueDepthPerSite和maxSubQueueDepth以增加发布端和订阅端的最大队列深度，提高系统数据流大幅波动的能力。鉴于队列深度增加时内存消耗会增加，应估算并监控内存使用量以合理配置内存。</p></li></ul></div></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title35" id="9-可视化"><h2 class="- topic/title title topictitle2" id="ariaid-title35">9. 可视化</h2><div class="- topic/body body"><p class="- topic/p p">流数据可视化可分为两种类型：</p><ul class="- topic/ul ul"><li class="- topic/li li"><p class="- topic/p p">实时值监控：定时刷新流数据在滑动窗口的聚合计算值，通常用于指标的监控和预警。</p></li><li class="- topic/li li"><p class="- topic/p p">趋势监控：把新产生的数据附加到原有的数据上并以可视化图表的方式实时更新。</p></li></ul><p class="- topic/p p">很多数据可视化的平台都能支持流数据的实时监控，比如当前流行的开源数据可视化框架Grafana。DolphinDB database 已经实现了Grafana的服务端和客户端的接口，具体配置可以参考 <a class="- topic/xref xref" href="../tools/grafana.html">Grafana教程</a>。</p></div></article></article></main></div>
                        
                        
                        
                        
                        
                        
                    </div>
                    
                        <nav role="navigation" id="wh_topic_toc" aria-label="On this page" class="col-lg-2 d-none d-lg-block navbar d-print-none"> 
                            <div id="wh_topic_toc_content">
		                        
	                            <div class=" wh_topic_toc "><div class="wh_topic_label">在本页上</div><ul><li class="topic-item"><a href="#1-%E6%B5%81%E7%A8%8B%E5%9B%BE%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5" data-tocid="1-流程图及相关概念">1. 流程图及相关概念</a><ul><li class="topic-item"><a href="#11-%E6%B5%81%E6%95%B0%E6%8D%AE%E8%A1%A8" data-tocid="11-流数据表">1.1. 流数据表</a></li><li class="topic-item"><a href="#12-%E5%8F%91%E5%B8%83%E4%B8%8E%E8%AE%A2%E9%98%85" data-tocid="12-发布与订阅">1.2. 发布与订阅</a></li><li class="topic-item"><a href="#13-%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E" data-tocid="13-流数据计算引擎">1.3. 流数据计算引擎</a></li></ul></li><li class="topic-item"><a href="#2-%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD" data-tocid="2-核心功能">2. 核心功能</a><ul><li class="topic-item"><a href="#21-%E6%B5%81%E6%95%B0%E6%8D%AE%E5%8F%91%E5%B8%83" data-tocid="21-流数据发布">2.1. 流数据发布</a></li><li class="topic-item"><a href="#22-%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A2%E9%98%85" data-tocid="22-流数据订阅">2.2. 流数据订阅</a></li><li class="topic-item"><a href="#23-%E6%96%AD%E7%BA%BF%E9%87%8D%E8%BF%9E" data-tocid="23-断线重连">2.3. 断线重连</a></li><li class="topic-item"><a href="#24-%E5%8F%91%E5%B8%83%E7%AB%AF%E6%95%B0%E6%8D%AE%E8%BF%87%E6%BB%A4" data-tocid="24-发布端数据过滤">2.4. 发布端数据过滤</a></li><li class="topic-item"><a href="#25-%E5%8F%96%E6%B6%88%E8%AE%A2%E9%98%85" data-tocid="25-取消订阅">2.5. 取消订阅</a></li><li class="topic-item"><a href="#26-%E6%B5%81%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96" data-tocid="26-流数据持久化">2.6. 流数据持久化</a></li></ul></li><li class="topic-item"><a href="#3-%E6%95%B0%E6%8D%AE%E5%9B%9E%E6%94%BE" data-tocid="3-数据回放">3. 数据回放</a></li><li class="topic-item"><a href="#4-%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E" data-tocid="4-流数据计算引擎">4. 流数据计算引擎</a><ul><li class="topic-item"><a href="#41-%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%A4%84%E7%90%86" data-tocid="41-流水线处理">4.1. 流水线处理</a></li><li class="topic-item"><a href="#42-%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86" data-tocid="42-并行处理">4.2. 并行处理</a></li><li class="topic-item"><a href="#43-%E5%BF%AB%E7%85%A7%E6%9C%BA%E5%88%B6" data-tocid="43-快照机制">4.3. 快照机制</a></li></ul></li><li class="topic-item"><a href="#5-%E9%AB%98%E5%8F%AF%E7%94%A8" data-tocid="5-高可用">5. 高可用</a><ul><li class="topic-item"><a href="#51-%E6%B5%81%E6%95%B0%E6%8D%AE%E9%AB%98%E5%8F%AF%E7%94%A8" data-tocid="51-流数据高可用">5.1. 流数据高可用</a></li><li class="topic-item"><a href="#52-%E6%B5%81%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E9%AB%98%E5%8F%AF%E7%94%A8" data-tocid="52-流计算引擎高可用">5.2. 流计算引擎高可用</a></li></ul></li><li class="topic-item"><a href="#6-%E6%B5%81%E6%95%B0%E6%8D%AEapi" data-tocid="6-流数据api">6. 流数据API</a><ul><li class="topic-item"><a href="#61-python-api" data-tocid="61-python-api">6.1. Python API</a><ul><li class="topic-item"><a href="#611-python%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A2%E9%98%85%E7%A4%BA%E4%BE%8B" data-tocid="611-python客户端流数据订阅示例">6.1.1. Python客户端流数据订阅示例</a></li><li class="topic-item"><a href="#612-dolphindb%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B5%81%E6%95%B0%E6%8D%AE%E8%AE%A2%E9%98%85%E7%A4%BA%E4%BE%8B" data-tocid="612-dolphindb服务端流数据订阅示例">6.1.2. DolphinDB服务端流数据订阅示例</a></li></ul></li></ul></li><li class="topic-item"><a href="#7-%E7%8A%B6%E6%80%81%E7%9B%91%E6%8E%A7" data-tocid="7-状态监控">7. 状态监控</a><ul><li class="topic-item"><a href="#71-%E6%B5%81%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%8A%B6%E6%80%81" data-tocid="71-流数据处理状态">7.1. 流数据处理状态</a></li><li class="topic-item"><a href="#72-%E6%B5%81%E8%AE%A1%E7%AE%97%E7%8A%B6%E6%80%81" data-tocid="72-流计算状态">7.2. 流计算状态</a><ul><li class="topic-item"><a href="#721-pubconns%E8%A1%A8" data-tocid="721-pubconns表">7.2.1. pubConns表</a></li><li class="topic-item"><a href="#722-subconns%E8%A1%A8" data-tocid="722-subconns表">7.2.2. subConns表</a></li><li class="topic-item"><a href="#723-persistworkers%E8%A1%A8" data-tocid="723-persistworkers表">7.2.3. persistWorkers表</a></li><li class="topic-item"><a href="#724-subworkers%E8%A1%A8" data-tocid="724-subworkers表">7.2.4. subWorkers表</a></li><li class="topic-item"><a href="#725-pubtables%E8%A1%A8" data-tocid="725-pubtables表">7.2.5. pubTables表</a></li></ul></li><li class="topic-item"><a href="#73-%E6%B5%81%E6%95%B0%E6%8D%AE%E5%BC%95%E6%93%8E%E7%8A%B6%E6%80%81" data-tocid="73-流数据引擎状态">7.3. 流数据引擎状态</a></li></ul></li><li class="topic-item"><a href="#8-%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98" data-tocid="8-性能调优">8. 性能调优</a></li><li class="topic-item"><a href="#9-%E5%8F%AF%E8%A7%86%E5%8C%96" data-tocid="9-可视化">9. 可视化</a></li></ul></div>
	                        	
                        	</div>
                        </nav>
                    
                </div>
            </div>
            
            
            
        </div> 
        <footer class="navbar navbar-default wh_footer">
  <div class=" footer-container mx-auto ">
<title>Copyright</title><p><b> ©2025 浙江智臾科技有限公司 浙ICP备18048711号-3</b></p>
  </div>
</footer>
        
        <div id="go2top" class="d-print-none">
            <span class="oxy-icon oxy-icon-up"></span>
        </div>
        
        <div id="modal_img_large" class="modal">
            <span class="close oxy-icon oxy-icon-remove"></span>
            <div id="modal_img_container"></div>
            <div id="caption"></div>
        </div>
        
        
        
    </body>
</html>
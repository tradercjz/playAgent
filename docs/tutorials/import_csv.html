<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh" lang="zh" data-whc_version="26.0">
    <head><link rel="shortcut icon" href="../favicon.ico"/><link rel="icon" href="../favicon.ico"/><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="description" content="DolphinDB提供以下4个函数，将文本数据导入内存或数据库： loadText ：将文本文件导入为内存表。 ploadText ：将文本文件并行导入为分区内存表。与 loadText 函数相比，速度更快。 loadTextEx ：将文本文件导入数据库中，包括分布式数据库或内存数据库。 textChunkDS ：将文本文件划分为多个小数据源，再通过 mr 函数进行灵活的数据处理。 ..."/><meta name="DC.rights.owner" content="(C) 版权 2025"/><meta name="copyright" content="(C) 版权 2025"/><meta name="generator" content="DITA-OT"/><meta name="DC.type" content="topic"/><meta name="DC.format" content="HTML5"/><meta name="DC.identifier" content="文本数据导入"/><title>文本数据导入</title><!--  Generated with Oxygen version 26.0, build number 2024012323.  --><meta name="wh-path2root" content="../"/><meta name="wh-toc-id" content="&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;?workdir /tmp/temp20250305183303418/tutorials?&gt;&lt;?workdir-uri file:/tmp/temp20250305183303418/tutorials/?&gt;&lt;?path2project ../?&gt;&lt;?path2project-uri ../?&gt;&lt;?path2rootmap-uri ../?&gt;&lt;topic xmlns:dita-ot=&#34;http://dita-ot.sourceforge.net/ns/201007/dita-ot&#34; xmlns:ditaarch=&#34;http://dita.oasis-open.org/architecture/2005/&#34; class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;文本数据导入&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:1;1:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:1;1:1&#34;&gt;文本数据导入&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:1;1:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:1;3:1&#34;&gt;DolphinDB提供以下4个函数，将文本数据导入内存或数据库：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;ul:1;5:1&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:1;5:1&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:1;5:3&#34;&gt;loadText&lt;/codeph&gt;：将文本文件导入为内存表。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:2;6:1&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:2;6:3&#34;&gt;ploadText&lt;/codeph&gt;：将文本文件并行导入为分区内存表。与&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:3;6:32&#34;&gt;loadText&lt;/codeph&gt;函数相比，速度更快。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:3;7:1&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:4;7:3&#34;&gt;loadTextEx&lt;/codeph&gt;：将文本文件导入数据库中，包括分布式数据库或内存数据库。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:4;8:1&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:5;8:3&#34;&gt;textChunkDS&lt;/codeph&gt;：将文本文件划分为多个小数据源，再通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:6;8:35&#34;&gt;mr&lt;/codeph&gt;函数进行灵活的数据处理。&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:2;10:1&#34;&gt;DolphinDB的文本数据导入不仅灵活，而且速度非常快。DolphinDB与Clickhouse, MemSQL, Druid, Pandas等业界流行的系统相比，单线程导入的速度优势，最多可达一个数量级；多线程并行导入的情况下，速度优势更加明显。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:3;12:1&#34;&gt;本教程介绍文本数据导入时的常见问题，相应的解决方案以及注意事项。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;1-自动识别数据格式&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:2;14:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:2;14:1&#34;&gt;1. 自动识别数据格式&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:2;14:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:4;16:1&#34;&gt;大多数其它系统中，导入文本数据时，需要由用户指定数据的格式。DolphinDB在导入数据时，能够自动识别数据格式，为用户提供了方便。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:5;18:1&#34;&gt;自动识别数据格式包括两部分：字段名称识别和数据类型识别。如果文件的第一行没有任何一列以数字开头，那么系统认为第一行是文件头，包含了字段名称。DolphinDB会抽取少量部分数据作为样本，并自动推断各列的数据类型。因为是基于部分数据，某些列的数据类型可能识别错误。但是对于大多数文本文件，无须手动指定各列的字段名称和数据类型，就能正确地导入到DolphinDB中。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:6;20:1&#34;&gt;请注意：1.20.0之前的版本不支持导入INT128, UUID和IPADDR这三种数据类型。如果在csv文件中包含这三种数据类型，请确保所用版本不低于1.20.0。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:7;22:1&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:7;22:1&#34;&gt;loadText&lt;/codeph&gt;函数用于将数据导入DolphinDB内存表。下例调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:8;22:37&#34;&gt;loadText&lt;/codeph&gt;函数导入数据，并查看生成的数据表的结构。例子中涉及到的数据文件请参考&lt;xref class=&#34;- topic/xref &#34; href=&#34;#附录&#34; dita-ot:orig-format=&#34;markdown&#34; format=&#34;dita&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;xref:1;22:81&#34;&gt;&lt;?ditaot usertext?&gt;附录&lt;/xref&gt;。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:1;24:1&#34;&gt;dataFilePath=&#34;/home/data/candle_201801.csv&#34; tmpTB=loadText(filename=dataFilePath);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:8;29:1&#34;&gt;查看数据表前5行数据：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:2;31:1&#34;&gt;select top 5 * from tmpTB; symbol exchange cycle tradingDay date time open high low close volume turnover unixTime ------ -------- ----- ---------- ---------- -------- ----- ----- ----- ----- ------- ---------- ------------- 000001 SZSE 1 2018.01.02 2018.01.02 93100000 13.35 13.39 13.35 13.38 2003635 2.678558E7 1514856660000 000001 SZSE 1 2018.01.02 2018.01.02 93200000 13.37 13.38 13.33 13.33 867181 1.158757E7 1514856720000 000001 SZSE 1 2018.01.02 2018.01.02 93300000 13.32 13.35 13.32 13.35 903894 1.204971E7 1514856780000 000001 SZSE 1 2018.01.02 2018.01.02 93400000 13.35 13.38 13.35 13.35 1012000 1.352286E7 1514856840000 000001 SZSE 1 2018.01.02 2018.01.02 93500000 13.35 13.37 13.35 13.37 1601939 2.140652E7 1514856900000&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:9;43:1&#34;&gt;调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:9;43:3&#34;&gt;schema&lt;/codeph&gt;函数查看表结构（字段名称、数据类型等信息）：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:3;45:1&#34;&gt;tmpTB.schema().colDefs; name typeString typeInt comment ---------- ---------- ------- ------- symbol SYMBOL 17 exchange SYMBOL 17 cycle INT 4 tradingDay DATE 6 date DATE 6 time INT 4 open DOUBLE 16 high DOUBLE 16 low DOUBLE 16 close DOUBLE 16 volume INT 4 turnover DOUBLE 16 unixTime LONG 5&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;2-指定数据导入格式&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:3;65:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:3;65:1&#34;&gt;2. 指定数据导入格式&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:3;65:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:10;67:1&#34;&gt;本教程讲述的4个数据加载函数中，均可用schema参数指定一个表，内含各字段的名称、类型、格式、需要导入的列等信息。该表可包含以下4列：&lt;/p&gt;&lt;table class=&#34;- topic/table &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;table:1;69:1&#34;&gt;&lt;tgroup class=&#34;- topic/tgroup &#34; cols=&#34;2&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;tgroup:1;69:1&#34;&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;colspec:1;69:1&#34; colnum=&#34;1&#34;/&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col2&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;colspec:2;69:1&#34; colnum=&#34;2&#34;/&gt;&lt;thead class=&#34;- topic/thead &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;thead:1;69:1&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;row:1;69:1&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:1;69:1&#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;1&#34;&gt;列名&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:2;69:5&#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;1&#34;&gt;含义&lt;/entry&gt;&lt;/row&gt;&lt;/thead&gt;&lt;tbody class=&#34;- topic/tbody &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;tbody:1;71:1&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;row:2;71:1&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:3;71:1&#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;2&#34;&gt;name&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:4;71:7&#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;2&#34;&gt;字符串，表示列名&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;row:3;72:1&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:5;72:1&#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;3&#34;&gt;type&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:6;72:7&#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;3&#34;&gt;字符串，表示每列的数据类型&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;row:4;73:1&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:7;73:1&#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;4&#34;&gt;format&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:8;73:9&#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;4&#34;&gt;字符串，表示日期或时间列的格式&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;row:5;74:1&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:9;74:1&#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;5&#34;&gt;col&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:10;74:6&#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;5&#34;&gt;整型，表示要加载的列的下标。该列的值必须是升序。&lt;/entry&gt;&lt;/row&gt;&lt;/tbody&gt;&lt;/tgroup&gt;&lt;/table&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:11;76:1&#34;&gt;其中，name和type这两列是必需的，而且必须是前两列。format和col这两列是可选的，且没有先后顺序的要求。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:12;78:1&#34;&gt;例如，我们可以使用以下的数据表作为schema参数：&lt;/p&gt;&lt;table class=&#34;- topic/table &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;table:2;80:1&#34;&gt;&lt;tgroup class=&#34;- topic/tgroup &#34; cols=&#34;2&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;tgroup:2;80:1&#34;&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;colspec:3;80:1&#34; colnum=&#34;1&#34;/&gt;&lt;colspec class=&#34;- topic/colspec &#34; colname=&#34;col2&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;colspec:4;80:1&#34; colnum=&#34;2&#34;/&gt;&lt;thead class=&#34;- topic/thead &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;thead:2;80:1&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;row:6;80:1&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:11;80:1&#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;1&#34;&gt;name&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:12;80:6&#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;1&#34;&gt;type&lt;/entry&gt;&lt;/row&gt;&lt;/thead&gt;&lt;tbody class=&#34;- topic/tbody &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;tbody:2;82:1&#34;&gt;&lt;row class=&#34;- topic/row &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;row:7;82:1&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:13;82:1&#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;2&#34;&gt;timestamp&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:14;82:11&#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;2&#34;&gt;SECOND&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;row:8;83:1&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:15;83:1&#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;3&#34;&gt;ID&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:16;83:4&#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;3&#34;&gt;INT&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;row:9;84:1&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:17;84:1&#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;4&#34;&gt;qty&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:18;84:5&#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;4&#34;&gt;INT&lt;/entry&gt;&lt;/row&gt;&lt;row class=&#34;- topic/row &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;row:10;85:1&#34;&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:19;85:1&#34; colname=&#34;col1&#34; dita-ot:x=&#34;1&#34; dita-ot:y=&#34;5&#34;&gt;price&lt;/entry&gt;&lt;entry class=&#34;- topic/entry &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;entry:20;85:7&#34; colname=&#34;col2&#34; dita-ot:x=&#34;2&#34; dita-ot:y=&#34;5&#34;&gt;DOUBLE&lt;/entry&gt;&lt;/row&gt;&lt;/tbody&gt;&lt;/tgroup&gt;&lt;/table&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;21-提取文本文件的schema&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:4;87:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:4;87:1&#34;&gt;2.1. 提取文本文件的schema&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:4;87:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:13;89:1&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:10;89:1&#34;&gt;extractTextSchema&lt;/codeph&gt;函数用于获取文本文件的schema，包括字段名称和数据类型等信息。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:14;91:1&#34;&gt;例如，使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:11;91:6&#34;&gt;extractTextSchema&lt;/codeph&gt;函数得到本教程中示例文件的表结构：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:4;93:1&#34;&gt;dataFilePath=&#34;/home/data/candle_201801.csv&#34; schemaTB=extractTextSchema(dataFilePath) schemaTB; name type ---------- ------ symbol SYMBOL exchange SYMBOL cycle INT tradingDay DATE date DATE time INT open DOUBLE high DOUBLE low DOUBLE close DOUBLE volume INT turnover DOUBLE unixTime LONG&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;22-指定字段名称和类型&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:5;115:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:5;115:1&#34;&gt;2.2. 指定字段名称和类型&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:5;115:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:15;117:1&#34;&gt;当系统自动识别的字段名称或者数据类型不符合预期时，可以通过修改&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:12;117:32&#34;&gt;extractTextSchema&lt;/codeph&gt;生成的schema表或直接创建schema表为文本文件中的每列指定字段名称和数据类型。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:16;119:1&#34;&gt;例如，若导入数据的volume列被自动识别为INT类型，而需要的volume类型是LONG类型，就需要修改schema表，指定volumn列类型为LONG。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:5;120:1&#34;&gt;dataFilePath=&#34;/home/data/candle_201801.csv&#34; schemaTB=extractTextSchema(dataFilePath) update schemaTB set type=&#34;LONG&#34; where name=&#34;volume&#34;;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:17;126:1&#34;&gt;使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:13;126:3&#34;&gt;loadText&lt;/codeph&gt;函数导入文本文件，将数据按照schemaTB所规定的字段数据类型导入到数据库中。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:6;127:1&#34;&gt;tmpTB=loadText(filename=dataFilePath,schema=schemaTB);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:18;131:1&#34;&gt;上例介绍了修改数据类型的情况，若要修改表中的字段名称，也可以通过同样的方法实现。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:19;133:2&#34;&gt;请注意，若对日期和时间相关数据类型的自动解析不符合预期，需要通过本教程指定日期和时间类型的格式小节的方式解决。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;23-指定日期和时间类型的格式&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:6;135:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:6;135:1&#34;&gt;2.3. 指定日期和时间类型的格式&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:6;135:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:20;137:1&#34;&gt;对于日期列或时间列的数据，如果自动识别的数据类型不符合预期，不仅需要在schema的type列指定数据类型，还需要在format列中指定格式（用字符串表示），如&#34;MM/dd/yyyy&#34;。如何表示日期和时间格式请参考日期和时间的调整及格式。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:21;139:1&#34;&gt;下面结合例子具体说明对日期和时间列指定数据类型的方法。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:22;141:1&#34;&gt;在DolphinDB中执行以下脚本，生成本例所需的数据文件。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:7;143:1&#34;&gt;dataFilePath=&#34;/home/data/timeData.csv&#34; t=table([&#34;20190623 14:54:57&#34;,&#34;20190623 15:54:23&#34;,&#34;20190623 16:30:25&#34;] as time,`AAPL`MS`IBM as sym,2200 5400 8670 as qty,54.78 59.64 65.23 as price) saveText(t,dataFilePath);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:23;149:1&#34;&gt;加载数据前，使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:14;149:9&#34;&gt;extractTextSchema&lt;/codeph&gt;函数获取该数据文件的schema:&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:8;151:1&#34;&gt;schemaTB=extractTextSchema(dataFilePath) schemaTB; name type ----- ------ time SECOND sym SYMBOL qty INT price DOUBLE&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:24;163:1&#34;&gt;显然，系统识别time列的数据类型不符合预期。如果直接加载该文件，time列的数据将为空。为了能够正确加载该文件time列的数据，需要指定time列的数据类型为DATETIME，并且指定该列的格式为&#34;yyyyMMdd HH:mm:ss&#34;。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:9;165:1&#34;&gt;update schemaTB set type=&#34;DATETIME&#34; where name=&#34;time&#34; schemaTB[`format]=[&#34;yyyyMMdd HH:mm:ss&#34;,,,];&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:25;170:1&#34;&gt;导入数据并查看，数据显示正确：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:10;171:1&#34;&gt;tmpTB=loadText(dataFilePath,,schemaTB) tmpTB; time sym qty price ------------------- ---- ---- ----- 2019.06.23T14:54:57 AAPL 2200 54.78 2019.06.23T15:54:23 MS 5400 59.64 2019.06.23T16:30:25 IBM 8670 65.23&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;24-导入指定列&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:7;182:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:7;182:1&#34;&gt;2.4. 导入指定列&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:7;182:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:26;184:1&#34;&gt;在导入数据时，可以通过schema参数指定只导入文本文件中的某几列。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:27;186:1&#34;&gt;下例中，只需加载文本文件中symbol, date, open, high, close, volume, turnover这7列。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:28;188:1&#34;&gt;首先，调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:15;188:6&#34;&gt;extractTextSchema&lt;/codeph&gt;函数得到目标文本文件的表结构。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:11;190:1&#34;&gt;dataFilePath=&#34;/home/data/candle_201801.csv&#34; schemaTB=extractTextSchema(dataFilePath);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:29;195:1&#34;&gt;使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:16;195:3&#34;&gt;rowNo&lt;/codeph&gt;函数为各列生成列号，赋值给schema表中的col列，然后修改schema表，仅保留表示需要导入的字段的行。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:12;196:1&#34;&gt;update schemaTB set col = rowNo(name) schemaTB=select * from schemaTB where name in `symbol`date`open`high`close`volume`turnover;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:30;201:1&#34;&gt;请注意：&lt;/p&gt;&lt;ol class=&#34;- topic/ol &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;ol:1;202:1&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:5;202:1&#34;&gt;列号从0开始。上例中第一列symbol列对应的列号是0。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:6;203:1&#34;&gt;导入数据时不能改变各列的先后顺序。如果需要调整列的顺序，可以将数据文件加载后，再使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:17;203:46&#34;&gt;reorderColumns!&lt;/codeph&gt;函数。&lt;/li&gt;&lt;/ol&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:31;205:1&#34;&gt;最后，使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:18;205:6&#34;&gt;loadText&lt;/codeph&gt;函数，并配置schema参数，导入文本文件中指定的列。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:13;207:1&#34;&gt;tmpTB=loadText(filename=dataFilePath,schema=schemaTB);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:32;211:1&#34;&gt;查看表中前5行，只导入了所需的列：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:14;213:1&#34;&gt;select top 5 * from tmpTB symbol date open high close volume turnover ------ ---------- ------ ----- ----- ------ ---------- 000001 2018.01.02 9.31E7 13.35 13.35 13 2.003635E6 000001 2018.01.02 9.32E7 13.37 13.33 13 867181 000001 2018.01.02 9.33E7 13.32 13.32 13 903894 000001 2018.01.02 9.34E7 13.35 13.35 13 1.012E6 000001 2018.01.02 9.35E7 13.35 13.35 13 1.601939E6&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;25-跳过文本数据的前若干行&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:8;225:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:8;225:1&#34;&gt;2.5. 跳过文本数据的前若干行&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:8;225:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:33;227:1&#34;&gt;在数据导入时，若需跳过文件前n行（可能为文件说明），可指定skipRows参数为n。由于描述文件的说明通常不会非常冗长，因此这个参数的取值最大为1024。本教程讲述的4个数据加载函数均支持skipRows参数。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:34;229:1&#34;&gt;下例中，通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:19;229:7&#34;&gt;loadText&lt;/codeph&gt;函数导入数据文件，并且查看该文件导入以后表的总行数，以及前5行的内容。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:15;231:1&#34;&gt;dataFilePath=&#34;/home/data/candle_201801.csv&#34; tmpTB=loadText(filename=dataFilePath) select count(*) from tmpTB; count ----- 5040 select top 5 * from tmpTB; symbol exchange cycle tradingDay date time open high low close volume turnover unixTime ------ -------- ----- ---------- ---------- -------- ----- ----- ----- ----- ------- ---------- ------------- 000001 SZSE 1 2018.01.02 2018.01.02 93100000 13.35 13.39 13.35 13.38 2003635 2.678558E7 1514856660000 000001 SZSE 1 2018.01.02 2018.01.02 93200000 13.37 13.38 13.33 13.33 867181 1.158757E7 1514856720000 000001 SZSE 1 2018.01.02 2018.01.02 93300000 13.32 13.35 13.32 13.35 903894 1.204971E7 1514856780000 000001 SZSE 1 2018.01.02 2018.01.02 93400000 13.35 13.38 13.35 13.35 1012000 1.352286E7 1514856840000 000001 SZSE 1 2018.01.02 2018.01.02 93500000 13.35 13.37 13.35 13.37 1601939 2.140652E7 1514856900000&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:35;251:1&#34;&gt;指定skipRows参数取值为1000，跳过文本文件的前1000行导入文件：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:16;253:1&#34;&gt;tmpTB=loadText(filename=dataFilePath,skipRows=1000) select count(*) from tmpTB; count ----- 4041 select top 5 * from tmpTB; col0 col1 col2 col3 col4 col5 col6 col7 col8 col9 col10 col11 col12 ------ ---- ---- ---------- ---------- --------- ----- ----- ----- ----- ------ ---------- ------------- 000001 SZSE 1 2018.01.08 2018.01.08 101000000 13.13 13.14 13.12 13.14 646912 8.48962E6 1515377400000 000001 SZSE 1 2018.01.08 2018.01.08 101100000 13.13 13.14 13.13 13.14 453647 5.958462E6 1515377460000 000001 SZSE 1 2018.01.08 2018.01.08 101200000 13.13 13.14 13.12 13.13 700853 9.200605E6 1515377520000 000001 SZSE 1 2018.01.08 2018.01.08 101300000 13.13 13.14 13.12 13.12 738920 9.697166E6 1515377580000 000001 SZSE 1 2018.01.08 2018.01.08 101400000 13.13 13.14 13.12 13.13 469800 6.168286E6 1515377640000&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:36;272:1&#34;&gt;请注意：如上例所示，在跳过前n行进行导入时，若数据文件的第一行是列名，该行会作为第一行被略过。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:37;274:1&#34;&gt;在上面的例子中，文本文件指定skipRows参数导入以后，由于表示列名的第一行被跳过，列名变成了默认列名：col0, col1, col2, 等等。若需要保留列名而又指定跳过前n行，可先通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:20;274:96&#34;&gt;extractTextSchema&lt;/codeph&gt;函数得到文本文件的schema，在导入时指定schema参数：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:17;276:1&#34;&gt;schema=extractTextSchema(dataFilePath) tmpTB=loadText(filename=dataFilePath,schema=schema,skipRows=1000) select count(*) from tmpTB; count ----- 4041 select top 5 * from tmpTB; symbol exchange cycle tradingDay date time open high low close volume turnover unixTime ------ -------- ----- ---------- ---------- --------- ----- ----- ----- ----- ------ ---------- ------------- 000001 SZSE 1 2018.01.08 2018.01.08 101000000 13.13 13.14 13.12 13.14 646912 8.48962E6 1515377400000 000001 SZSE 1 2018.01.08 2018.01.08 101100000 13.13 13.14 13.13 13.14 453647 5.958462E6 1515377460000 000001 SZSE 1 2018.01.08 2018.01.08 101200000 13.13 13.14 13.12 13.13 700853 9.200605E6 1515377520000 000001 SZSE 1 2018.01.08 2018.01.08 101300000 13.13 13.14 13.12 13.12 738920 9.697166E6 1515377580000 000001 SZSE 1 2018.01.08 2018.01.08 101400000 13.13 13.14 13.12 13.13 469800 6.168286E6 1515377640000&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;3-并行导入数据&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:9;296:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:9;296:1&#34;&gt;3. 并行导入数据&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:9;296:1&#34;/&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;31-单个文件多线程载入内存&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:10;298:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:10;298:1&#34;&gt;3.1. 单个文件多线程载入内存&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:10;298:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:38;300:1&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:21;300:1&#34;&gt;ploadText&lt;/codeph&gt;函数可将一个文本文件以多线程的方式载入内存。该函数与&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:22;300:38&#34;&gt;loadText&lt;/codeph&gt;函数的语法是一致的，区别在于，&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:23;300:63&#34;&gt;ploadText&lt;/codeph&gt;函数可以快速载入大型文件（至少16MB），并且生成内存分区表。它充分利用了多核CPU来并行载入文件，并行程度取决于服务器本身CPU核数量和节点的workerNum配置。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:39;302:1&#34;&gt;下面比较&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:24;302:5&#34;&gt;loadText&lt;/codeph&gt;函数与&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:25;302:18&#34;&gt;ploadText&lt;/codeph&gt;函数导入同一个文件的性能。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:40;304:1&#34;&gt;首先通过脚本生成一个4GB左右的文本文件：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; outputclass=&#34;txt&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:18;306:1&#34;&gt;filePath=&#34;/home/data/testFile.csv&#34; appendRows=100000000 t=table(rand(100,appendRows) as int,take(string('A'..'Z'),appendRows) as symbol,take(2010.01.01..2018.12.30,appendRows) as date,rand(float(100),appendRows) as float,00:00:00.000 + rand(86400000,appendRows) as time) t.saveText(filePath);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:41;313:1&#34;&gt;分别通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:26;313:5&#34;&gt;loadText&lt;/codeph&gt;和&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:27;313:16&#34;&gt;ploadText&lt;/codeph&gt;来载入文件。本例所用节点是6核12超线程的CPU。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; outputclass=&#34;txt&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:19;315:1&#34;&gt;timer loadText(filePath); Time elapsed: 12629.492 ms timer ploadText(filePath); Time elapsed: 2669.702 ms&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:42;323:1&#34;&gt;结果显示在此配置下，&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:28;323:11&#34;&gt;ploadText&lt;/codeph&gt;的性能是&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:29;323:26&#34;&gt;loadText&lt;/codeph&gt;的4.5倍左右。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;32-多文件并行导入&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:11;325:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:11;325:1&#34;&gt;3.2. 多文件并行导入&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:11;325:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:43;327:1&#34;&gt;在大数据应用领域，数据导入往往不只是一个或两个文件的导入，而是数十个甚至数百个大型文件的批量导入。为了达到更好的导入性能，建议尽量以并行方式导入批量的数据文件。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:44;329:1&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:30;329:1&#34;&gt;loadTextEx&lt;/codeph&gt;函数可将文本文件导入指定的数据库中，包括分布式数据库或内存数据库。由于DolphinDB的分区表支持并发读写，因此可以支持多线程导入数据。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:45;331:1&#34;&gt;使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:31;331:3&#34;&gt;loadTextEx&lt;/codeph&gt;将文本数据导入到分布式数据库，具体实现为将数据先导入到内存，再由内存写入到数据库，这两个步骤由同一个函数完成，以保证高效率。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:46;333:1&#34;&gt;下例展示如何将磁盘上的多个文件批量写入到DolphinDB分区表中。首先，在DolphinDB中执行以下脚本，生成100个文件，共约778MB，包括1千万条记录。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:20;335:1&#34;&gt;n=100000 dataFilePath=&#34;/home/data/multi/multiImport_&#34;+string(1..100)+&#34;.csv&#34; for (i in 0..99){ trades=table(sort(take(100*i+1..100,n)) as id,rand(`IBM`MSFT`GM`C`FB`GOOG`V`F`XOM`AMZN`TSLA`PG`S,n) as sym,take(2000.01.01..2000.06.30,n) as date,10.0+rand(2.0,n) as price1,100.0+rand(20.0,n) as price2,1000.0+rand(200.0,n) as price3,10000.0+rand(2000.0,n) as price4,10000.0+rand(3000.0,n) as price5) trades.saveText(dataFilePath[i]) };&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:47;344:1&#34;&gt;创建数据库和表：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:21;346:1&#34;&gt;login(`admin,`123456) dbPath=&#34;dfs://DolphinDBdatabase&#34; db=database(dbPath,VALUE,1..10000) tb=db.createPartitionedTable(trades,`tb,`id);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:48;353:1&#34;&gt;DolphinDB的&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:32;353:11&#34;&gt;cut&lt;/codeph&gt;函数可将一个向量中的元素分组。下面调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:33;353:35&#34;&gt;cut&lt;/codeph&gt;函数将待导入的文件路径进行分组，再调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:34;353:59&#34;&gt;submitJob&lt;/codeph&gt;函数，为每个线程分配写入任务，批量导入数据。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:22;355:1&#34;&gt;def writeData(db,file){ loop(loadTextEx{db,`tb,`id,},file) } parallelLevel=10 for(x in dataFilePath.cut(100/parallelLevel)){ submitJob(&#34;loadData&#34;+parallelLevel,&#34;loadData&#34;,writeData{db,x}) };&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:49;365:1&#34;&gt;通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:35;365:3&#34;&gt;getRecentJobs&lt;/codeph&gt;函数可以取得当前本地节点上最近n个批处理作业的状态。使用select语句计算并行导入批量文件所需时间，得到在6核12超线程的CPU上耗时约1.59秒。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:23;367:1&#34;&gt;select max(endTime) - min(startTime) from getRecentJobs() where jobId like (&#34;loadData&#34;+string(parallelLevel)+&#34;%&#34;); max_endTime_sub --------------- 1590&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:50;375:1&#34;&gt;执行以下脚本，将100个文件单线程顺序导入数据库，记录所需时间，耗时约8.65秒。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:24;377:1&#34;&gt;timer writeData(db, dataFilePath); Time elapsed: 8647.645 ms&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:51;382:1&#34;&gt;结果显示在此配置下，并行开启10个线程导入速度是单线程导入的5.5倍左右。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:52;384:1&#34;&gt;查看数据表中的记录条数：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:25;386:1&#34;&gt;select count(*) from loadTable(&#34;dfs://DolphinDBdatabase&#34;, `tb); count ------ 10000000&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;4-导入数据库前的预处理&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:12;394:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:12;394:1&#34;&gt;4. 导入数据库前的预处理&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:12;394:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:53;396:1&#34;&gt;在将数据导入数据库之前，若需要对数据进行预处理，例如转换日期和时间数据类型，填充空值等，可以在调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:36;396:50&#34;&gt;loadTextEx&lt;/codeph&gt;函数时指定transform参数。tansform参数接受一个函数作为参数，并且要求该函数只能接受一个参数。函数的输入是一个未分区的内存表，输出也是一个未分区的内存表。需要注意的是，只有&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:37;396:155&#34;&gt;loadTextEx&lt;/codeph&gt;函数提供transform参数。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;41-指定日期和时间数据的数据类型&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:13;398:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:13;398:1&#34;&gt;4.1. 指定日期和时间数据的数据类型&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:13;398:1&#34;/&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;411-将数值类型表示的日期和时间转化为指定类型&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:14;400:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:14;400:1&#34;&gt;4.1.1. 将数值类型表示的日期和时间转化为指定类型&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:14;400:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:54;402:1&#34;&gt;数据文件中表示时间的数据可能是整型或者长整型，而在进行数据分析时，往往又需要将这类数据强制转化为时间类型的格式导入并存储到数据库中。针对这种场景，可通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:38;402:77&#34;&gt;loadTextEx&lt;/codeph&gt;函数的transform参数为文本文件中的日期和时间列指定相应的数据类型。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:55;404:1&#34;&gt;首先，创建分布式数据库和表。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:26;406:1&#34;&gt;login(`admin,`123456) dataFilePath=&#34;/home/data/candle_201801.csv&#34; dbPath=&#34;dfs://DolphinDBdatabase&#34; db=database(dbPath,VALUE,2018.01.02..2018.01.30) schemaTB=extractTextSchema(dataFilePath) update schemaTB set type=&#34;TIME&#34; where name=&#34;time&#34; tb=table(1:0,schemaTB.name,schemaTB.type) tb=db.createPartitionedTable(tb,`tb1,`date);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:56;417:1&#34;&gt;自定义函数&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:39;417:6&#34;&gt;i2t&lt;/codeph&gt;，用于对数据进行预处理，并返回处理过后的数据表。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:27;419:1&#34;&gt;def i2t(mutable t){ return t.replaceColumn!(`time,time(t.time/10)) }&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:57;425:1&#34;&gt;请注意：在自定义函数体内对数据进行处理时，请尽量使用本地的修改（以!结尾的函数）来提升性能。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:58;427:1&#34;&gt;调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:40;427:3&#34;&gt;loadTextEx&lt;/codeph&gt;函数，并且指定transform参数为&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:41;427:34&#34;&gt;i2t&lt;/codeph&gt;函数，系统会对文本文件中的数据执行&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:42;427:56&#34;&gt;i2t&lt;/codeph&gt;函数，并将结果保存到数据库中。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:28;429:1&#34;&gt;tmpTB=loadTextEx(dbHandle=db,tableName=`tb1,partitionColumns=`date,filename=dataFilePath,transform=i2t);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:59;433:1&#34;&gt;查看表内前5行数据。可见time列是以TIME类型存储，而不是文本文件中的INT类型：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:29;435:1&#34;&gt;select top 5 * from loadTable(dbPath,`tb1); symbol exchange cycle tradingDay date time open high low close volume turnover unixTime ------ -------- ----- ---------- ---------- ------------------ ----- ----- ----- ----- ------- ---------- ------------- 000001 SZSE 1 2018.01.02 2018.01.02 02:35:10.000000000 13.35 13.39 13.35 13.38 2003635 2.678558E7 1514856660000 000001 SZSE 1 2018.01.02 2018.01.02 02:35:20.000000000 13.37 13.38 13.33 13.33 867181 1.158757E7 1514856720000 000001 SZSE 1 2018.01.02 2018.01.02 02:35:30.000000000 13.32 13.35 13.32 13.35 903894 1.204971E7 1514856780000 000001 SZSE 1 2018.01.02 2018.01.02 02:35:40.000000000 13.35 13.38 13.35 13.35 1012000 1.352286E7 1514856840000 000001 SZSE 1 2018.01.02 2018.01.02 02:35:50.000000000 13.35 13.37 13.35 13.37 1601939 2.140652E7 1514856900000&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;412-日期或时间数据类型之间转换&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:15;447:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:15;447:1&#34;&gt;4.1.2. 日期或时间数据类型之间转换&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:15;447:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:60;449:1&#34;&gt;若文本文件中日期以DATE类型存储，在导入数据库时希望以MONTH的形式存储，这种情况也可通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:43;449:48&#34;&gt;loadTextEx&lt;/codeph&gt;函数的transform参数转换该日期列的数据类型，步骤与上一小节一致。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:30;451:1&#34;&gt;login(`admin,`123456) dbPath=&#34;dfs://DolphinDBdatabase&#34; db=database(dbPath,VALUE,2018.01.02..2018.01.30) schemaTB=extractTextSchema(dataFilePath) update schemaTB set type=&#34;MONTH&#34; where name=&#34;tradingDay&#34; tb=table(1:0,schemaTB.name,schemaTB.type) tb=db.createPartitionedTable(tb,`tb1,`date) def d2m(mutable t){ return t.replaceColumn!(`tradingDay,month(t.tradingDay)) } tmpTB=loadTextEx(dbHandle=db,tableName=`tb1,partitionColumns=`date,filename=dataFilePath,transform=d2m);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:61;465:1&#34;&gt;查看表内前5行数据。可见tradingDay列是以MONTH类型存储，而不是文本文件中的DATE类型：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:31;467:1&#34;&gt;select top 5 * from loadTable(dbPath,`tb1); symbol exchange cycle tradingDay date time open high low close volume turnover unixTime ------ -------- ----- ---------- ---------- -------- ----- ----- ----- ----- ------- ---------- ------------- 000001 SZSE 1 2018.01M 2018.01.02 93100000 13.35 13.39 13.35 13.38 2003635 2.678558E7 1514856660000 000001 SZSE 1 2018.01M 2018.01.02 93200000 13.37 13.38 13.33 13.33 867181 1.158757E7 1514856720000 000001 SZSE 1 2018.01M 2018.01.02 93300000 13.32 13.35 13.32 13.35 903894 1.204971E7 1514856780000 000001 SZSE 1 2018.01M 2018.01.02 93400000 13.35 13.38 13.35 13.35 1012000 1.352286E7 1514856840000 000001 SZSE 1 2018.01M 2018.01.02 93500000 13.35 13.37 13.35 13.37 1601939 2.140652E7 1514856900000&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;42-填充空值&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:16;479:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:16;479:1&#34;&gt;4.2. 填充空值&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:16;479:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:62;481:1&#34;&gt;transform参数可调用DolphinDB的内置函数。当内置函数要求多个参数时，我们可以使用部分应用将多参数函数转换为一个参数的函数。例如，调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:44;481:75&#34;&gt;nullFill!&lt;/codeph&gt;函数对文本文件中的空值进行填充。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:32;483:1&#34;&gt;db=database(dbPath,VALUE,2018.01.02..2018.01.30) tb=db.createPartitionedTable(tb,`tb1,`date) tmpTB=loadTextEx(dbHandle=db,tableName=`tb1,partitionColumns=`date,filename=dataFilePath,transform=nullFill!{,0});&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;5-导入数组向量类型的数据&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:17;489:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:17;489:1&#34;&gt;5. 导入数组向量类型的数据&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:17;489:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:63;490:1&#34;&gt;DolphinDB 中的数组向量 (array vector) 是一种特殊的向量，用于存储可变长度的二维数组。数组向量应用于数据表时，可将数据类型相同且含义相近的多列存为一列，例如股票的多档报价数据存为一个数组向量。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:64;492:1&#34;&gt;数据表中使用数组向量具有以下优势：&lt;/p&gt;&lt;ol class=&#34;- topic/ol &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;ol:2;493:1&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:7;493:1&#34;&gt;显著简化某些常用的查询和计算&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:8;494:1&#34;&gt;若不同列中含有大量重复数据，使用数组向量存储可提高数据压缩比，提升查询速度&lt;/li&gt;&lt;/ol&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:65;496:1&#34;&gt;DolphinDB 提供3种方法，以导入数组向量类型的数据：&lt;/p&gt;&lt;ol class=&#34;- topic/ol &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;ol:3;497:1&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:9;497:1&#34;&gt;直接导入符合条件的文本文件&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:10;498:1&#34;&gt;将文本文件导入内存后，将多列合并成一个数组向量，再导入分布式数据库&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:11;499:1&#34;&gt;使用 loadTextEx 函数时指定 transform 参数，将文本文件导入分布式数据库&lt;/li&gt;&lt;/ol&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;51-直接导入符合条件的文本文件-2004及以上版本&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:18;501:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:18;501:1&#34;&gt;5.1. 直接导入符合条件的文本文件 （2.00.4及以上版本）&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:18;501:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:66;503:1&#34;&gt;在导入文本文件时，暂不支持将多列数据合并导入 DolphinDB 数据表的一列（数组向量类型）。如需将数据导入为数组向量，需经过以下两步：&lt;/p&gt;&lt;ol class=&#34;- topic/ol &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;ol:4;505:1&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:12;505:1&#34;&gt;将文本文件的多列数据合并存储到一列中，并通过标识符进行分隔。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:13;506:1&#34;&gt;导入数据时，通过 loadText (ploadText) 与 loadTextEx 的 arrayDelimiter 参数指定分隔符，系统会将包含指定分隔符的列解析为数组向量。&lt;/li&gt;&lt;/ol&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:67;508:1&#34;&gt;构建包含数组向量的表，并将其存入1个 csv 文件&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:33;510:1&#34;&gt;bid = array(DOUBLE[], 0, 20).append!([1.4799 1.479 1.4787, 1.4796 1.479 1.4784, 1.4791 1.479 1.4784]) ask = array(DOUBLE[], 0, 20).append!([1.4821 1.4825 1.4828, 1.4818 1.482 1.4821, 1.4814 1.4818 1.482]) TradeDate = 2022.01.01 + 1..3 SecurityID = rand(`APPL`AMZN`IBM, 3) t = table(SecurityID as `sid, TradeDate as `date, bid as `bid, ask as `ask) saveText(t,filename=&#34;/home/data/t.csv&#34;,delimiter=',',append=true)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:68;519:1&#34;&gt;导入数据前需要修改 schema 中对应列的类型为数组向量。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:34;521:1&#34;&gt;path = &#34;/home/data/t.csv&#34; schema=extractTextSchema(path); update schema set type = &#34;DOUBLE[]&#34; where name=&#34;bid&#34; or name =&#34;ask&#34;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:69;527:1&#34;&gt;使用 loadText (ploadText) 与 loadTextEx 导入数据时，通过参数 arrayDelimiter 指定分隔符（本例中的分隔符为“,&#34;）。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:35;529:1&#34;&gt;//用 loadText 将文本文件导入内存表 t = loadText(path, schema=schema, arrayDelimiter=&#34;,&#34;) //用 loadTextEx 将文本文件导入分布式数据库 //创建 TSDB 引擎下的数据库表 db = database(directory=&#34;dfs://testTSDB&#34;, partitionType=VALUE, partitionScheme=`APPL`AMZN`IBM, engine=&#34;TSDB&#34; ) name = `sid`date`bid`ask type = [&#34;SYMBOL&#34;,&#34;DATE&#34;,&#34;DOUBLE[]&#34;,&#34;DOUBLE[]&#34;] tbTemp = table(1:0, name, type) db.createPartitionedTable(tbTemp, `pt, `sid, sortColumns=`date) pt = loadTextEx(dbHandle=db, tableName=`pt, partitionColumns=`sid, filename=path, schema=schema, arrayDelimiter=&#34;,&#34;)&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;52-文本文件导入内存后将多列合并成一列数组向量再导入分布式数据库&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:19;544:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:19;544:1&#34;&gt;5.2. 文本文件导入内存后，将多列合并成一列数组向量，再导入分布式数据库&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:19;544:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:70;546:1&#34;&gt;如果不能方便地对文本文件进行修改，也可以先将数据导入内存后，将多列数据合并成一个数组向量，再导入分布式数据库。&lt;?linebreak?&gt;下例展示如何将国内A股行情快照数据的买10档或卖10档作为1个 vector 存入单个 cell 中。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:71;549:1&#34;&gt;建库建表及模拟数据生成语句参见&lt;xref class=&#34;- topic/xref &#34; href=&#34;script/csvImportDemo/tsdbDatabaseTableGenerationAndDataSimulationForWritingArrayVector.dos&#34; format=&#34;dos&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;xref:2;549:16&#34;&gt;&lt;?ditaot usertext?&gt;建库建表及模拟数据生成脚本&lt;/xref&gt;。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:72;551:1&#34;&gt;在本例中，我们首先使用 loadText 函数将模拟数据导入内存，再使用 fixedLengthArrayVector 函数将买10档和卖10档的各项数据分别整合为1列，最后将处理后的数据写入数据库。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:36;553:1&#34;&gt;snapFile=&#34;/home/data/snapshot.csv&#34; dbpath=&#34;dfs://LEVEL2_Snapshot_ArrayVector&#34; tbName=&#34;Snap&#34; schemas=extractTextSchema(snapFile) update schemas set type = `SYMBOL where name = `InstrumentStatus //使用 loadText 加载文本，耗时约1分30秒 rawTb = loadText(snapFile,schema=schemas) //合并10档数据为1列，耗时约15秒 arrayVectorTb = select SecurityID,TradeTime,PreClosePx,OpenPx,HighPx,LowPx,LastPx,TotalVolumeTrade,TotalValueTrade,InstrumentStatus,fixedLengthArrayVector(BidPrice0,BidPrice1,BidPrice2,BidPrice3,BidPrice4,BidPrice5,BidPrice6,BidPrice7,BidPrice8,BidPrice9) as BidPrice,fixedLengthArrayVector(BidOrderQty0,BidOrderQty1,BidOrderQty2,BidOrderQty3,BidOrderQty4,BidOrderQty5,BidOrderQty6,BidOrderQty7,BidOrderQty8,BidOrderQty9) as BidOrderQty,fixedLengthArrayVector(BidOrders0,BidOrders1,BidOrders2,BidOrders3,BidOrders4,BidOrders5,BidOrders6,BidOrders7,BidOrders8,BidOrders9) as BidOrders ,fixedLengthArrayVector(OfferPrice0,OfferPrice1,OfferPrice2,OfferPrice3,OfferPrice4,OfferPrice5,OfferPrice6,OfferPrice7,OfferPrice8,OfferPrice9) as OfferPrice,fixedLengthArrayVector(OfferOrderQty0,OfferOrderQty1,OfferOrderQty2,OfferOrderQty3,OfferOrderQty4,OfferOrderQty5,OfferOrderQty6,OfferOrderQty7,OfferOrderQty8,OfferOrderQty9) as OfferOrderQty,fixedLengthArrayVector(OfferOrders0,OfferOrders1,OfferOrders2,OfferOrders3,OfferOrders4,OfferOrders5,OfferOrders6,OfferOrders7,OfferOrders8,OfferOrders9) as OfferOrders,NumTrades,IOPV,TotalBidQty,TotalOfferQty,WeightedAvgBidPx,WeightedAvgOfferPx,TotalBidNumber,TotalOfferNumber,BidTradeMaxDuration,OfferTradeMaxDuration,NumBidOrders,NumOfferOrders,WithdrawBuyNumber,WithdrawBuyAmount,WithdrawBuyMoney,WithdrawSellNumber,WithdrawSellAmount,WithdrawSellMoney,ETFBuyNumber,ETFBuyAmount,ETFBuyMoney,ETFSellNumber,ETFSellAmount,ETFSellMoney from rawTb //载入数据库，耗时约60秒 loadTable(dbpath, tbName).append!(arrayVectorTb)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:73;568:1&#34;&gt;由上述代码可以看出，数据导入到分布式数据表，共耗时约2分45秒。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;53-使用-loadtextex-函数时指定-transform-参数将文本文件导入分布式数据库&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:20;570:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:20;570:1&#34;&gt;5.3. 使用 loadTextEx 函数时指定 transform 参数，将文本文件导入分布式数据库&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:20;570:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:74;572:1&#34;&gt;使用上文中提到的通过为 loadTextEx 指定 transform 参数的方式，一步到位地将数据导入分布式数据库。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:75;574:1&#34;&gt;自定义函数&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:45;574:6&#34;&gt;toArrayVector&lt;/codeph&gt;，将10档数据合并为1列，重新排序列，并返回处理后的数据表。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:37;576:1&#34;&gt;def toArrayVector(mutable tmp){ //将10档数据合并为1列，添加到tmp表中。也可以使用update!方法添加。 tmp[`BidPrice]=fixedLengthArrayVector(tmp.BidPrice0,tmp.BidPrice1,tmp.BidPrice2,tmp.BidPrice3,tmp.BidPrice4,tmp.BidPrice5,tmp.BidPrice6,tmp.BidPrice7,tmp.BidPrice8,tmp.BidPrice9) tmp[`BidOrderQty]=fixedLengthArrayVector(tmp.BidOrderQty0,tmp.BidOrderQty1,tmp.BidOrderQty2,tmp.BidOrderQty3,tmp.BidOrderQty4,tmp.BidOrderQty5,tmp.BidOrderQty6,tmp.BidOrderQty7,tmp.BidOrderQty8,tmp.BidOrderQty9) tmp[`BidOrders]=fixedLengthArrayVector(tmp.BidOrders0,tmp.BidOrders1,tmp.BidOrders2,tmp.BidOrders3,tmp.BidOrders4,tmp.BidOrders5,tmp.BidOrders6,tmp.BidOrders7,tmp.BidOrders8,tmp.BidOrders9) tmp[`OfferPrice]=fixedLengthArrayVector(tmp.OfferPrice0,tmp.OfferPrice1,tmp.OfferPrice2,tmp.OfferPrice3,tmp.OfferPrice4,tmp.OfferPrice5,tmp.OfferPrice6,tmp.OfferPrice7,tmp.OfferPrice8,tmp.OfferPrice9) tmp[`OfferOrderQty]=fixedLengthArrayVector(tmp.OfferOrderQty0,tmp.OfferOrderQty1,tmp.OfferOrderQty2,tmp.OfferOrderQty3,tmp.OfferOrderQty4,tmp.OfferOrderQty5,tmp.OfferOrderQty6,tmp.OfferOrderQty7,tmp.OfferOrderQty8,tmp.OfferOrderQty9) tmp[`OfferOrders]=fixedLengthArrayVector(tmp.OfferOrders0,tmp.OfferOrders1,tmp.OfferOrders2,tmp.OfferOrders3,tmp.OfferOrders4,tmp.OfferOrders5,tmp.OfferOrders6,tmp.OfferOrders7,tmp.OfferOrders8,tmp.OfferOrders9) //删除合并前的列 tmp.dropColumns!(`BidPrice0`BidPrice1`BidPrice2`BidPrice3`BidPrice4`BidPrice5`BidPrice6`BidPrice7`BidPrice8`BidPrice9`BidOrderQty0`BidOrderQty1`BidOrderQty2`BidOrderQty3`BidOrderQty4`BidOrderQty5`BidOrderQty6`BidOrderQty7`BidOrderQty8`BidOrderQty9`BidOrders0`BidOrders1`BidOrders2`BidOrders3`BidOrders4`BidOrders5`BidOrders6`BidOrders7`BidOrders8`BidOrders9`OfferPrice0`OfferPrice1`OfferPrice2`OfferPrice3`OfferPrice4`OfferPrice5`OfferPrice6`OfferPrice7`OfferPrice8`OfferPrice9`OfferOrderQty0`OfferOrderQty1`OfferOrderQty2`OfferOrderQty3`OfferOrderQty4`OfferOrderQty5`OfferOrderQty6`OfferOrderQty7`OfferOrderQty8`OfferOrderQty9`OfferOrders0`OfferOrders1`OfferOrders2`OfferOrders3`OfferOrders4`OfferOrders5`OfferOrders6`OfferOrders7`OfferOrders8`OfferOrders9) //对列重新排序 tmp.reorderColumns!(`SecurityID`TradeTime`PreClosePx`OpenPx`HighPx`LowPx`LastPx`TotalVolumeTrade`TotalValueTrade`InstrumentStatus`BidPrice`BidOrderQty`BidOrders`OfferPrice`OfferOrderQty`OfferOrders`NumTrades`IOPV`TotalBidQty`TotalOfferQty`WeightedAvgBidPx`WeightedAvgOfferPx`TotalBidNumber`TotalOfferNumber`BidTradeMaxDuration`OfferTradeMaxDuration`NumBidOrders`NumOfferOrders`WithdrawBuyNumber`WithdrawBuyAmount`WithdrawBuyMoney`WithdrawSellNumber`WithdrawSellAmount`WithdrawSellMoney`ETFBuyNumber`ETFBuyAmount`ETFBuyMoney`ETFSellNumber`ETFSellAmount`ETFSellMoney) return tmp }&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:76;593:1&#34;&gt;调用 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:46;593:4&#34;&gt;loadTextEx&lt;/codeph&gt; 函数，并且指定 transform 参数为 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:47;593:39&#34;&gt;toArrayVector&lt;/codeph&gt; 函数，系统会对文本文件中的数据执行&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:48;593:72&#34;&gt;toArrayVector&lt;/codeph&gt; 函数，并将结果保存到数据库中。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:38;595:1&#34;&gt;db=database(dbpath) db.loadTextEx(tbName, `Tradetime`SecurityID, snapFile, schema=schemas, transform=toArrayVector)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:77;600:1&#34;&gt;数据导入分布式表耗时约1分40秒，比5.2章节的方法快了65秒。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;6-使用map-reduce自定义数据导入&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:21;602:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:21;602:1&#34;&gt;6. 使用Map-Reduce自定义数据导入&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:21;602:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:78;604:1&#34;&gt;DolphinDB支持使用Map-Reduce自定义数据导入，将数据按行进行划分，并将划分后的数据通过Map-Reduce导入到DolphinDB。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:79;606:1&#34;&gt;可使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:49;606:4&#34;&gt;textChunkDS&lt;/codeph&gt;函数将文件划分为多个小文件数据源，再通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:50;606:37&#34;&gt;mr&lt;/codeph&gt;函数写入到数据库中。在调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:51;606:54&#34;&gt;mr&lt;/codeph&gt;将数据存入数据库前，用户还可进行灵活的数据处理，从而实现更复杂的导入需求。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;61-将文件中的股票和期货数据存储到两个不同的数据表&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:22;608:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:22;608:1&#34;&gt;6.1. 将文件中的股票和期货数据存储到两个不同的数据表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:22;608:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:80;610:1&#34;&gt;在DolphinDB中执行以下脚本，生成一个大小约为1.6GB的数据文件，其中包括股票数据和期货数据。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:39;611:1&#34;&gt;n=10000000 dataFilePath=&#34;/home/data/chunkText.csv&#34; trades=table(rand(`stock`futures,n) as type, rand(`IBM`MSFT`GM`C`FB`GOOG`V`F`XOM`AMZN`TSLA`PG`S,n) as sym,take(2000.01.01..2000.06.30,n) as date,10.0+rand(2.0,n) as price1,100.0+rand(20.0,n) as price2,1000.0+rand(200.0,n) as price3,10000.0+rand(2000.0,n) as price4,10000.0+rand(3000.0,n) as price5,10000.0+rand(4000.0,n) as price6,rand(10,n) as qty1,rand(100,n) as qty2,rand(1000,n) as qty3,rand(10000,n) as qty4,rand(10000,n) as qty5,rand(10000,n) as qty6) trades.saveText(dataFilePath);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:81;618:1&#34;&gt;分别创建用于存放股票数据和期货数据的分布式数据库和表:&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:40;619:1&#34;&gt;login(`admin,`123456) dbPath1=&#34;dfs://stocksDatabase&#34; dbPath2=&#34;dfs://futuresDatabase&#34; db1=database(dbPath1,VALUE,`IBM`MSFT`GM`C`FB`GOOG`V`F`XOM`AMZN`TSLA`PG`S) db2=database(dbPath2,VALUE,2000.01.01..2000.06.30) tb1=db1.createPartitionedTable(trades,`stock,`sym) tb2=db2.createPartitionedTable(trades,`futures,`date);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:82;629:1&#34;&gt;定义以下函数，用于划分数据，并将数据写入到不同的数据库。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:41;630:1&#34;&gt;def divideImport(tb, mutable stockTB, mutable futuresTB) { tdata1=select * from tb where type=&#34;stock&#34; tdata2=select * from tb where type=&#34;futures&#34; append!(stockTB, tdata1) append!(futuresTB, tdata2) }&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:83;640:1&#34;&gt;再通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:52;640:4&#34;&gt;textChunkDS&lt;/codeph&gt;函数划分文本文件，以300MB为单位进行划分，文件被划分成了6部分。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:42;641:1&#34;&gt;ds=textChunkDS(dataFilePath,300) ds; (DataSource&amp;lt;readTableFromFileSegment, DataSource&amp;lt;readTableFromFileSegment, DataSource&amp;lt;readTableFromFileSegment, DataSource&amp;lt;readTableFromFileSegment)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:84;648:1&#34;&gt;调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:53;648:3&#34;&gt;mr&lt;/codeph&gt;函数，指定&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:54;648:12&#34;&gt;textChunkDS&lt;/codeph&gt;函数结果为数据源，将文件导入到数据库中。由于map函数（由mapFunc参数指定）只接受一个表作为参数，这里我们使用部分应用将多参数函数转换为一个参数的函数。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:43;650:1&#34;&gt;mr(ds=ds, mapFunc=divideImport{,tb1,tb2}, parallel=false);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:85;654:1&#34;&gt;请注意，这里不同的小文件数据源可能包含相同分区的数据。DolphinDB不允许多个线程同时对相同分区进行写入，因此要将&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:55;654:60&#34;&gt;mr&lt;/codeph&gt;函数的parallel参数设置为false，否则会抛出异常。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:86;656:1&#34;&gt;查看2个数据库中表的前5行，股票数据库中均为股票数据，期货数据库中均为期货数据。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:87;658:1&#34;&gt;stock表：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:44;660:1&#34;&gt;select top 5 * from loadTable(dbPath1, `stock); type sym date price1 price2 price3 price4 price5 price6 qty1 qty2 qty3 qty4 qty5 qty6 ----- ---- ---------- --------- ---------- ----------- ------------ ------------ ------------ ---- ---- ---- ---- ---- ---- stock AMZN 2000.02.14 11.224234 112.26763 1160.926836 11661.418403 11902.403305 11636.093467 4 53 450 2072 9116 12 stock AMZN 2000.03.29 10.119057 111.132165 1031.171855 10655.048121 12682.656303 11182.317321 6 21 651 2078 7971 6207 stock AMZN 2000.06.16 11.61637 101.943971 1019.122963 10768.996906 11091.395164 11239.242307 0 91 857 3129 3829 811 stock AMZN 2000.02.20 11.69517 114.607763 1005.724332 10548.273754 12548.185724 12750.524002 1 39 270 4216 8607 6578 stock AMZN 2000.02.23 11.534805 106.040664 1085.913295 11461.783565 12496.932604 12995.461331 4 35 488 4042 6500 4826&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:88;672:1&#34;&gt;futures表：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:45;674:1&#34;&gt;select top 5 * from loadTable(dbPath2, `futures); type sym date price1 price2 price3 price4 price5 price6 qty1 qty2 qty3 qty4 qty5 ... ------- ---- ---------- --------- ---------- ----------- ------------ ------------ ------------ ---- ---- ---- ---- ---- --- futures MSFT 2000.01.01 11.894442 106.494131 1000.600933 10927.639217 10648.298313 11680.875797 9 10 241 524 8325 ... futures S 2000.01.01 10.13728 115.907379 1140.10161 11222.057315 10909.352983 13535.931446 3 69 461 4560 2583 ... futures GM 2000.01.01 10.339581 112.602729 1097.198543 10938.208083 10761.688725 11121.888288 1 1 714 6701 9203 ... futures IBM 2000.01.01 10.45422 112.229537 1087.366764 10356.28124 11829.206165 11724.680443 0 47 741 7794 5529 ... futures TSLA 2000.01.01 11.901426 106.127109 1144.022732 10465.529256 12831.721586 10621.111858 4 43 136 9858 8487 ...&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;62-快速加载大文件首尾部分数据&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:23;686:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:23;686:1&#34;&gt;6.2. 快速加载大文件首尾部分数据&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:23;686:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:89;688:1&#34;&gt;可使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:56;688:4&#34;&gt;textChunkDS&lt;/codeph&gt;将大文件划分成多个小的数据源(chunk)，然后加载首尾两个数据源。在DolphinDB中执行以下脚本生成数据文件：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:46;690:1&#34;&gt;n=10000000 dataFilePath=&#34;/home/data/chunkText.csv&#34; trades=table(rand(`IBM`MSFT`GM`C`FB`GOOG`V`F`XOM`AMZN`TSLA`PG`S,n) as sym,sort(take(2000.01.01..2000.06.30,n)) as date,10.0+rand(2.0,n) as price1,100.0+rand(20.0,n) as price2,1000.0+rand(200.0,n) as price3,10000.0+rand(2000.0,n) as price4,10000.0+rand(3000.0,n) as price5,10000.0+rand(4000.0,n) as price6,rand(10,n) as qty1,rand(100,n) as qty2,rand(1000,n) as qty3,rand(10000,n) as qty4, rand(10000,n) as qty5, rand(1000,n) as qty6) trades.saveText(dataFilePath);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:90;696:1&#34;&gt;再通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:57;696:4&#34;&gt;textChunkDS&lt;/codeph&gt;函数划分文本文件，以10MB为单位进行划分。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:47;698:1&#34;&gt;ds=textChunkDS(dataFilePath, 10);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:91;702:1&#34;&gt;调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:58;702:3&#34;&gt;mr&lt;/codeph&gt;函数，加载首尾两个chunk的数据。因为这两个chunk的数据非常小，加载速度非常快。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:48;704:1&#34;&gt;head_tail_tb = mr(ds=[ds.head(), ds.tail()], mapFunc=x-&amp;gt;x, finalFunc=unionAll{,false});&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:92;708:1&#34;&gt;查看head_tail_tb表中的记录数：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:49;710:1&#34;&gt;select count(*) from head_tail_tb; count ------ 192262&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;7-其它注意事项&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:24;718:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:24;718:1&#34;&gt;7. 其它注意事项&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:24;718:1&#34;/&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;71-不同编码的数据的处理&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:25;720:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:25;720:1&#34;&gt;7.1. 不同编码的数据的处理&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:25;720:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:93;722:1&#34;&gt;由于DolphinDB的字符串采用UTF-8编码，若加载的文件不是UTF-8编码，需在导入后进行转化。DolphinDB提供了&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:59;722:64&#34;&gt;convertEncode&lt;/codeph&gt;、&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:60;722:80&#34;&gt;fromUTF8&lt;/codeph&gt;和&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:61;722:91&#34;&gt;toUTF8&lt;/codeph&gt;函数，用于导入数据后对字符串编码进行转换。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:94;724:1&#34;&gt;例如，使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeph:62;724:6&#34;&gt;convertEncode&lt;/codeph&gt;函数转换表tmpTB中的exchange列的编码：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:50;726:1&#34;&gt;dataFilePath=&#34;/home/data/candle_201801.csv&#34; tmpTB=loadText(filename=dataFilePath, skipRows=0) tmpTB.replaceColumn!(`exchange, convertEncode(tmpTB.exchange,&#34;gbk&#34;,&#34;utf-8&#34;));&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;72-数值类型的解析&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:26;732:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:26;732:1&#34;&gt;7.2. 数值类型的解析&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:26;732:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:95;734:1&#34;&gt;本教程介绍了DolphinDB在导入数据时的数据类型自动解析机制，本节讲解数值类型（包括CHAR，SHORT，INT，LONG，FLOAT和DOUBLE）数据的解析。系统能够识别以下几种形式的数值数据：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;ul:2;736:1&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:14;736:1&#34;&gt;数字表示的数值，例如：123&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:15;737:1&#34;&gt;含有千位分隔符的数值，例如：100,000&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:16;738:1&#34;&gt;含有小数点的数值，即浮点数，例如：1.231&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;li:17;739:1&#34;&gt;科学计数法表示的数值，例如：1.23E5&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:96;741:1&#34;&gt;若指定数据类型为数值类型，DolphinDB在导入时会自动忽略数字前后的字母及其他符号，如果没有出现任何数字，则解析为NULL值。下面结合例子具体说明。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:97;743:1&#34;&gt;首先，执行以下脚本，创建一个文本文件。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:51;745:1&#34;&gt;dataFilePath=&#34;/home/data/testSym.csv&#34; prices1=[&#34;2131&#34;,&#34;$2,131&#34;, &#34;N/A&#34;] prices2=[&#34;213.1&#34;,&#34;$213.1&#34;, &#34;N/A&#34;] totals=[&#34;2.658E7&#34;,&#34;-2.658e7&#34;,&#34;2.658e-7&#34;] tt=table(1..3 as id, prices1 as price1, prices2 as price2, totals as total) saveText(tt,dataFilePath);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:98;754:1&#34;&gt;创建的文本文件中，price1和price2列中既有数字，又有字符。若导入数据时不指定schema参数，系统会将这两列均识别为SYMBOL类型：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:52;756:1&#34;&gt;tmpTB=loadText(dataFilePath) tmpTB; id price1 price2 total -- ------ ------ -------- 1 2131 213.1 2.658E7 2 $2,131 $213.1 -2.658E7 3 N/A N/A 2.658E-7 tmpTB.schema().colDefs; name typeString typeInt comment ------ ---------- ------- ------- id INT 4 price1 SYMBOL 17 price2 SYMBOL 17 total DOUBLE 16&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:99;776:1&#34;&gt;若指定price1列为INT类型，指定price2列为DOUBLE类型，导入时系统会忽略数字前后的字母及其他符号。如果没有出现任何数字，则解析为NULL值。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:53;778:1&#34;&gt;schemaTB=table(`id`price1`price2`total as name, `INT`INT`DOUBLE`DOUBLE as type) tmpTB=loadText(dataFilePath,,schemaTB) tmpTB; id price1 price2 total -- ------ ------ -------- 1 2131 213.1 2.658E7 2 2131 213.1 -2.658E7 3 2.658E-7&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;73-自动去除双引号&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:27;790:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:27;790:1&#34;&gt;7.3. 自动去除双引号&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:27;790:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:100;792:1&#34;&gt;在CSV文件中，有时候会用双引号来处理数值中含有的特殊字符（譬如千位分隔符）的字段。DolphinDB处理这样的数据时，会自动去除文本外的双引号。下面结合例子具体说明。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:101;794:1&#34;&gt;在下例所用的数据文件中，num列为使用千位分节法表示的数值。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:54;796:1&#34;&gt;dataFilePath=&#34;/home/data/test.csv&#34; tt=table(1..3 as id, [&#34;\&#34;500\&#34;&#34;,&#34;\&#34;3,500\&#34;&#34;,&#34;\&#34;9,000,000\&#34;&#34;] as num) saveText(tt,dataFilePath);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:102;802:1&#34;&gt;导入数据并查看表内数据，DolphinDB自动脱去了文本外的双引号。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;codeblock:55;804:1&#34;&gt;tmpTB=loadText(dataFilePath) tmpTB; id num -- ------- 1 500 2 3500 3 9000000&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; id=&#34;8-附录&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;topic:28;816:1&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;title:28;816:1&#34;&gt;8. 附录&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;body:28;816:1&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:103;817:1&#34;&gt;--&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;p:104;819:1&#34;&gt;本教程的例子中使用的数据文件： &lt;xref class=&#34;- topic/xref &#34; href=&#34;data/candle_201801.csv&#34; format=&#34;csv&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/import_csv.md&#34; xtrc=&#34;xref:3;819:17&#34;&gt;&lt;?ditaot usertext?&gt;candle_201801.csv&lt;/xref&gt;。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;"/><meta name="wh-source-relpath" content="tutorials/import_csv.md"/><meta name="wh-out-relpath" content="tutorials/import_csv.html"/>

    <link rel="stylesheet" type="text/css" href="../oxygen-webhelp/app/commons.css?buildId=2024012323"/>
    <link rel="stylesheet" type="text/css" href="../oxygen-webhelp/app/topic.css?buildId=2024012323"/>

    <script src="../oxygen-webhelp/app/options/properties.js?buildId=20250305183303"></script>
    <script src="../oxygen-webhelp/app/localization/strings.js?buildId=2024012323"></script>
    <script src="../oxygen-webhelp/app/search/index/keywords.js?buildId=20250305183303"></script>
    <script defer="defer" src="../oxygen-webhelp/app/commons.js?buildId=2024012323"></script>
    <script defer="defer" src="../oxygen-webhelp/app/topic.js?buildId=2024012323"></script>
<link rel="stylesheet" type="text/css" href="../oxygen-webhelp/template/styles.css?buildId=2024012323"/><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script></head>

    <body id="文本数据导入" class="wh_topic_page frmBody">
        <a href="#wh_topic_body" class="sr-only sr-only-focusable">
            跳转到主要内容
        </a>
        
        
        
        
        <header class="navbar navbar-default wh_header">
    <div class="container-fluid">
        <div xmlns:whc="http://www.oxygenxml.com/webhelp/components" class="wh_header_flex_container navbar-nav navbar-expand-md navbar-dark">
            <div class="wh_logo_and_publication_title_container">
                <div class="wh_logo_and_publication_title">
                    
                    <a href="https://docs.dolphindb.cn/zh/index.html" class=" wh_logo d-none d-sm-block "><img src="../logo.png" alt="  DolphinDB 文档中心  "/></a>
                    <div class=" wh_publication_title "><a href="../index.html"><span class="booktitle">  <span class="ph mainbooktitle">DolphinDB 文档中心</span>  </span></a></div>
                    
                </div>
                
                
            </div>

            <div class="wh_top_menu_and_indexterms_link collapse navbar-collapse" id="wh_top_menu_and_indexterms_link">
                
                
                
                
            </div>
        <div class=" wh_search_input navbar-form wh_topic_page_search search " role="form">
            
            
            
            <form id="searchForm" method="get" role="search" action="../search.html"><div><input type="search" placeholder="搜索 " class="wh_search_textfield" id="textToSearch" name="searchQuery" aria-label="搜索查询" required="required"/><button type="submit" class="wh_search_button" aria-label="搜索"><span class="search_input_text">搜索</span></button></div></form>
            
            <script src="/vendors/react/umd/react.production.min.js" defer="defer"></script>
<script src="/vendors/react-dom/umd/react-dom.production.min.js" defer="defer"></script>
<script src="/vendors/dayjs/dayjs.min.js" defer="defer"></script>
<script src="/vendors/antd/dist/antd.min.js" defer="defer"></script>
<script src="/vendors/@ant-design/icons/dist/index.umd.min.js" defer="defer"></script>
<script src="/zh/index.js" type="module"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" defer="defer"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer="defer"><!--


--></script>
<script defer="defer"><!--

// 从主页重定向
const currentUrl = window.location.href;

// 判断当前URL是否包含index.html并且路径最后部分是index.html
if (currentUrl.endsWith('index.html')) {
    // 处理根目录下的index.html跳转
    const baseUrl = currentUrl.split('/index.html')[0]; // 获取index.html之前的部分
    const redirectUrl = `${baseUrl}/about/ddb_intro.html`; // 构建跳转路径
    window.location.href = redirectUrl; // 执行跳转
}

--></script>
            
        </div></div>
    </div>
</header>
        
        
         
        
        
        
        <div class="container-fluid" id="wh_topic_container">
            <div class="row">

                <nav class="wh_tools d-print-none navbar-expand-md" aria-label="Tools">
                    
                    <div data-tooltip-position="bottom" class=" wh_breadcrumb "></div>
                    
                    
                    
                    <div class="wh_right_tools">
                        <button class="wh_hide_highlight" aria-label="切换搜索突出显示" title="切换搜索突出显示"></button>
                        <button class="webhelp_expand_collapse_sections" data-next-state="collapsed" aria-label="折叠截面" title="折叠截面"></button>
                        
                        
                        
                        
                        <div class=" wh_print_link print d-none d-md-inline-block "><button onClick="window.print()" title="打印此页" aria-label="打印此页"></button></div>
                        
                        
                    </div>
                    
                </nav>
            </div>
            
            
            
            
            <div class="wh_content_area">
                <div class="row">
                    
                    
                    <div class="col-lg-10 col-md-10 col-sm-10 col-xs-12" id="wh_topic_body">
                        
                        <button id="wh_close_topic_toc_button" class="close-toc-button d-none" aria-label="Toggle topic table of content" aria-controls="wh_topic_toc" aria-expanded="true">
                            <span class="close-toc-icon-container">
                                <span class="close-toc-icon"></span>     
                            </span>
                        </button>
                        
                        <div class=" wh_topic_content body "><main role="main"><article class="- topic/topic topic" role="article" aria-labelledby="ariaid-title1"><h1 class="- topic/title title topictitle1" id="ariaid-title1">文本数据导入</h1><div class="- topic/body body"><p class="- topic/p p">DolphinDB提供以下4个函数，将文本数据导入内存或数据库：</p><ul class="- topic/ul ul"><li class="- topic/li li"><code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>：将文本文件导入为内存表。</li><li class="- topic/li li"><code class="+ topic/ph pr-d/codeph ph codeph">ploadText</code>：将文本文件并行导入为分区内存表。与<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>函数相比，速度更快。</li><li class="- topic/li li"><code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>：将文本文件导入数据库中，包括分布式数据库或内存数据库。</li><li class="- topic/li li"><code class="+ topic/ph pr-d/codeph ph codeph">textChunkDS</code>：将文本文件划分为多个小数据源，再通过<code class="+ topic/ph pr-d/codeph ph codeph">mr</code>函数进行灵活的数据处理。</li></ul><p class="- topic/p p">DolphinDB的文本数据导入不仅灵活，而且速度非常快。DolphinDB与Clickhouse, MemSQL, Druid, Pandas等业界流行的系统相比，单线程导入的速度优势，最多可达一个数量级；多线程并行导入的情况下，速度优势更加明显。</p><p class="- topic/p p">本教程介绍文本数据导入时的常见问题，相应的解决方案以及注意事项。</p></div><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title2" id="1-自动识别数据格式"><h2 class="- topic/title title topictitle2" id="ariaid-title2">1. 自动识别数据格式</h2><div class="- topic/body body"><p class="- topic/p p">大多数其它系统中，导入文本数据时，需要由用户指定数据的格式。DolphinDB在导入数据时，能够自动识别数据格式，为用户提供了方便。</p><p class="- topic/p p">自动识别数据格式包括两部分：字段名称识别和数据类型识别。如果文件的第一行没有任何一列以数字开头，那么系统认为第一行是文件头，包含了字段名称。DolphinDB会抽取少量部分数据作为样本，并自动推断各列的数据类型。因为是基于部分数据，某些列的数据类型可能识别错误。但是对于大多数文本文件，无须手动指定各列的字段名称和数据类型，就能正确地导入到DolphinDB中。</p><p class="- topic/p p">请注意：1.20.0之前的版本不支持导入INT128, UUID和IPADDR这三种数据类型。如果在csv文件中包含这三种数据类型，请确保所用版本不低于1.20.0。</p><p class="- topic/p p"><code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>函数用于将数据导入DolphinDB内存表。下例调用<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>函数导入数据，并查看生成的数据表的结构。例子中涉及到的数据文件请参考<a class="- topic/xref xref" href="#%E9%99%84%E5%BD%95">附录</a>。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dataFilePath="/home/data/candle_201801.csv"
tmpTB=loadText(filename=dataFilePath);</code></pre><p class="- topic/p p">查看数据表前5行数据：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select top 5 * from tmpTB;

symbol exchange cycle tradingDay date       time     open  high  low   close volume  turnover   unixTime
------ -------- ----- ---------- ---------- -------- ----- ----- ----- ----- ------- ---------- -------------
000001 SZSE     1     2018.01.02 2018.01.02 93100000 13.35 13.39 13.35 13.38 2003635 2.678558E7 1514856660000
000001 SZSE     1     2018.01.02 2018.01.02 93200000 13.37 13.38 13.33 13.33 867181  1.158757E7 1514856720000
000001 SZSE     1     2018.01.02 2018.01.02 93300000 13.32 13.35 13.32 13.35 903894  1.204971E7 1514856780000
000001 SZSE     1     2018.01.02 2018.01.02 93400000 13.35 13.38 13.35 13.35 1012000 1.352286E7 1514856840000
000001 SZSE     1     2018.01.02 2018.01.02 93500000 13.35 13.37 13.35 13.37 1601939 2.140652E7 1514856900000</code></pre><p class="- topic/p p">调用<code class="+ topic/ph pr-d/codeph ph codeph">schema</code>函数查看表结构（字段名称、数据类型等信息）：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>tmpTB.schema().colDefs;

name       typeString typeInt comment
---------- ---------- ------- -------
symbol     SYMBOL     17
exchange   SYMBOL     17
cycle      INT        4
tradingDay DATE       6
date       DATE       6
time       INT        4
open       DOUBLE     16
high       DOUBLE     16
low        DOUBLE     16
close      DOUBLE     16
volume     INT        4
turnover   DOUBLE     16
unixTime   LONG       5</code></pre></div></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title3" id="2-指定数据导入格式"><h2 class="- topic/title title topictitle2" id="ariaid-title3">2. 指定数据导入格式</h2><div class="- topic/body body"><p class="- topic/p p">本教程讲述的4个数据加载函数中，均可用schema参数指定一个表，内含各字段的名称、类型、格式、需要导入的列等信息。该表可包含以下4列：</p><div class="table-container"><table class="- topic/table table" data-cols="2"><caption></caption><colgroup><col/><col/></colgroup><thead class="- topic/thead thead"><tr class="- topic/row"><th class="- topic/entry entry colsep-0 rowsep-0" id="2-指定数据导入格式__entry__1">列名</th><th class="- topic/entry entry colsep-0 rowsep-0" id="2-指定数据导入格式__entry__2">含义</th></tr></thead><tbody class="- topic/tbody tbody"><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__1">name</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__2">字符串，表示列名</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__1">type</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__2">字符串，表示每列的数据类型</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__1">format</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__2">字符串，表示日期或时间列的格式</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__1">col</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__2">整型，表示要加载的列的下标。该列的值必须是升序。</td></tr></tbody></table></div><p class="- topic/p p">其中，name和type这两列是必需的，而且必须是前两列。format和col这两列是可选的，且没有先后顺序的要求。</p><p class="- topic/p p">例如，我们可以使用以下的数据表作为schema参数：</p><div class="table-container"><table class="- topic/table table" data-cols="2"><caption></caption><colgroup><col/><col/></colgroup><thead class="- topic/thead thead"><tr class="- topic/row"><th class="- topic/entry entry colsep-0 rowsep-0" id="2-指定数据导入格式__entry__11">name</th><th class="- topic/entry entry colsep-0 rowsep-0" id="2-指定数据导入格式__entry__12">type</th></tr></thead><tbody class="- topic/tbody tbody"><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__11">timestamp</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__12">SECOND</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__11">ID</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__12">INT</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__11">qty</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__12">INT</td></tr><tr class="- topic/row"><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__11">price</td><td class="- topic/entry entry colsep-0 rowsep-0" headers="2-指定数据导入格式__entry__12">DOUBLE</td></tr></tbody></table></div></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title4" id="21-提取文本文件的schema"><h3 class="- topic/title title topictitle3" id="ariaid-title4">2.1. 提取文本文件的schema</h3><div class="- topic/body body"><p class="- topic/p p"><code class="+ topic/ph pr-d/codeph ph codeph">extractTextSchema</code>函数用于获取文本文件的schema，包括字段名称和数据类型等信息。</p><p class="- topic/p p">例如，使用<code class="+ topic/ph pr-d/codeph ph codeph">extractTextSchema</code>函数得到本教程中示例文件的表结构：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dataFilePath="/home/data/candle_201801.csv"
schemaTB=extractTextSchema(dataFilePath)
schemaTB;

name       type
---------- ------
symbol     SYMBOL
exchange   SYMBOL
cycle      INT
tradingDay DATE
date       DATE
time       INT
open       DOUBLE
high       DOUBLE
low        DOUBLE
close      DOUBLE
volume     INT
turnover   DOUBLE
unixTime   LONG</code></pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title5" id="22-指定字段名称和类型"><h3 class="- topic/title title topictitle3" id="ariaid-title5">2.2. 指定字段名称和类型</h3><div class="- topic/body body"><p class="- topic/p p">当系统自动识别的字段名称或者数据类型不符合预期时，可以通过修改<code class="+ topic/ph pr-d/codeph ph codeph">extractTextSchema</code>生成的schema表或直接创建schema表为文本文件中的每列指定字段名称和数据类型。</p><p class="- topic/p p">例如，若导入数据的volume列被自动识别为INT类型，而需要的volume类型是LONG类型，就需要修改schema表，指定volumn列类型为LONG。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dataFilePath="/home/data/candle_201801.csv"
schemaTB=extractTextSchema(dataFilePath)
update schemaTB set type="LONG" where name="volume";</code></pre><p class="- topic/p p">使用<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>函数导入文本文件，将数据按照schemaTB所规定的字段数据类型导入到数据库中。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>tmpTB=loadText(filename=dataFilePath,schema=schemaTB);</code></pre><p class="- topic/p p">上例介绍了修改数据类型的情况，若要修改表中的字段名称，也可以通过同样的方法实现。</p><p class="- topic/p p">请注意，若对日期和时间相关数据类型的自动解析不符合预期，需要通过本教程指定日期和时间类型的格式小节的方式解决。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title6" id="23-指定日期和时间类型的格式"><h3 class="- topic/title title topictitle3" id="ariaid-title6">2.3. 指定日期和时间类型的格式</h3><div class="- topic/body body"><p class="- topic/p p">对于日期列或时间列的数据，如果自动识别的数据类型不符合预期，不仅需要在schema的type列指定数据类型，还需要在format列中指定格式（用字符串表示），如"MM/dd/yyyy"。如何表示日期和时间格式请参考日期和时间的调整及格式。</p><p class="- topic/p p">下面结合例子具体说明对日期和时间列指定数据类型的方法。</p><p class="- topic/p p">在DolphinDB中执行以下脚本，生成本例所需的数据文件。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dataFilePath="/home/data/timeData.csv"
t=table(["20190623 14:54:57","20190623 15:54:23","20190623 16:30:25"] as time,`AAPL`MS`IBM as sym,2200 5400 8670 as qty,54.78 59.64 65.23 as price)
saveText(t,dataFilePath);</code></pre><p class="- topic/p p">加载数据前，使用<code class="+ topic/ph pr-d/codeph ph codeph">extractTextSchema</code>函数获取该数据文件的schema:</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>schemaTB=extractTextSchema(dataFilePath)
schemaTB;

name  type
----- ------
time  SECOND
sym   SYMBOL
qty   INT
price DOUBLE</code></pre><p class="- topic/p p">显然，系统识别time列的数据类型不符合预期。如果直接加载该文件，time列的数据将为空。为了能够正确加载该文件time列的数据，需要指定time列的数据类型为DATETIME，并且指定该列的格式为"yyyyMMdd HH:mm:ss"。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>update schemaTB set type="DATETIME" where name="time"
schemaTB[`format]=["yyyyMMdd HH:mm:ss",,,];</code></pre><p class="- topic/p p">导入数据并查看，数据显示正确：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>tmpTB=loadText(dataFilePath,,schemaTB)
tmpTB;

time                sym  qty  price
------------------- ---- ---- -----
2019.06.23T14:54:57 AAPL 2200 54.78
2019.06.23T15:54:23 MS   5400 59.64
2019.06.23T16:30:25 IBM  8670 65.23</code></pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title7" id="24-导入指定列"><h3 class="- topic/title title topictitle3" id="ariaid-title7">2.4. 导入指定列</h3><div class="- topic/body body"><p class="- topic/p p">在导入数据时，可以通过schema参数指定只导入文本文件中的某几列。</p><p class="- topic/p p">下例中，只需加载文本文件中symbol, date, open, high, close, volume, turnover这7列。</p><p class="- topic/p p">首先，调用<code class="+ topic/ph pr-d/codeph ph codeph">extractTextSchema</code>函数得到目标文本文件的表结构。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dataFilePath="/home/data/candle_201801.csv"
schemaTB=extractTextSchema(dataFilePath);</code></pre><p class="- topic/p p">使用<code class="+ topic/ph pr-d/codeph ph codeph">rowNo</code>函数为各列生成列号，赋值给schema表中的col列，然后修改schema表，仅保留表示需要导入的字段的行。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>update schemaTB set col = rowNo(name)
schemaTB=select * from schemaTB where name in `symbol`date`open`high`close`volume`turnover;</code></pre><p class="- topic/p p">请注意：</p><ol class="- topic/ol ol"><li class="- topic/li li">列号从0开始。上例中第一列symbol列对应的列号是0。</li><li class="- topic/li li">导入数据时不能改变各列的先后顺序。如果需要调整列的顺序，可以将数据文件加载后，再使用<code class="+ topic/ph pr-d/codeph ph codeph">reorderColumns!</code>函数。</li></ol><p class="- topic/p p">最后，使用<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>函数，并配置schema参数，导入文本文件中指定的列。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>tmpTB=loadText(filename=dataFilePath,schema=schemaTB);</code></pre><p class="- topic/p p">查看表中前5行，只导入了所需的列：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select top 5 * from tmpTB

symbol date       open   high  close volume turnover
------ ---------- ------ ----- ----- ------ ----------
000001 2018.01.02 9.31E7 13.35 13.35 13     2.003635E6
000001 2018.01.02 9.32E7 13.37 13.33 13     867181
000001 2018.01.02 9.33E7 13.32 13.32 13     903894
000001 2018.01.02 9.34E7 13.35 13.35 13     1.012E6
000001 2018.01.02 9.35E7 13.35 13.35 13     1.601939E6</code></pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title8" id="25-跳过文本数据的前若干行"><h3 class="- topic/title title topictitle3" id="ariaid-title8">2.5. 跳过文本数据的前若干行</h3><div class="- topic/body body"><p class="- topic/p p">在数据导入时，若需跳过文件前n行（可能为文件说明），可指定skipRows参数为n。由于描述文件的说明通常不会非常冗长，因此这个参数的取值最大为1024。本教程讲述的4个数据加载函数均支持skipRows参数。</p><p class="- topic/p p">下例中，通过<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>函数导入数据文件，并且查看该文件导入以后表的总行数，以及前5行的内容。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dataFilePath="/home/data/candle_201801.csv"
tmpTB=loadText(filename=dataFilePath)
select count(*) from tmpTB;

count
-----
5040

select top 5 * from tmpTB;

symbol exchange cycle tradingDay date       time     open  high  low   close volume  turnover   unixTime
------ -------- ----- ---------- ---------- -------- ----- ----- ----- ----- ------- ---------- -------------
000001 SZSE     1     2018.01.02 2018.01.02 93100000 13.35 13.39 13.35 13.38 2003635 2.678558E7 1514856660000
000001 SZSE     1     2018.01.02 2018.01.02 93200000 13.37 13.38 13.33 13.33 867181  1.158757E7 1514856720000
000001 SZSE     1     2018.01.02 2018.01.02 93300000 13.32 13.35 13.32 13.35 903894  1.204971E7 1514856780000
000001 SZSE     1     2018.01.02 2018.01.02 93400000 13.35 13.38 13.35 13.35 1012000 1.352286E7 1514856840000
000001 SZSE     1     2018.01.02 2018.01.02 93500000 13.35 13.37 13.35 13.37 1601939 2.140652E7 1514856900000</code></pre><p class="- topic/p p">指定skipRows参数取值为1000，跳过文本文件的前1000行导入文件：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>tmpTB=loadText(filename=dataFilePath,skipRows=1000)
select count(*) from tmpTB;

count
-----
4041

select top 5 * from tmpTB;

col0   col1 col2 col3       col4       col5      col6  col7  col8  col9  col10  col11      col12
------ ---- ---- ---------- ---------- --------- ----- ----- ----- ----- ------ ---------- -------------
000001 SZSE 1    2018.01.08 2018.01.08 101000000 13.13 13.14 13.12 13.14 646912 8.48962E6  1515377400000
000001 SZSE 1    2018.01.08 2018.01.08 101100000 13.13 13.14 13.13 13.14 453647 5.958462E6 1515377460000
000001 SZSE 1    2018.01.08 2018.01.08 101200000 13.13 13.14 13.12 13.13 700853 9.200605E6 1515377520000
000001 SZSE 1    2018.01.08 2018.01.08 101300000 13.13 13.14 13.12 13.12 738920 9.697166E6 1515377580000
000001 SZSE 1    2018.01.08 2018.01.08 101400000 13.13 13.14 13.12 13.13 469800 6.168286E6 1515377640000</code></pre><p class="- topic/p p">请注意：如上例所示，在跳过前n行进行导入时，若数据文件的第一行是列名，该行会作为第一行被略过。</p><p class="- topic/p p">在上面的例子中，文本文件指定skipRows参数导入以后，由于表示列名的第一行被跳过，列名变成了默认列名：col0, col1, col2, 等等。若需要保留列名而又指定跳过前n行，可先通过<code class="+ topic/ph pr-d/codeph ph codeph">extractTextSchema</code>函数得到文本文件的schema，在导入时指定schema参数：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>schema=extractTextSchema(dataFilePath)
tmpTB=loadText(filename=dataFilePath,schema=schema,skipRows=1000)
select count(*) from tmpTB;

count
-----
4041

select top 5 * from tmpTB;

symbol exchange cycle tradingDay date       time      open  high  low   close volume turnover   unixTime
------ -------- ----- ---------- ---------- --------- ----- ----- ----- ----- ------ ---------- -------------
000001 SZSE     1     2018.01.08 2018.01.08 101000000 13.13 13.14 13.12 13.14 646912 8.48962E6  1515377400000
000001 SZSE     1     2018.01.08 2018.01.08 101100000 13.13 13.14 13.13 13.14 453647 5.958462E6 1515377460000
000001 SZSE     1     2018.01.08 2018.01.08 101200000 13.13 13.14 13.12 13.13 700853 9.200605E6 1515377520000
000001 SZSE     1     2018.01.08 2018.01.08 101300000 13.13 13.14 13.12 13.12 738920 9.697166E6 1515377580000
000001 SZSE     1     2018.01.08 2018.01.08 101400000 13.13 13.14 13.12 13.13 469800 6.168286E6 1515377640000</code></pre></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title9" id="3-并行导入数据"><h2 class="- topic/title title topictitle2" id="ariaid-title9">3. 并行导入数据</h2><div class="- topic/body body"></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title10" id="31-单个文件多线程载入内存"><h3 class="- topic/title title topictitle3" id="ariaid-title10">3.1. 单个文件多线程载入内存</h3><div class="- topic/body body"><p class="- topic/p p"><code class="+ topic/ph pr-d/codeph ph codeph">ploadText</code>函数可将一个文本文件以多线程的方式载入内存。该函数与<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>函数的语法是一致的，区别在于，<code class="+ topic/ph pr-d/codeph ph codeph">ploadText</code>函数可以快速载入大型文件（至少16MB），并且生成内存分区表。它充分利用了多核CPU来并行载入文件，并行程度取决于服务器本身CPU核数量和节点的workerNum配置。</p><p class="- topic/p p">下面比较<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>函数与<code class="+ topic/ph pr-d/codeph ph codeph">ploadText</code>函数导入同一个文件的性能。</p><p class="- topic/p p">首先通过脚本生成一个4GB左右的文本文件：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock txt"><code>filePath="/home/data/testFile.csv"
appendRows=100000000
t=table(rand(100,appendRows) as int,take(string('A'..'Z'),appendRows) as symbol,take(2010.01.01..2018.12.30,appendRows) as date,rand(float(100),appendRows) as float,00:00:00.000 + rand(86400000,appendRows) as time)
t.saveText(filePath);</code></pre><p class="- topic/p p">分别通过<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>和<code class="+ topic/ph pr-d/codeph ph codeph">ploadText</code>来载入文件。本例所用节点是6核12超线程的CPU。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock txt"><code>timer loadText(filePath);
Time elapsed: 12629.492 ms

timer ploadText(filePath);
Time elapsed: 2669.702 ms</code></pre><p class="- topic/p p">结果显示在此配置下，<code class="+ topic/ph pr-d/codeph ph codeph">ploadText</code>的性能是<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>的4.5倍左右。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title11" id="32-多文件并行导入"><h3 class="- topic/title title topictitle3" id="ariaid-title11">3.2. 多文件并行导入</h3><div class="- topic/body body"><p class="- topic/p p">在大数据应用领域，数据导入往往不只是一个或两个文件的导入，而是数十个甚至数百个大型文件的批量导入。为了达到更好的导入性能，建议尽量以并行方式导入批量的数据文件。</p><p class="- topic/p p"><code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>函数可将文本文件导入指定的数据库中，包括分布式数据库或内存数据库。由于DolphinDB的分区表支持并发读写，因此可以支持多线程导入数据。</p><p class="- topic/p p">使用<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>将文本数据导入到分布式数据库，具体实现为将数据先导入到内存，再由内存写入到数据库，这两个步骤由同一个函数完成，以保证高效率。</p><p class="- topic/p p">下例展示如何将磁盘上的多个文件批量写入到DolphinDB分区表中。首先，在DolphinDB中执行以下脚本，生成100个文件，共约778MB，包括1千万条记录。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>n=100000
dataFilePath="/home/data/multi/multiImport_"+string(1..100)+".csv"
for (i in 0..99){
    trades=table(sort(take(100*i+1..100,n)) as id,rand(`IBM`MSFT`GM`C`FB`GOOG`V`F`XOM`AMZN`TSLA`PG`S,n) as sym,take(2000.01.01..2000.06.30,n) as date,10.0+rand(2.0,n) as price1,100.0+rand(20.0,n) as price2,1000.0+rand(200.0,n) as price3,10000.0+rand(2000.0,n) as price4,10000.0+rand(3000.0,n) as price5)
    trades.saveText(dataFilePath[i])
};</code></pre><p class="- topic/p p">创建数据库和表：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>login(`admin,`123456)
dbPath="dfs://DolphinDBdatabase"
db=database(dbPath,VALUE,1..10000)
tb=db.createPartitionedTable(trades,`tb,`id);</code></pre><p class="- topic/p p">DolphinDB的<code class="+ topic/ph pr-d/codeph ph codeph">cut</code>函数可将一个向量中的元素分组。下面调用<code class="+ topic/ph pr-d/codeph ph codeph">cut</code>函数将待导入的文件路径进行分组，再调用<code class="+ topic/ph pr-d/codeph ph codeph">submitJob</code>函数，为每个线程分配写入任务，批量导入数据。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def writeData(db,file){
   loop(loadTextEx{db,`tb,`id,},file)
}
parallelLevel=10
for(x in dataFilePath.cut(100/parallelLevel)){
    submitJob("loadData"+parallelLevel,"loadData",writeData{db,x})
};</code></pre><p class="- topic/p p">通过<code class="+ topic/ph pr-d/codeph ph codeph">getRecentJobs</code>函数可以取得当前本地节点上最近n个批处理作业的状态。使用select语句计算并行导入批量文件所需时间，得到在6核12超线程的CPU上耗时约1.59秒。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select max(endTime) - min(startTime) from getRecentJobs() where jobId like ("loadData"+string(parallelLevel)+"%");

max_endTime_sub
---------------
1590</code></pre><p class="- topic/p p">执行以下脚本，将100个文件单线程顺序导入数据库，记录所需时间，耗时约8.65秒。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>timer writeData(db, dataFilePath);
Time elapsed: 8647.645 ms</code></pre><p class="- topic/p p">结果显示在此配置下，并行开启10个线程导入速度是单线程导入的5.5倍左右。</p><p class="- topic/p p">查看数据表中的记录条数：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select count(*) from loadTable("dfs://DolphinDBdatabase", `tb);

count
------
10000000</code></pre></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title12" id="4-导入数据库前的预处理"><h2 class="- topic/title title topictitle2" id="ariaid-title12">4. 导入数据库前的预处理</h2><div class="- topic/body body"><p class="- topic/p p">在将数据导入数据库之前，若需要对数据进行预处理，例如转换日期和时间数据类型，填充空值等，可以在调用<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>函数时指定transform参数。tansform参数接受一个函数作为参数，并且要求该函数只能接受一个参数。函数的输入是一个未分区的内存表，输出也是一个未分区的内存表。需要注意的是，只有<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>函数提供transform参数。</p></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title13" id="41-指定日期和时间数据的数据类型"><h3 class="- topic/title title topictitle3" id="ariaid-title13">4.1. 指定日期和时间数据的数据类型</h3><div class="- topic/body body"></div><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title14" id="411-将数值类型表示的日期和时间转化为指定类型"><h4 class="- topic/title title topictitle4" id="ariaid-title14">4.1.1. 将数值类型表示的日期和时间转化为指定类型</h4><div class="- topic/body body"><p class="- topic/p p">数据文件中表示时间的数据可能是整型或者长整型，而在进行数据分析时，往往又需要将这类数据强制转化为时间类型的格式导入并存储到数据库中。针对这种场景，可通过<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>函数的transform参数为文本文件中的日期和时间列指定相应的数据类型。</p><p class="- topic/p p">首先，创建分布式数据库和表。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>login(`admin,`123456)
dataFilePath="/home/data/candle_201801.csv"
dbPath="dfs://DolphinDBdatabase"
db=database(dbPath,VALUE,2018.01.02..2018.01.30)
schemaTB=extractTextSchema(dataFilePath)
update schemaTB set type="TIME" where name="time"
tb=table(1:0,schemaTB.name,schemaTB.type)
tb=db.createPartitionedTable(tb,`tb1,`date);</code></pre><p class="- topic/p p">自定义函数<code class="+ topic/ph pr-d/codeph ph codeph">i2t</code>，用于对数据进行预处理，并返回处理过后的数据表。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def i2t(mutable t){
    return t.replaceColumn!(`time,time(t.time/10))
}</code></pre><p class="- topic/p p">请注意：在自定义函数体内对数据进行处理时，请尽量使用本地的修改（以!结尾的函数）来提升性能。</p><p class="- topic/p p">调用<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>函数，并且指定transform参数为<code class="+ topic/ph pr-d/codeph ph codeph">i2t</code>函数，系统会对文本文件中的数据执行<code class="+ topic/ph pr-d/codeph ph codeph">i2t</code>函数，并将结果保存到数据库中。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>tmpTB=loadTextEx(dbHandle=db,tableName=`tb1,partitionColumns=`date,filename=dataFilePath,transform=i2t);</code></pre><p class="- topic/p p">查看表内前5行数据。可见time列是以TIME类型存储，而不是文本文件中的INT类型：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select top 5 * from loadTable(dbPath,`tb1);

symbol exchange cycle tradingDay date       time               open  high  low   close volume  turnover   unixTime
------ -------- ----- ---------- ---------- ------------------ ----- ----- ----- ----- ------- ---------- -------------
000001 SZSE     1     2018.01.02 2018.01.02 02:35:10.000000000 13.35 13.39 13.35 13.38 2003635 2.678558E7 1514856660000
000001 SZSE     1     2018.01.02 2018.01.02 02:35:20.000000000 13.37 13.38 13.33 13.33 867181  1.158757E7 1514856720000
000001 SZSE     1     2018.01.02 2018.01.02 02:35:30.000000000 13.32 13.35 13.32 13.35 903894  1.204971E7 1514856780000
000001 SZSE     1     2018.01.02 2018.01.02 02:35:40.000000000 13.35 13.38 13.35 13.35 1012000 1.352286E7 1514856840000
000001 SZSE     1     2018.01.02 2018.01.02 02:35:50.000000000 13.35 13.37 13.35 13.37 1601939 2.140652E7 1514856900000</code></pre></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title15" id="412-日期或时间数据类型之间转换"><h4 class="- topic/title title topictitle4" id="ariaid-title15">4.1.2. 日期或时间数据类型之间转换</h4><div class="- topic/body body"><p class="- topic/p p">若文本文件中日期以DATE类型存储，在导入数据库时希望以MONTH的形式存储，这种情况也可通过<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>函数的transform参数转换该日期列的数据类型，步骤与上一小节一致。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>login(`admin,`123456)
dbPath="dfs://DolphinDBdatabase"
db=database(dbPath,VALUE,2018.01.02..2018.01.30)
schemaTB=extractTextSchema(dataFilePath)
update schemaTB set type="MONTH" where name="tradingDay"
tb=table(1:0,schemaTB.name,schemaTB.type)
tb=db.createPartitionedTable(tb,`tb1,`date)
def d2m(mutable t){
    return t.replaceColumn!(`tradingDay,month(t.tradingDay))
}
tmpTB=loadTextEx(dbHandle=db,tableName=`tb1,partitionColumns=`date,filename=dataFilePath,transform=d2m);</code></pre><p class="- topic/p p">查看表内前5行数据。可见tradingDay列是以MONTH类型存储，而不是文本文件中的DATE类型：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select top 5 * from loadTable(dbPath,`tb1);

symbol exchange cycle tradingDay date       time     open  high  low   close volume  turnover   unixTime
------ -------- ----- ---------- ---------- -------- ----- ----- ----- ----- ------- ---------- -------------
000001 SZSE     1     2018.01M   2018.01.02 93100000 13.35 13.39 13.35 13.38 2003635 2.678558E7 1514856660000
000001 SZSE     1     2018.01M   2018.01.02 93200000 13.37 13.38 13.33 13.33 867181  1.158757E7 1514856720000
000001 SZSE     1     2018.01M   2018.01.02 93300000 13.32 13.35 13.32 13.35 903894  1.204971E7 1514856780000
000001 SZSE     1     2018.01M   2018.01.02 93400000 13.35 13.38 13.35 13.35 1012000 1.352286E7 1514856840000
000001 SZSE     1     2018.01M   2018.01.02 93500000 13.35 13.37 13.35 13.37 1601939 2.140652E7 1514856900000</code></pre></div></article></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title16" id="42-填充空值"><h3 class="- topic/title title topictitle3" id="ariaid-title16">4.2. 填充空值</h3><div class="- topic/body body"><p class="- topic/p p">transform参数可调用DolphinDB的内置函数。当内置函数要求多个参数时，我们可以使用部分应用将多参数函数转换为一个参数的函数。例如，调用<code class="+ topic/ph pr-d/codeph ph codeph">nullFill!</code>函数对文本文件中的空值进行填充。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>db=database(dbPath,VALUE,2018.01.02..2018.01.30)
tb=db.createPartitionedTable(tb,`tb1,`date)
tmpTB=loadTextEx(dbHandle=db,tableName=`tb1,partitionColumns=`date,filename=dataFilePath,transform=nullFill!{,0});</code></pre></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title17" id="5-导入数组向量类型的数据"><h2 class="- topic/title title topictitle2" id="ariaid-title17">5. 导入数组向量类型的数据</h2><div class="- topic/body body"><p class="- topic/p p">DolphinDB 中的数组向量 (array vector) 是一种特殊的向量，用于存储可变长度的二维数组。数组向量应用于数据表时，可将数据类型相同且含义相近的多列存为一列，例如股票的多档报价数据存为一个数组向量。</p><p class="- topic/p p">数据表中使用数组向量具有以下优势：</p><ol class="- topic/ol ol"><li class="- topic/li li">显著简化某些常用的查询和计算</li><li class="- topic/li li">若不同列中含有大量重复数据，使用数组向量存储可提高数据压缩比，提升查询速度</li></ol><p class="- topic/p p">DolphinDB 提供3种方法，以导入数组向量类型的数据：</p><ol class="- topic/ol ol"><li class="- topic/li li">直接导入符合条件的文本文件</li><li class="- topic/li li">将文本文件导入内存后，将多列合并成一个数组向量，再导入分布式数据库</li><li class="- topic/li li">使用 loadTextEx 函数时指定 transform 参数，将文本文件导入分布式数据库</li></ol></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title18" id="51-直接导入符合条件的文本文件-2004及以上版本"><h3 class="- topic/title title topictitle3" id="ariaid-title18">5.1. 直接导入符合条件的文本文件 （2.00.4及以上版本）</h3><div class="- topic/body body"><p class="- topic/p p">在导入文本文件时，暂不支持将多列数据合并导入 DolphinDB 数据表的一列（数组向量类型）。如需将数据导入为数组向量，需经过以下两步：</p><ol class="- topic/ol ol"><li class="- topic/li li">将文本文件的多列数据合并存储到一列中，并通过标识符进行分隔。</li><li class="- topic/li li">导入数据时，通过 loadText (ploadText) 与 loadTextEx 的 arrayDelimiter 参数指定分隔符，系统会将包含指定分隔符的列解析为数组向量。</li></ol><p class="- topic/p p">构建包含数组向量的表，并将其存入1个 csv 文件</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>bid = array(DOUBLE[], 0, 20).append!([1.4799 1.479 1.4787, 1.4796 1.479 1.4784, 1.4791 1.479 1.4784])
ask = array(DOUBLE[], 0, 20).append!([1.4821 1.4825 1.4828, 1.4818 1.482 1.4821, 1.4814 1.4818 1.482])
TradeDate = 2022.01.01 + 1..3
SecurityID = rand(`APPL`AMZN`IBM, 3)
t = table(SecurityID as `sid, TradeDate as `date, bid as `bid, ask as `ask)
saveText(t,filename="/home/data/t.csv",delimiter=',',append=true)</code></pre><p class="- topic/p p">导入数据前需要修改 schema 中对应列的类型为数组向量。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>path = "/home/data/t.csv"
schema=extractTextSchema(path);
update schema set type = "DOUBLE[]" where name="bid" or name ="ask"</code></pre><p class="- topic/p p">使用 loadText (ploadText) 与 loadTextEx 导入数据时，通过参数 arrayDelimiter 指定分隔符（本例中的分隔符为“,"）。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>//用 loadText 将文本文件导入内存表
t = loadText(path, schema=schema, arrayDelimiter=",")

//用 loadTextEx 将文本文件导入分布式数据库
//创建 TSDB 引擎下的数据库表
db = database(directory="dfs://testTSDB", partitionType=VALUE, partitionScheme=`APPL`AMZN`IBM, engine="TSDB" )
name = `sid`date`bid`ask
type = ["SYMBOL","DATE","DOUBLE[]","DOUBLE[]"]
tbTemp = table(1:0, name, type)
db.createPartitionedTable(tbTemp, `pt, `sid, sortColumns=`date)
pt = loadTextEx(dbHandle=db, tableName=`pt, partitionColumns=`sid, filename=path, schema=schema, arrayDelimiter=",")</code></pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title19" id="52-文本文件导入内存后将多列合并成一列数组向量再导入分布式数据库"><h3 class="- topic/title title topictitle3" id="ariaid-title19">5.2. 文本文件导入内存后，将多列合并成一列数组向量，再导入分布式数据库</h3><div class="- topic/body body"><p class="- topic/p p">如果不能方便地对文本文件进行修改，也可以先将数据导入内存后，将多列数据合并成一个数组向量，再导入分布式数据库。<br/>下例展示如何将国内A股行情快照数据的买10档或卖10档作为1个 vector 存入单个 cell 中。</p><p class="- topic/p p">建库建表及模拟数据生成语句参见<a class="- topic/xref xref" href="script/csvImportDemo/tsdbDatabaseTableGenerationAndDataSimulationForWritingArrayVector.dos">建库建表及模拟数据生成脚本</a>。</p><p class="- topic/p p">在本例中，我们首先使用 loadText 函数将模拟数据导入内存，再使用 fixedLengthArrayVector 函数将买10档和卖10档的各项数据分别整合为1列，最后将处理后的数据写入数据库。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>snapFile="/home/data/snapshot.csv"
dbpath="dfs://LEVEL2_Snapshot_ArrayVector"
tbName="Snap"

schemas=extractTextSchema(snapFile)
update schemas set type = `SYMBOL where name = `InstrumentStatus

//使用 loadText 加载文本，耗时约1分30秒
rawTb = loadText(snapFile,schema=schemas)
//合并10档数据为1列，耗时约15秒
arrayVectorTb = select SecurityID,TradeTime,PreClosePx,OpenPx,HighPx,LowPx,LastPx,TotalVolumeTrade,TotalValueTrade,InstrumentStatus,fixedLengthArrayVector(BidPrice0,BidPrice1,BidPrice2,BidPrice3,BidPrice4,BidPrice5,BidPrice6,BidPrice7,BidPrice8,BidPrice9) as BidPrice,fixedLengthArrayVector(BidOrderQty0,BidOrderQty1,BidOrderQty2,BidOrderQty3,BidOrderQty4,BidOrderQty5,BidOrderQty6,BidOrderQty7,BidOrderQty8,BidOrderQty9) as BidOrderQty,fixedLengthArrayVector(BidOrders0,BidOrders1,BidOrders2,BidOrders3,BidOrders4,BidOrders5,BidOrders6,BidOrders7,BidOrders8,BidOrders9) as BidOrders ,fixedLengthArrayVector(OfferPrice0,OfferPrice1,OfferPrice2,OfferPrice3,OfferPrice4,OfferPrice5,OfferPrice6,OfferPrice7,OfferPrice8,OfferPrice9) as OfferPrice,fixedLengthArrayVector(OfferOrderQty0,OfferOrderQty1,OfferOrderQty2,OfferOrderQty3,OfferOrderQty4,OfferOrderQty5,OfferOrderQty6,OfferOrderQty7,OfferOrderQty8,OfferOrderQty9) as OfferOrderQty,fixedLengthArrayVector(OfferOrders0,OfferOrders1,OfferOrders2,OfferOrders3,OfferOrders4,OfferOrders5,OfferOrders6,OfferOrders7,OfferOrders8,OfferOrders9) as OfferOrders,NumTrades,IOPV,TotalBidQty,TotalOfferQty,WeightedAvgBidPx,WeightedAvgOfferPx,TotalBidNumber,TotalOfferNumber,BidTradeMaxDuration,OfferTradeMaxDuration,NumBidOrders,NumOfferOrders,WithdrawBuyNumber,WithdrawBuyAmount,WithdrawBuyMoney,WithdrawSellNumber,WithdrawSellAmount,WithdrawSellMoney,ETFBuyNumber,ETFBuyAmount,ETFBuyMoney,ETFSellNumber,ETFSellAmount,ETFSellMoney from rawTb
//载入数据库，耗时约60秒
loadTable(dbpath, tbName).append!(arrayVectorTb)</code></pre><p class="- topic/p p">由上述代码可以看出，数据导入到分布式数据表，共耗时约2分45秒。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title20" id="53-使用-loadtextex-函数时指定-transform-参数将文本文件导入分布式数据库"><h3 class="- topic/title title topictitle3" id="ariaid-title20">5.3. 使用 loadTextEx 函数时指定 transform 参数，将文本文件导入分布式数据库</h3><div class="- topic/body body"><p class="- topic/p p">使用上文中提到的通过为 loadTextEx 指定 transform 参数的方式，一步到位地将数据导入分布式数据库。</p><p class="- topic/p p">自定义函数<code class="+ topic/ph pr-d/codeph ph codeph">toArrayVector</code>，将10档数据合并为1列，重新排序列，并返回处理后的数据表。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def toArrayVector(mutable tmp){
  //将10档数据合并为1列，添加到tmp表中。也可以使用update!方法添加。
	tmp[`BidPrice]=fixedLengthArrayVector(tmp.BidPrice0,tmp.BidPrice1,tmp.BidPrice2,tmp.BidPrice3,tmp.BidPrice4,tmp.BidPrice5,tmp.BidPrice6,tmp.BidPrice7,tmp.BidPrice8,tmp.BidPrice9)
	tmp[`BidOrderQty]=fixedLengthArrayVector(tmp.BidOrderQty0,tmp.BidOrderQty1,tmp.BidOrderQty2,tmp.BidOrderQty3,tmp.BidOrderQty4,tmp.BidOrderQty5,tmp.BidOrderQty6,tmp.BidOrderQty7,tmp.BidOrderQty8,tmp.BidOrderQty9)
	tmp[`BidOrders]=fixedLengthArrayVector(tmp.BidOrders0,tmp.BidOrders1,tmp.BidOrders2,tmp.BidOrders3,tmp.BidOrders4,tmp.BidOrders5,tmp.BidOrders6,tmp.BidOrders7,tmp.BidOrders8,tmp.BidOrders9)
	tmp[`OfferPrice]=fixedLengthArrayVector(tmp.OfferPrice0,tmp.OfferPrice1,tmp.OfferPrice2,tmp.OfferPrice3,tmp.OfferPrice4,tmp.OfferPrice5,tmp.OfferPrice6,tmp.OfferPrice7,tmp.OfferPrice8,tmp.OfferPrice9)
	tmp[`OfferOrderQty]=fixedLengthArrayVector(tmp.OfferOrderQty0,tmp.OfferOrderQty1,tmp.OfferOrderQty2,tmp.OfferOrderQty3,tmp.OfferOrderQty4,tmp.OfferOrderQty5,tmp.OfferOrderQty6,tmp.OfferOrderQty7,tmp.OfferOrderQty8,tmp.OfferOrderQty9)
	tmp[`OfferOrders]=fixedLengthArrayVector(tmp.OfferOrders0,tmp.OfferOrders1,tmp.OfferOrders2,tmp.OfferOrders3,tmp.OfferOrders4,tmp.OfferOrders5,tmp.OfferOrders6,tmp.OfferOrders7,tmp.OfferOrders8,tmp.OfferOrders9)
  //删除合并前的列
	tmp.dropColumns!(`BidPrice0`BidPrice1`BidPrice2`BidPrice3`BidPrice4`BidPrice5`BidPrice6`BidPrice7`BidPrice8`BidPrice9`BidOrderQty0`BidOrderQty1`BidOrderQty2`BidOrderQty3`BidOrderQty4`BidOrderQty5`BidOrderQty6`BidOrderQty7`BidOrderQty8`BidOrderQty9`BidOrders0`BidOrders1`BidOrders2`BidOrders3`BidOrders4`BidOrders5`BidOrders6`BidOrders7`BidOrders8`BidOrders9`OfferPrice0`OfferPrice1`OfferPrice2`OfferPrice3`OfferPrice4`OfferPrice5`OfferPrice6`OfferPrice7`OfferPrice8`OfferPrice9`OfferOrderQty0`OfferOrderQty1`OfferOrderQty2`OfferOrderQty3`OfferOrderQty4`OfferOrderQty5`OfferOrderQty6`OfferOrderQty7`OfferOrderQty8`OfferOrderQty9`OfferOrders0`OfferOrders1`OfferOrders2`OfferOrders3`OfferOrders4`OfferOrders5`OfferOrders6`OfferOrders7`OfferOrders8`OfferOrders9)
  //对列重新排序
	tmp.reorderColumns!(`SecurityID`TradeTime`PreClosePx`OpenPx`HighPx`LowPx`LastPx`TotalVolumeTrade`TotalValueTrade`InstrumentStatus`BidPrice`BidOrderQty`BidOrders`OfferPrice`OfferOrderQty`OfferOrders`NumTrades`IOPV`TotalBidQty`TotalOfferQty`WeightedAvgBidPx`WeightedAvgOfferPx`TotalBidNumber`TotalOfferNumber`BidTradeMaxDuration`OfferTradeMaxDuration`NumBidOrders`NumOfferOrders`WithdrawBuyNumber`WithdrawBuyAmount`WithdrawBuyMoney`WithdrawSellNumber`WithdrawSellAmount`WithdrawSellMoney`ETFBuyNumber`ETFBuyAmount`ETFBuyMoney`ETFSellNumber`ETFSellAmount`ETFSellMoney)
	return tmp 
}</code></pre><p class="- topic/p p">调用 <code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code> 函数，并且指定 transform 参数为 <code class="+ topic/ph pr-d/codeph ph codeph">toArrayVector</code> 函数，系统会对文本文件中的数据执行<code class="+ topic/ph pr-d/codeph ph codeph">toArrayVector</code> 函数，并将结果保存到数据库中。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>db=database(dbpath)
db.loadTextEx(tbName, `Tradetime`SecurityID, snapFile, schema=schemas, transform=toArrayVector)</code></pre><p class="- topic/p p">数据导入分布式表耗时约1分40秒，比5.2章节的方法快了65秒。</p></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title21" id="6-使用map-reduce自定义数据导入"><h2 class="- topic/title title topictitle2" id="ariaid-title21">6. 使用Map-Reduce自定义数据导入</h2><div class="- topic/body body"><p class="- topic/p p">DolphinDB支持使用Map-Reduce自定义数据导入，将数据按行进行划分，并将划分后的数据通过Map-Reduce导入到DolphinDB。</p><p class="- topic/p p">可使用<code class="+ topic/ph pr-d/codeph ph codeph">textChunkDS</code>函数将文件划分为多个小文件数据源，再通过<code class="+ topic/ph pr-d/codeph ph codeph">mr</code>函数写入到数据库中。在调用<code class="+ topic/ph pr-d/codeph ph codeph">mr</code>将数据存入数据库前，用户还可进行灵活的数据处理，从而实现更复杂的导入需求。</p></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title22" id="61-将文件中的股票和期货数据存储到两个不同的数据表"><h3 class="- topic/title title topictitle3" id="ariaid-title22">6.1. 将文件中的股票和期货数据存储到两个不同的数据表</h3><div class="- topic/body body"><p class="- topic/p p">在DolphinDB中执行以下脚本，生成一个大小约为1.6GB的数据文件，其中包括股票数据和期货数据。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>n=10000000
dataFilePath="/home/data/chunkText.csv"
trades=table(rand(`stock`futures,n) as type, rand(`IBM`MSFT`GM`C`FB`GOOG`V`F`XOM`AMZN`TSLA`PG`S,n) as sym,take(2000.01.01..2000.06.30,n) as date,10.0+rand(2.0,n) as price1,100.0+rand(20.0,n) as price2,1000.0+rand(200.0,n) as price3,10000.0+rand(2000.0,n) as price4,10000.0+rand(3000.0,n) as price5,10000.0+rand(4000.0,n) as price6,rand(10,n) as qty1,rand(100,n) as qty2,rand(1000,n) as qty3,rand(10000,n) as qty4,rand(10000,n) as qty5,rand(10000,n) as qty6)
trades.saveText(dataFilePath);</code></pre><p class="- topic/p p">分别创建用于存放股票数据和期货数据的分布式数据库和表:</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>login(`admin,`123456)
dbPath1="dfs://stocksDatabase"
dbPath2="dfs://futuresDatabase"
db1=database(dbPath1,VALUE,`IBM`MSFT`GM`C`FB`GOOG`V`F`XOM`AMZN`TSLA`PG`S)
db2=database(dbPath2,VALUE,2000.01.01..2000.06.30)
tb1=db1.createPartitionedTable(trades,`stock,`sym)
tb2=db2.createPartitionedTable(trades,`futures,`date);</code></pre><p class="- topic/p p">定义以下函数，用于划分数据，并将数据写入到不同的数据库。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>def divideImport(tb, mutable stockTB, mutable futuresTB)
{
	tdata1=select * from tb where type="stock"
	tdata2=select * from tb where type="futures"
	append!(stockTB, tdata1)
	append!(futuresTB, tdata2)
}</code></pre><p class="- topic/p p">再通过<code class="+ topic/ph pr-d/codeph ph codeph">textChunkDS</code>函数划分文本文件，以300MB为单位进行划分，文件被划分成了6部分。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>ds=textChunkDS(dataFilePath,300)
ds;

(DataSource&lt;readTableFromFileSegment, DataSource&lt;readTableFromFileSegment, DataSource&lt;readTableFromFileSegment, DataSource&lt;readTableFromFileSegment)</code></pre><p class="- topic/p p">调用<code class="+ topic/ph pr-d/codeph ph codeph">mr</code>函数，指定<code class="+ topic/ph pr-d/codeph ph codeph">textChunkDS</code>函数结果为数据源，将文件导入到数据库中。由于map函数（由mapFunc参数指定）只接受一个表作为参数，这里我们使用部分应用将多参数函数转换为一个参数的函数。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>mr(ds=ds, mapFunc=divideImport{,tb1,tb2}, parallel=false);</code></pre><p class="- topic/p p">请注意，这里不同的小文件数据源可能包含相同分区的数据。DolphinDB不允许多个线程同时对相同分区进行写入，因此要将<code class="+ topic/ph pr-d/codeph ph codeph">mr</code>函数的parallel参数设置为false，否则会抛出异常。</p><p class="- topic/p p">查看2个数据库中表的前5行，股票数据库中均为股票数据，期货数据库中均为期货数据。</p><p class="- topic/p p">stock表：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select top 5 * from loadTable(dbPath1, `stock);

type  sym  date       price1    price2     price3      price4       price5       price6       qty1 qty2 qty3 qty4 qty5 qty6
----- ---- ---------- --------- ---------- ----------- ------------ ------------ ------------ ---- ---- ---- ---- ---- ----
stock AMZN 2000.02.14 11.224234 112.26763  1160.926836 11661.418403 11902.403305 11636.093467 4    53   450  2072 9116 12
stock AMZN 2000.03.29 10.119057 111.132165 1031.171855 10655.048121 12682.656303 11182.317321 6    21   651  2078 7971 6207
stock AMZN 2000.06.16 11.61637  101.943971 1019.122963 10768.996906 11091.395164 11239.242307 0    91   857  3129 3829 811
stock AMZN 2000.02.20 11.69517  114.607763 1005.724332 10548.273754 12548.185724 12750.524002 1    39   270  4216 8607 6578
stock AMZN 2000.02.23 11.534805 106.040664 1085.913295 11461.783565 12496.932604 12995.461331 4    35   488  4042 6500 4826</code></pre><p class="- topic/p p">futures表：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select top 5 * from loadTable(dbPath2, `futures);

type    sym  date       price1    price2     price3      price4       price5       price6       qty1 qty2 qty3 qty4 qty5 ...
------- ---- ---------- --------- ---------- ----------- ------------ ------------ ------------ ---- ---- ---- ---- ---- ---
futures MSFT 2000.01.01 11.894442 106.494131 1000.600933 10927.639217 10648.298313 11680.875797 9    10   241  524  8325 ...
futures S    2000.01.01 10.13728  115.907379 1140.10161  11222.057315 10909.352983 13535.931446 3    69   461  4560 2583 ...
futures GM   2000.01.01 10.339581 112.602729 1097.198543 10938.208083 10761.688725 11121.888288 1    1    714  6701 9203 ...
futures IBM  2000.01.01 10.45422  112.229537 1087.366764 10356.28124  11829.206165 11724.680443 0    47   741  7794 5529 ...
futures TSLA 2000.01.01 11.901426 106.127109 1144.022732 10465.529256 12831.721586 10621.111858 4    43   136  9858 8487 ...</code></pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title23" id="62-快速加载大文件首尾部分数据"><h3 class="- topic/title title topictitle3" id="ariaid-title23">6.2. 快速加载大文件首尾部分数据</h3><div class="- topic/body body"><p class="- topic/p p">可使用<code class="+ topic/ph pr-d/codeph ph codeph">textChunkDS</code>将大文件划分成多个小的数据源(chunk)，然后加载首尾两个数据源。在DolphinDB中执行以下脚本生成数据文件：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>n=10000000
dataFilePath="/home/data/chunkText.csv"
trades=table(rand(`IBM`MSFT`GM`C`FB`GOOG`V`F`XOM`AMZN`TSLA`PG`S,n) as sym,sort(take(2000.01.01..2000.06.30,n)) as date,10.0+rand(2.0,n) as price1,100.0+rand(20.0,n) as price2,1000.0+rand(200.0,n) as price3,10000.0+rand(2000.0,n) as price4,10000.0+rand(3000.0,n) as price5,10000.0+rand(4000.0,n) as price6,rand(10,n) as qty1,rand(100,n) as qty2,rand(1000,n) as qty3,rand(10000,n) as qty4, rand(10000,n) as qty5, rand(1000,n) as qty6)
trades.saveText(dataFilePath);</code></pre><p class="- topic/p p">再通过<code class="+ topic/ph pr-d/codeph ph codeph">textChunkDS</code>函数划分文本文件，以10MB为单位进行划分。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>ds=textChunkDS(dataFilePath, 10);</code></pre><p class="- topic/p p">调用<code class="+ topic/ph pr-d/codeph ph codeph">mr</code>函数，加载首尾两个chunk的数据。因为这两个chunk的数据非常小，加载速度非常快。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>head_tail_tb = mr(ds=[ds.head(), ds.tail()], mapFunc=x-&gt;x, finalFunc=unionAll{,false});</code></pre><p class="- topic/p p">查看head_tail_tb表中的记录数：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select count(*) from head_tail_tb;

count
------
192262</code></pre></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title24" id="7-其它注意事项"><h2 class="- topic/title title topictitle2" id="ariaid-title24">7. 其它注意事项</h2><div class="- topic/body body"></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title25" id="71-不同编码的数据的处理"><h3 class="- topic/title title topictitle3" id="ariaid-title25">7.1. 不同编码的数据的处理</h3><div class="- topic/body body"><p class="- topic/p p">由于DolphinDB的字符串采用UTF-8编码，若加载的文件不是UTF-8编码，需在导入后进行转化。DolphinDB提供了<code class="+ topic/ph pr-d/codeph ph codeph">convertEncode</code>、<code class="+ topic/ph pr-d/codeph ph codeph">fromUTF8</code>和<code class="+ topic/ph pr-d/codeph ph codeph">toUTF8</code>函数，用于导入数据后对字符串编码进行转换。</p><p class="- topic/p p">例如，使用<code class="+ topic/ph pr-d/codeph ph codeph">convertEncode</code>函数转换表tmpTB中的exchange列的编码：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dataFilePath="/home/data/candle_201801.csv"
tmpTB=loadText(filename=dataFilePath, skipRows=0)
tmpTB.replaceColumn!(`exchange, convertEncode(tmpTB.exchange,"gbk","utf-8"));</code></pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title26" id="72-数值类型的解析"><h3 class="- topic/title title topictitle3" id="ariaid-title26">7.2. 数值类型的解析</h3><div class="- topic/body body"><p class="- topic/p p">本教程介绍了DolphinDB在导入数据时的数据类型自动解析机制，本节讲解数值类型（包括CHAR，SHORT，INT，LONG，FLOAT和DOUBLE）数据的解析。系统能够识别以下几种形式的数值数据：</p><ul class="- topic/ul ul"><li class="- topic/li li">数字表示的数值，例如：123</li><li class="- topic/li li">含有千位分隔符的数值，例如：100,000</li><li class="- topic/li li">含有小数点的数值，即浮点数，例如：1.231</li><li class="- topic/li li">科学计数法表示的数值，例如：1.23E5</li></ul><p class="- topic/p p">若指定数据类型为数值类型，DolphinDB在导入时会自动忽略数字前后的字母及其他符号，如果没有出现任何数字，则解析为NULL值。下面结合例子具体说明。</p><p class="- topic/p p">首先，执行以下脚本，创建一个文本文件。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dataFilePath="/home/data/testSym.csv"
prices1=["2131","$2,131", "N/A"]
prices2=["213.1","$213.1", "N/A"]
totals=["2.658E7","-2.658e7","2.658e-7"]
tt=table(1..3 as id, prices1 as price1, prices2 as price2, totals as total)
saveText(tt,dataFilePath);</code></pre><p class="- topic/p p">创建的文本文件中，price1和price2列中既有数字，又有字符。若导入数据时不指定schema参数，系统会将这两列均识别为SYMBOL类型：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>tmpTB=loadText(dataFilePath)
tmpTB;

id price1 price2 total
-- ------ ------ --------
1  2131   213.1  2.658E7
2  $2,131 $213.1 -2.658E7
3  N/A    N/A    2.658E-7

tmpTB.schema().colDefs;

name   typeString typeInt comment
------ ---------- ------- -------
id     INT        4
price1 SYMBOL     17
price2 SYMBOL     17
total  DOUBLE     16</code></pre><p class="- topic/p p">若指定price1列为INT类型，指定price2列为DOUBLE类型，导入时系统会忽略数字前后的字母及其他符号。如果没有出现任何数字，则解析为NULL值。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>schemaTB=table(`id`price1`price2`total as name, `INT`INT`DOUBLE`DOUBLE as type) 
tmpTB=loadText(dataFilePath,,schemaTB)
tmpTB;

id price1 price2 total
-- ------ ------ --------
1  2131   213.1  2.658E7
2  2131   213.1  -2.658E7
3                2.658E-7</code></pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title27" id="73-自动去除双引号"><h3 class="- topic/title title topictitle3" id="ariaid-title27">7.3. 自动去除双引号</h3><div class="- topic/body body"><p class="- topic/p p">在CSV文件中，有时候会用双引号来处理数值中含有的特殊字符（譬如千位分隔符）的字段。DolphinDB处理这样的数据时，会自动去除文本外的双引号。下面结合例子具体说明。</p><p class="- topic/p p">在下例所用的数据文件中，num列为使用千位分节法表示的数值。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>dataFilePath="/home/data/test.csv"
tt=table(1..3 as id,  ["\"500\"","\"3,500\"","\"9,000,000\""] as num)
saveText(tt,dataFilePath);</code></pre><p class="- topic/p p">导入数据并查看表内数据，DolphinDB自动脱去了文本外的双引号。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>tmpTB=loadText(dataFilePath)
tmpTB;

id num
-- -------
1  500
2  3500
3  9000000</code></pre></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title28" id="8-附录"><h2 class="- topic/title title topictitle2" id="ariaid-title28">8. 附录</h2><div class="- topic/body body"><p class="- topic/p p">--</p><p class="- topic/p p">本教程的例子中使用的数据文件： <a class="- topic/xref xref" href="data/candle_201801.csv">candle_201801.csv</a>。</p></div></article></article></main></div>
                        
                        
                        
                        
                        
                        
                    </div>
                    
                        <nav role="navigation" id="wh_topic_toc" aria-label="On this page" class="col-lg-2 d-none d-lg-block navbar d-print-none"> 
                            <div id="wh_topic_toc_content">
		                        
	                            <div class=" wh_topic_toc "><div class="wh_topic_label">在本页上</div><ul><li class="topic-item"><a href="#1-%E8%87%AA%E5%8A%A8%E8%AF%86%E5%88%AB%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F" data-tocid="1-自动识别数据格式">1. 自动识别数据格式</a></li><li class="topic-item"><a href="#2-%E6%8C%87%E5%AE%9A%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E6%A0%BC%E5%BC%8F" data-tocid="2-指定数据导入格式">2. 指定数据导入格式</a><ul><li class="topic-item"><a href="#21-%E6%8F%90%E5%8F%96%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E7%9A%84schema" data-tocid="21-提取文本文件的schema">2.1. 提取文本文件的schema</a></li><li class="topic-item"><a href="#22-%E6%8C%87%E5%AE%9A%E5%AD%97%E6%AE%B5%E5%90%8D%E7%A7%B0%E5%92%8C%E7%B1%BB%E5%9E%8B" data-tocid="22-指定字段名称和类型">2.2. 指定字段名称和类型</a></li><li class="topic-item"><a href="#23-%E6%8C%87%E5%AE%9A%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%A0%BC%E5%BC%8F" data-tocid="23-指定日期和时间类型的格式">2.3. 指定日期和时间类型的格式</a></li><li class="topic-item"><a href="#24-%E5%AF%BC%E5%85%A5%E6%8C%87%E5%AE%9A%E5%88%97" data-tocid="24-导入指定列">2.4. 导入指定列</a></li><li class="topic-item"><a href="#25-%E8%B7%B3%E8%BF%87%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9A%84%E5%89%8D%E8%8B%A5%E5%B9%B2%E8%A1%8C" data-tocid="25-跳过文本数据的前若干行">2.5. 跳过文本数据的前若干行</a></li></ul></li><li class="topic-item"><a href="#3-%E5%B9%B6%E8%A1%8C%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE" data-tocid="3-并行导入数据">3. 并行导入数据</a><ul><li class="topic-item"><a href="#31-%E5%8D%95%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%BD%BD%E5%85%A5%E5%86%85%E5%AD%98" data-tocid="31-单个文件多线程载入内存">3.1. 单个文件多线程载入内存</a></li><li class="topic-item"><a href="#32-%E5%A4%9A%E6%96%87%E4%BB%B6%E5%B9%B6%E8%A1%8C%E5%AF%BC%E5%85%A5" data-tocid="32-多文件并行导入">3.2. 多文件并行导入</a></li></ul></li><li class="topic-item"><a href="#4-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%BA%93%E5%89%8D%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86" data-tocid="4-导入数据库前的预处理">4. 导入数据库前的预处理</a><ul><li class="topic-item"><a href="#41-%E6%8C%87%E5%AE%9A%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B" data-tocid="41-指定日期和时间数据的数据类型">4.1. 指定日期和时间数据的数据类型</a><ul><li class="topic-item"><a href="#411-%E5%B0%86%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B%E8%A1%A8%E7%A4%BA%E7%9A%84%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E8%BD%AC%E5%8C%96%E4%B8%BA%E6%8C%87%E5%AE%9A%E7%B1%BB%E5%9E%8B" data-tocid="411-将数值类型表示的日期和时间转化为指定类型">4.1.1. 将数值类型表示的日期和时间转化为指定类型</a></li><li class="topic-item"><a href="#412-%E6%97%A5%E6%9C%9F%E6%88%96%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B9%8B%E9%97%B4%E8%BD%AC%E6%8D%A2" data-tocid="412-日期或时间数据类型之间转换">4.1.2. 日期或时间数据类型之间转换</a></li></ul></li><li class="topic-item"><a href="#42-%E5%A1%AB%E5%85%85%E7%A9%BA%E5%80%BC" data-tocid="42-填充空值">4.2. 填充空值</a></li></ul></li><li class="topic-item"><a href="#5-%E5%AF%BC%E5%85%A5%E6%95%B0%E7%BB%84%E5%90%91%E9%87%8F%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%95%B0%E6%8D%AE" data-tocid="5-导入数组向量类型的数据">5. 导入数组向量类型的数据</a><ul><li class="topic-item"><a href="#51-%E7%9B%B4%E6%8E%A5%E5%AF%BC%E5%85%A5%E7%AC%A6%E5%90%88%E6%9D%A1%E4%BB%B6%E7%9A%84%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6-2004%E5%8F%8A%E4%BB%A5%E4%B8%8A%E7%89%88%E6%9C%AC" data-tocid="51-直接导入符合条件的文本文件-2004及以上版本">5.1. 直接导入符合条件的文本文件 （2.00.4及以上版本）</a></li><li class="topic-item"><a href="#52-%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%AF%BC%E5%85%A5%E5%86%85%E5%AD%98%E5%90%8E%E5%B0%86%E5%A4%9A%E5%88%97%E5%90%88%E5%B9%B6%E6%88%90%E4%B8%80%E5%88%97%E6%95%B0%E7%BB%84%E5%90%91%E9%87%8F%E5%86%8D%E5%AF%BC%E5%85%A5%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93" data-tocid="52-文本文件导入内存后将多列合并成一列数组向量再导入分布式数据库">5.2. 文本文件导入内存后，将多列合并成一列数组向量，再导入分布式数据库</a></li><li class="topic-item"><a href="#53-%E4%BD%BF%E7%94%A8-loadtextex-%E5%87%BD%E6%95%B0%E6%97%B6%E6%8C%87%E5%AE%9A-transform-%E5%8F%82%E6%95%B0%E5%B0%86%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%AF%BC%E5%85%A5%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93" data-tocid="53-使用-loadtextex-函数时指定-transform-参数将文本文件导入分布式数据库">5.3. 使用 loadTextEx 函数时指定 transform 参数，将文本文件导入分布式数据库</a></li></ul></li><li class="topic-item"><a href="#6-%E4%BD%BF%E7%94%A8map-reduce%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5" data-tocid="6-使用map-reduce自定义数据导入">6. 使用Map-Reduce自定义数据导入</a><ul><li class="topic-item"><a href="#61-%E5%B0%86%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E8%82%A1%E7%A5%A8%E5%92%8C%E6%9C%9F%E8%B4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E5%88%B0%E4%B8%A4%E4%B8%AA%E4%B8%8D%E5%90%8C%E7%9A%84%E6%95%B0%E6%8D%AE%E8%A1%A8" data-tocid="61-将文件中的股票和期货数据存储到两个不同的数据表">6.1. 将文件中的股票和期货数据存储到两个不同的数据表</a></li><li class="topic-item"><a href="#62-%E5%BF%AB%E9%80%9F%E5%8A%A0%E8%BD%BD%E5%A4%A7%E6%96%87%E4%BB%B6%E9%A6%96%E5%B0%BE%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE" data-tocid="62-快速加载大文件首尾部分数据">6.2. 快速加载大文件首尾部分数据</a></li></ul></li><li class="topic-item"><a href="#7-%E5%85%B6%E5%AE%83%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9" data-tocid="7-其它注意事项">7. 其它注意事项</a><ul><li class="topic-item"><a href="#71-%E4%B8%8D%E5%90%8C%E7%BC%96%E7%A0%81%E7%9A%84%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86" data-tocid="71-不同编码的数据的处理">7.1. 不同编码的数据的处理</a></li><li class="topic-item"><a href="#72-%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B%E7%9A%84%E8%A7%A3%E6%9E%90" data-tocid="72-数值类型的解析">7.2. 数值类型的解析</a></li><li class="topic-item"><a href="#73-%E8%87%AA%E5%8A%A8%E5%8E%BB%E9%99%A4%E5%8F%8C%E5%BC%95%E5%8F%B7" data-tocid="73-自动去除双引号">7.3. 自动去除双引号</a></li></ul></li><li class="topic-item"><a href="#8-%E9%99%84%E5%BD%95" data-tocid="8-附录">8. 附录</a></li></ul></div>
	                        	
                        	</div>
                        </nav>
                    
                </div>
            </div>
            
            
            
        </div> 
        <footer class="navbar navbar-default wh_footer">
  <div class=" footer-container mx-auto ">
<title>Copyright</title><p><b> ©2025 浙江智臾科技有限公司 浙ICP备18048711号-3</b></p>
  </div>
</footer>
        
        <div id="go2top" class="d-print-none">
            <span class="oxy-icon oxy-icon-up"></span>
        </div>
        
        <div id="modal_img_large" class="modal">
            <span class="close oxy-icon oxy-icon-remove"></span>
            <div id="modal_img_container"></div>
            <div id="caption"></div>
        </div>
        
        
        
    </body>
</html>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh" lang="zh" data-whc_version="26.0">
    <head><link rel="shortcut icon" href="../favicon.ico"/><link rel="icon" href="../favicon.ico"/><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="description" content="对数据库进行分区可以显著降低系统响应延迟，提高数据吞吐量。具体来说，分区有以下主要好处。 分区使得大型表更易于管理。对数据子集的维护操作也更加高效，因为这些操作只针对需要的数据而不是整个表。一个好的分区策略通过只读取查询所需的相关数据来减少要扫描的数据量。如果分区机制设计不合理，对数据库的查询、计算以及其它操作都可能受到磁盘访问 I/O 这个瓶颈的限制。 ..."/><meta name="DC.rights.owner" content="(C) 版权 2025"/><meta name="copyright" content="(C) 版权 2025"/><meta name="generator" content="DITA-OT"/><meta name="DC.type" content="topic"/><meta name="DC.coverage" content=""/><meta name="DC.relation" content="../tutorials/about_tutorials.html"/><meta name="prodname" content="DolphinDB"/><meta name="brand" content="DolphinDB"/><meta name="DC.creator" content="DolphinDB"/><meta name="DC.publisher" content="DDB N/A DDB 200"/><meta name="DC.format" content="HTML5"/><meta name="DC.identifier" content="分区数据库设计和操作"/><title>分区数据库设计和操作</title><!--  Generated with Oxygen version 26.0, build number 2024012323.  --><meta name="wh-path2root" content="../"/><meta name="wh-toc-id" content="&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;&lt;?workdir /tmp/temp20250305183303418/tutorials?&gt;&lt;?workdir-uri file:/tmp/temp20250305183303418/tutorials/?&gt;&lt;?path2project ../?&gt;&lt;?path2project-uri ../?&gt;&lt;?path2rootmap-uri ../?&gt;&lt;topic xmlns:dita-ot=&#34;http://dita-ot.sourceforge.net/ns/201007/dita-ot&#34; xmlns:ditaarch=&#34;http://dita.oasis-open.org/architecture/2005/&#34; class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;分区数据库设计和操作&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:1;1:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:1;1:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;分区数据库设计和操作&lt;/title&gt;&lt;prolog class=&#34;- topic/prolog &#34;&gt;&lt;author class=&#34;- topic/author &#34; xtrc=&#34;author:1;12:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DolphinDB&lt;/author&gt;&lt;publisherinformation class=&#34;- topic/publisher bookmap/publisherinformation &#34; xtrc=&#34;publisherinformation:1;14:31&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt; &lt;person class=&#34;- topic/data bookmap/person &#34; xtrc=&#34;person:1;15:21&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DDB&lt;/person&gt; &lt;printlocation class=&#34;- topic/data bookmap/printlocation &#34; xtrc=&#34;printlocation:1;16:28&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;N/A&lt;/printlocation&gt; &lt;published class=&#34;- topic/data bookmap/published &#34; xtrc=&#34;published:1;17:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt; &lt;person class=&#34;- topic/data bookmap/person &#34; xtrc=&#34;person:2;18:25&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DDB&lt;/person&gt; &lt;publishtype class=&#34;- topic/data bookmap/publishtype &#34; value=&#34;HTML&#34; xtrc=&#34;publishtype:1;19:44&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;revisionid class=&#34;- topic/ph bookmap/revisionid &#34; xtrc=&#34;revisionid:1;20:29&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;200&lt;/revisionid&gt; &lt;summary class=&#34;- topic/ph bookmap/summary &#34; xtrc=&#34;summary:1;22:27&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;data class=&#34;- topic/data &#34; xtrc=&#34;data:1;23:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;/published&gt; &lt;data class=&#34;- topic/data &#34; xtrc=&#34;data:2;25:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt; &lt;/publisherinformation&gt;&lt;metadata class=&#34;- topic/metadata &#34;&gt;&lt;audience class=&#34;- topic/audience &#34; xtrc=&#34;audience:2;39:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt;&lt;audience class=&#34;- topic/audience &#34; xtrc=&#34;audience:1;28:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt;&lt;category class=&#34;- topic/category &#34; xtrc=&#34;category:1;29:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;/&gt;&lt;prodinfo class=&#34;- topic/prodinfo &#34; xtrc=&#34;prodinfo:1;34:23&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt; &lt;prodname class=&#34;- topic/prodname &#34; xtrc=&#34;prodname:1;35:27&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DolphinDB&lt;/prodname&gt; &lt;brand class=&#34;- topic/brand &#34; xtrc=&#34;brand:1;36:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/ddb_doc_centre.ditamap&#34;&gt;DolphinDB&lt;/brand&gt; &lt;/prodinfo&gt;&lt;/metadata&gt;&lt;/prolog&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:1;1:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;/&gt;&lt;related-links class=&#34;- topic/related-links &#34;&gt;&lt;linkpool class=&#34;- topic/linkpool &#34; xtrc=&#34;topicref:3;16:71&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/chap_tutorials.ditamap&#34;&gt;&lt;link class=&#34;- topic/link &#34; format=&#34;dita&#34; href=&#34;../tutorials/about_tutorials.dita&#34; mapclass=&#34;- map/topicref bookmap/chapter &#34; role=&#34;parent&#34; scope=&#34;local&#34; type=&#34;topic&#34; xtrc=&#34;topicref:1;5:53&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/chap_tutorials.ditamap&#34;&gt;&lt;?ditaot usertext?&gt;&lt;linktext class=&#34;- topic/linktext &#34;&gt;&lt;?ditaot usertext?&gt;教程&lt;/linktext&gt;&lt;?ditaot usershortdesc?&gt;&lt;desc class=&#34;- topic/desc &#34;&gt;DolphinDB 产品使用教程&lt;/desc&gt;&lt;/link&gt;&lt;/linkpool&gt;&lt;/related-links&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;1-为什么对数据库进行分区&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:2;3:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:2;3:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;1. 为什么对数据库进行分区&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:2;3:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:1;5:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;对数据库进行分区可以显著降低系统响应延迟，提高数据吞吐量。具体来说，分区有以下主要好处。&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:1;6:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:1;6:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;分区使得大型表更易于管理。对数据子集的维护操作也更加高效，因为这些操作只针对需要的数据而不是整个表。一个好的分区策略通过只读取查询所需的相关数据来减少要扫描的数据量。如果分区机制设计不合理，对数据库的查询、计算以及其它操作都可能受到磁盘访问 I/O 这个瓶颈的限制。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:2;7:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;分区使得系统可以充分利用所有资源。选择一个良好的分区方案搭配并行计算，分布式计算可以充分利用所有节点来完成通常要在一个节点上完成的任务。若一个任务可以拆分成几个子任务，每个子任务访问不同的分区，可以显著提升效率。&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;2-dolphindb-分区和基于-mpp-架构的数据存储的区别&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:3;10:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:3;10:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;2. DolphinDB 分区和基于 MPP 架构的数据存储的区别&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:3;10:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:2;12:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;MPP(Massive Parallel Processing) 是目前主流数据仓库普遍采用的一种方案，包括开源软件 Greenplum，云数据库 AWS Redshift 等。MPP 有一个主节点，每个客户端都连接到这个主节点。DolphinDB 在数据库层面不存在主节点，是点对点结构，每个客户端可以连接到任何一个数据节点，不会出现主节点瓶颈问题。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:3;14:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;MPP 一般通过哈希规则，将数据分布到各个节点上（水平分割），在各个节点内部再进行分区（垂直分割）。哈希时容易出现各个节点数据分布不均匀的问题。DolphinDB 将各个节点的存储空间交给内置的分布式文件系统（DFS）统一进行管理，分区的规则与分区的存储位置解耦，数据分割不再按水平和垂直两个步骤进行，而是进行全局优化。这样一来，分区的粒度更细更均匀，在计算时能充分的利用集群的所有计算资源。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:4;16:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;由于分布式文件系统具有强大的分区管理、容错、复制机制，以及事务管理机制，DolphinDB 的单表能轻松的支持百万级别的分区。若每个分区有 1GB 的数据，就可实现 PB 级数据的存储和快速查询。另外，通过引入 DFS，数据库的存储和数据库节点相分离，使得 DolphinDB 在集群水平扩展（新增节点）上更加方便。&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/distributed_mpp.JPG&#34; placement=&#34;break&#34; xtrc=&#34;image:1;18:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34; dita-ot:image-width=&#34;1243&#34; dita-ot:image-height=&#34;400&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;3-分区类型&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:4;20:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:4;20:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;3. 分区类型&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:4;20:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:5;22:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB database 支持多种分区类型：范围分区、哈希分区、值分区、列表分区与复合分区。选择合适的分区类型，有助于用户根据业务特点对数据进行均匀分割。&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:2;23:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:3;23:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;范围分区对每个分区区间创建一个分区。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:4;24:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;哈希分区利用哈希函数对分区列操作，方便建立指定数量的分区。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:5;25:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;值分区每个值创建一个分区，例如股票交易日期、股票交易月等。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:6;26:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;列表分区是根据用户枚举的列表来进行分区，比值分区更加灵活。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:7;27:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;复合分区适用于数据量特别大而且 SQL where 或 group by 语句经常涉及多列。可使用 2 个或 3 个分区列，每个分区选择都可以采用区间、值、哈希或列表分区。例如按股票交易日期进行值分区，同时按股票代码进行范围分区。&lt;/li&gt;&lt;/ul&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:6;29:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;创建一个新的分布式数据库时，需要在&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:1;29:18&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;database&lt;/codeph&gt;函数中指定数据库路径 directory，分区类型 partitionType 以及分区模式 partitionScheme。重新打开已有的分布式数据库时，只需指定数据库路径。不允许用不同的分区类型或分区方案覆盖已有的分布式数据库。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:7;31:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;聚合函数在分区表上利用分区列操作时，例如当 group by 列与分区列一致时，运行速度特别快。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:8;33:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;为了学习方便，以下分区例子使用 Windows 本地目录，用户可以将数据库创建使用的路径改成 Linux 或 DFS 目录。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:9;35:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;调用 database 函数前，用户必须先登录，只有具有 DB_OWNER 或 admin 管理员权限才能创建数据库。默认的 admin 管理员登录脚本为：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:1;37:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;login(userId=`admin, password=`123456)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:10;41:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;下文提供的所有创建数据库脚本，默认已经登录。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;31-范围-range-分区&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:5;43:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:5;43:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;3.1. 范围 (RANGE) 分区&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:5;43:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:11;45:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在范围分区中，分区由区间决定，而区间由分区向量的任意两个相邻元素定义。区间包含起始值，但不包含结尾值。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:12;47:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在下面的例子中，数据库 db 有两个分区：[0,5) 和[5,10)。使用 ID 作为分区列，并使用函数 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:2;47:58&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;append!&lt;/codeph&gt; 在数据库 db 中保存表 t 为分区表 pt。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:2;49:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;n=1000000 ID=rand(10, n) x=rand(1.0, n) t=table(ID, x) db=database(&#34;dfs://rangedb&#34;, RANGE, 0 5 10) pt = db.createPartitionedTable(t, `pt, `ID) pt.append!(t) pt=loadTable(db,`pt) select count(x) from pt;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:13;63:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;磁盘目录结构&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/database/range.png&#34; placement=&#34;break&#34; xtrc=&#34;image:2;65:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34; dita-ot:image-width=&#34;675&#34; dita-ot:image-height=&#34;151&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:14;67:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;范围分区创建后，可使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:3;67:12&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;addRangePartitions&lt;/codeph&gt;函数来追加分区。细节参见用户手册。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;32-哈希-hash-分区&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:6;69:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:6;69:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;3.2. 哈希 (HASH) 分区&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:6;69:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:15;71:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;哈希分区对分区列使用哈希函数以产生分区。哈希分区是产生指定数量的分区的一个简便方法。但是要注意，哈希分区不能保证分区的大小一致，尤其当分区列的值的分布存在偏态的时候。此外，若要查找分区列中一个连续范围的数据时，哈希分区的效率比范围分区或值分区要低。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:16;73:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在下面的例子中，数据库 db 有两个分区。使用 ID 作为分区列，并使用函数&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:4;73:39&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;append!&lt;/codeph&gt;在数据库 db 中保存表 t 为分区表 pt。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:3;75:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;n=1000000 ID=rand(10, n) x=rand(1.0, n) t=table(ID, x) db=database(&#34;dfs://hashdb&#34;, HASH, [INT, 2]) pt = db.createPartitionedTable(t, `pt, `ID) pt.append!(t) pt=loadTable(db,`pt) select count(x) from pt;&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;33--值-value-分区&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:7;89:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:7;89:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;3.3. 值 (VALUE) 分区&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:7;89:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:17;91:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在值域（VALUE）分区中，一个值代表一个分区。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:4;93:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;n=1000000 month=take(2000.01M..2016.12M, n) x=rand(1.0, n) t=table(month, x) db=database(&#34;dfs://valuedb&#34;, VALUE, 2000.01M..2016.12M) pt = db.createPartitionedTable(t, `pt, `month) pt.append!(t) pt=loadTable(db,`pt) select count(x) from pt;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:18;108:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;上面的例子定义了一个具有 204 个分区的数据库 db。每个分区是 2000 年 1 月到 2016 年 12 月之间的一个月 (如下图）。在数据库 db 中，表 t 被保存为分区表 pt，分区列为 month。&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/database/value.png&#34; placement=&#34;break&#34; xtrc=&#34;image:3;110:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34; dita-ot:image-width=&#34;605&#34; dita-ot:image-height=&#34;293&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:19;112:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在默认配置（newValuePartitionPolicy=add）情况下，无需手动添加新的分区，当写入数据时，会自动增加对应分区。如本例中，2017年01月的数据写入时，会自动创建201701M这个分区。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;34-列表-list-分区&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:8;114:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:8;114:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;3.4. 列表 (LIST) 分区&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:8;114:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:20;116:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在列表（LIST）分区中，我们用一个包含多个元素的列表代表一个分区。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:5;118:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;n=1000000 ticker = rand(`MSFT`GOOG`FB`ORCL`IBM,n) x=rand(1.0, n) t=table(ticker, x) db=database(&#34;dfs://listdb&#34;, LIST, [`IBM`ORCL`MSFT, `GOOG`FB]) pt = db.createPartitionedTable(t, `pt, `ticker) pt.append!(t) pt=loadTable(db,`pt) select count(x) from pt;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:21;131:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;上面的数据库有 2 个分区。第一个分区包含 3 个股票代号，第二个分区包含 2 个股票代号。&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/database/list.png&#34; placement=&#34;break&#34; xtrc=&#34;image:4;133:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34; dita-ot:image-width=&#34;659&#34; dita-ot:image-height=&#34;165&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;35-组合-compo-分区&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:9;135:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:9;135:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;3.5. 组合 (COMPO) 分区&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:9;135:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:22;137:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;组合（COMPO）分区可以定义 2 或 3 个分区列。每列可以独立采用范围 (RANGE)、值 (VALUE)、哈希 (HASH) 或列表 (LIST) 分区。组合分区的多个列在逻辑上是并列的，不存在从属关系或优先级关系。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:6;139:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;n=1000000 ID=rand(100, n) dates=2017.08.07..2017.08.11 date=rand(dates, n) x=rand(10.0, n) t=table(ID, date, x) dbDate = database(, VALUE, 2017.08.07..2017.08.11) dbID=database(, RANGE, 0 50 100) db = database(&#34;dfs://compoDB&#34;, COMPO, [dbDate, dbID]) pt = db.createPartitionedTable(t, `pt, `date`ID) pt.append!(t) pt=loadTable(db,`pt) select count(x) from pt;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:23;158:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;值域有 5 个分区：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/database/hier1.png&#34; placement=&#34;break&#34; xtrc=&#34;image:5;160:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34; dita-ot:image-width=&#34;642&#34; dita-ot:image-height=&#34;215&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:24;162:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在 20170807 这个分区中，有 2 个区间域 (RANGE) 分区：&lt;/p&gt;&lt;image class=&#34;- topic/image &#34; href=&#34;images/database/hier2.png&#34; placement=&#34;break&#34; xtrc=&#34;image:6;164:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34; dita-ot:image-width=&#34;643&#34; dita-ot:image-height=&#34;96&#34; dita-ot:horizontal-dpi=&#34;96&#34; dita-ot:vertical-dpi=&#34;96&#34;/&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:25;167:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;若组合分区有一列为值分区，创建后可使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:5;167:20&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;addValuePartitions&lt;/codeph&gt;函数来追加分区。细节参见用户手册。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;4-分区设计注意事项&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:10;170:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:10;170:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;4. 分区设计注意事项&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:10;170:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:26;172:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;分区的总原则是让数据管理更加高效，提高查询和计算的性能，达到低延时和高吞吐量。下面是设计和优化分区表的需要考虑的因素，以供参考。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;41-选择合适的分区字段&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:11;174:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:11;174:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;4.1. 选择合适的分区字段&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:11;174:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:27;176:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在 DolphinDB 中，可以用于分区的数据类型包括整型 (CHAR, SHORT, INT)，日期类型 (DATE, MONTH, TIME, MINUTE, SECOND, DATETIME, DATEHOUR)，以及 STRING 与 SYMBOL。除此之外，哈希分区还支持 LONG, UUID, IPADDR, INT128 类型。虽然 STRING 可作为分区列，但为了性能考虑，建议将 STRING 转化为 SYMBOL 再用于分区列。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:28;178:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;FLOAT 和 DOUBLE 数据类型不可作为分区字段。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:7;180:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;db=database(&#34;dfs://rangedb1&#34;, RANGE, 0.0 5.0 10.0)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:29;183:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;会产生出错信息：DOUBLE 数据类型的字段不能作为分区字段&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:8;185:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;The data type DOUBLE can't be used for a partition column&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:30;189:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;虽然 DolphinDB 支持对 TIME, SECOND, DATETIME 类型字段的分区，但是在实际使用中要尽量避免对这些数据类型采用值分区，以免分区粒度过细，将耗费大量时间创建或查询百万级以上的很小的分区。例如下面这个例子就会产生过多的分区。序列：2012.06.01T09:30:00..2012.06.30T16:00:00 包含 2,529,001 个元素。如果用这个序列进行值分区，将会在磁盘上产生 2,529,001 个分区，即 2,529,001 个文件目录和相关文件，从而使得分区表创建、写入、查询都非常缓慢。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:31;191:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;分区字段应当在业务中，特别是数据更新的任务中有重要相关性。譬如在证券交易领域，许多任务都与股票交易日期或股票代码相关，因此以这两个字段来分区比较合理。更新数据库时，DolphinDB 的事务机制（在 5.2 中会提到）不允许多个 writer 的事务在分区上有重叠。鉴于经常需要对某个交易日或某只股票的数据进行更新，若采用其它分区字段（例如交易时刻），有可能造成多个 writer 同时对同一分区进行写入而导致问题。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:32;193:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;一个分区字段相当于数据表的一个物理索引。如果查询时用到了该字段做数据过滤，SQL 引擎就能快速定位需要的数据块，而无需对整表进行扫描，从而大幅度提高处理速度。因此，分区字段应当选用查询和计算时经常用到的过滤字段。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;42-分区粒度不要过大&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:12;196:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:12;196:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;4.2. 分区粒度不要过大&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:12;196:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:33;198:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;一个分区内的多个列以文件形式独立存储在磁盘上，通常数据是经过压缩的。使用的时候，系统从磁盘读取所需要的列，解压后加载到内存。若分区粒度过大，可能会造成多个工作线程并行时内存不足，或者导致系统频繁地在磁盘和工作内存之间切换，影响性能。一个经验公式是，若数据节点的可用内存是 S，工作线程（worker）的的数量是 W，建议每个分区解压后在内存中的大小不超过 S/8W。假设工作内存上限为 32GB，并有 8 个工作线程，建议单个分区解压后的大小不超过 512MB。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:34;200:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 的子任务以分区为单位。因此分区粒度过大会造成无法有效利用多节点多分区的优势，将本来可以并行计算的任务转化成了顺序计算任务。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:35;202:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 是为 OLAP 的场景优化设计的，支持添加数据，不支持对个别行进行删除或更新。如果要修改数据，需以分区为单位替换全部数据。如果分区过大，会降低效率。DolphinDB 在节点之间复制副本数据时，同样以分区为单位，若分区过大，则不利于数据在节点之间的复制。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:36;204:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;综上各种因素，建议一个分区未压缩前的原始数据大小不超过 1GB。当然这个限制可结合实际情况调整。譬如在大数据应用中，经常有宽表设计，一个表有几百个字段，但是单个应用只会使用一部分字段。这种情况下，可以适当放大上限的范围。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:37;206:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;降低分区粒度可采用以下几种方法：（1）采用组合分区 (COMPO)；（2）增加分区个数；（3）将范围分区改为值分区。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;43-分区粒度不要过小&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:13;209:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:13;209:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;4.3. 分区粒度不要过小&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:13;209:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:38;211:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;若分区粒度过小，一个查询和计算作业往往会生成大量的子任务，这会增加数据节点和控制节点，以及控制节点之间的通讯和调度成本。分区粒度过小，也会造成很多低效的磁盘访问（小文件读写)，造成系统负荷过重。另外，所有的分区的元数据都会驻留在控制节点的内存中。分区粒度过小，分区数过多，可能会导致控制节点内存不足。我们建议每个分区未压缩前的数据量不要小于 100M。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:39;213:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;综合前述，推荐分区大小控制在 100MB 到 1GB 之间。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:40;215:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;股票的高频交易数据若按交易日期和股票代码的值做组合分区，会导致许多极小的分区，因为许多交易不活跃的股票的交易数据量太少。如果将股票代码的维度按照范围分区的方法来切分数据，将多个交易不活跃的股票组合在一个分区内，则可以有效解决分区粒度过小的问题，提高系统的性能。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;44-如何将数据均匀分区&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:14;218:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:14;218:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;4.4. 如何将数据均匀分区&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:14;218:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:41;220:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;当各个分区的数据量差异很大时，会造成系统负荷不均衡，部分节点任务过重，而其它节点处于闲置等待状态。当一个任务有多个子任务时，只有最后一个子任务完成了，才会将结果返回给用户。由于一个子任务对应一个分区，如果数据分布不均匀，可能会增大作业延时，影响用户体验。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:42;222:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;为了方便根据数据的分布进行分区，DolphinDB 提供了函数&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:6;222:32&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;cutPoints(X, N, [freq])&lt;/codeph&gt;。这里 X 是一个数组，N 指需要产生多少组，而 freq 是 X 的等长数组，其中每个元素对应着 X 中元素出现的频率。函数返回具有 (N + 1) 个元素的数组，代表 N 个组，使得 X 中的数据均匀地分布在这 N 个组中。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:43;224:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;下面的例子中，需要对股票的报价数据按日期和股票代码两个维度做数据分区。如果简单的按股票的首字母进行范围分区，极易造成数据分布不均，因为极少量的股票代码以 U, V, X，Y，Z 等字母开头。我们这里使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:7;224:102&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;cutPoints&lt;/codeph&gt;函数将 2020 年 10 月 01 日到 2020 年 10 月 29 日的数据根据股票代码划为 5 个分区，&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:9;226:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;dates=2020.10.01..2020.10.29; syms=&#34;A&#34;+string(1..13); syms.append!(string('B'..'Z')); buckets=cutPoints(syms,5);//cutpoints t1=table(take(syms,10000) as stock, rand(dates,10000) as date, rand(10.0,10000) as x); dateDomain = database(&#34;&#34;, VALUE, dates); symDomain = database(&#34;&#34;, RANGE, buckets); stockDB = database(&#34;dfs://stockDBTest&#34;, COMPO, [dateDomain, symDomain]); pt = stockDB.createPartitionedTable(t1, `pt, `date`stock).append!(t1);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:44;238:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;除了使用范围分区的方法，列表分区也是解决数据分布不均匀的有效方法。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;45-时序类型分区&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:15;240:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:15;240:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;4.5. 时序类型分区&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:15;240:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:45;242:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;时间是实际数据中最常见的一个维度。DolphinDB 提供了丰富时间类型以满足用户的需求。当我们以时间类型字段作为分区字段时，在时间取值上可以预留分区以容纳未来的数据。下面的例子，我们创建一个数据库，以天为单位，将 2000.01.01 到 2030.01.01 的日期分区。注意，只有当实际数据写入数据库时，数据库才会真正创建需要的分区。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:10;244:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;dateDB = database(&#34;dfs://testDate&#34;, VALUE, 2000.01.01 .. 2030.01.01)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:46;248:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 使用时间类型作为分区字段时，还有一个特殊的优点。数据库定义的分区字段类型和数据表实际采用的时间类型可以不一致，只要保证定义的分区字段数据类型精度小于等于实际数据类型即可。比如说，如果数据库是按月（month）分区，数据表的字段可以是 month, date, datetime, timestamp 和 nanotimestamp。系统自动会作数据类型的转换。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;46-不同表相同分区的数据存于同一节点&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:16;251:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:16;251:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;4.6. 不同表相同分区的数据存于同一节点&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:16;251:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:47;253:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在分布式数据库中，如果多个分区的数据表要连接（join）通常十分耗时，因为涉及到的分区可能在不同的节点上，需要在不同节点之间复制数据。为解决这个问题，DolphinDB 推出了共存储位置的分区机制，确保同一个分布式数据库里所有表在相同分区的数据存储在相同的节点上。这样的安排，保证了这些表在连接的时候非常高效。DolphinDB 当前版本对采用不同分区机制的多个分区表不提供连接功能。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:11;255:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;dateDomain = database(&#34;&#34;, VALUE, 2018.05.01..2018.07.01) symDomain = database(&#34;&#34;, RANGE, string('A'..'Z') join `ZZZZZ) stockDB = database(&#34;dfs://stockDB&#34;, COMPO, [dateDomain, symDomain]) quoteSchema = table(10:0, `sym`date`time`bid`bidSize`ask`askSize, [SYMBOL,DATE,TIME,DOUBLE,INT,DOUBLE,INT]) stockDB.createPartitionedTable(quoteSchema, &#34;quotes&#34;, `date`sym) tradeSchema = table(10:0, `sym`date`time`price`vol, [SYMBOL,DATE,TIME,DOUBLE,INT]) stockDB.createPartitionedTable(tradeSchema, &#34;trades&#34;, `date`sym)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:48;266:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;上面的例子中，quotes 和 trades 两个分区表采用同一个分区机制。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;5-导入数据到分布式数据表&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:17;268:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:17;268:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;5. 导入数据到分布式数据表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:17;268:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:49;270:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 是为 OLAP 设计的系统，主要是解决海量结构化数据的快速存储和计算，以及通过内存数据库和流数据计算引擎实现高性能的数据处理。DolphinDB 不适合数据频繁更改的 OLTP 业务系统。DolphinDB 的数据写入与 Hadoop HDFS 类似，快速在每个分区或文件的末尾批量插入数据。插入的数据会压缩存储到磁盘，一般压缩比例在 20%~25%。数据一旦追加到基于磁盘的数据表后，不能快速更新或删除某些符合条件的记录，必须以分区为单位对数据表进行修改。这也是分区原则中提到单个分区不宜过大的原因之一。&lt;/p&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;51-多副本机制&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:18;272:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:18;272:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;5.1. 多副本机制&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:18;272:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:50;274:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 允许为每一个分区保留多个副本，默认的副本个数是 2，可以修改控制节点的参数 dfsReplicationFactor 来设置副本数量。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:51;276:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;设置冗余数据的目的有两个： （1）当某个数据节点失效或者或磁盘数据损坏时，系统提供容错功能继续提供服务； （2）当大量并发用户访问时，多副本提供负载均衡的功能，提高系统吞吐量，降低访问延时。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:52;280:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 通过两阶段事务提交机制，确保数据写入时，同一副本在多节点之间的数据强一致性。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:53;282:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在控制节点的参数文件 controller.cfg 中，还有一个非常重要的参数 dfsReplicaReliabilityLevel。该参数决定是否允许多个副本驻留在同一台物理服务器的多个数据节点上。在开发阶段，可允许在一个机器上配置多个节点，同时允许多个副本驻留在同一台物理服务器（dfsReplicaReliabilityLevel=0），但是在生产阶段需要设置成为 1，否则起不到容错备份的作用。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;52-事务机制&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:19;284:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:19;284:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;5.2. 事务机制&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:19;284:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:54;286:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 对基于磁盘（分布式文件系统）的数据库表的读写支持事务，也就是说确保事务的原子性，一致性，隔离性和持久化。DolphinDB 采用多版本机制实现快照级别的隔离。在这种隔离机制下，数据的读操作和写操作互相不阻塞，可以最大程度优化数据仓库读的性能。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:55;288:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;为了最大程度优化数据仓库查询、分析、计算的性能，DolphinDB 对事务作了一些限制：&lt;/p&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:3;289:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:8;289:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;首先，一个事务只能包含写或者读，不能同时进行写和读。&lt;/li&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:9;290:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;其次，一个写事务可以跨越多个分区，但当通过 database 建库且设置参数 atomic='TRANS'，则同一个分区不能被多个 writer 并发写入。当一个分区被某一个事务 A 锁定之后，另一个事务 B 试图再次去锁定这个分区时，系统立刻会抛出异常导致事务 B 失败回滚。当设置 atomic='CHUNK'时，无此限制。&lt;/li&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;53-多-writer-并行写入&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:20;292:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:20;292:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;5.3. 多 Writer 并行写入&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:20;292:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:56;294:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 中，单个数据表可有几百万个分区，这为高性能的并行数据加载创造了条件。特别是将海量数据从其它系统导入 DolphinDB 时，或者需要将实时数据以准实时的方式写入数据仓库时，并行加载对于性能尤为重要。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:57;296:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;下面的例子将股票报价数据（quotes）并行加载到基于日期和股票代码的复合分区数据库 stockDB。数据存储在&lt;xref class=&#34;- topic/xref &#34; format=&#34;zip&#34; href=&#34;data/database/quotes.zip&#34; xtrc=&#34;xref:1;296:57&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;?ditaot usertext?&gt;csv 文件&lt;/xref&gt;中，每个文件保存一天的报价数据。对每个文件，通过文件名产生 jobId 前缀，并通过命令&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:8;296:135&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;submitJob&lt;/codeph&gt;提交后台程序调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:9;296:154&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;loadTextEx&lt;/codeph&gt;函数将数据加载到 stockDB 数据库中。通过&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:10;296:190&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;pnodeRun&lt;/codeph&gt;将上述任务发送到集群的每个数据节点进行并行加载。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:12;298:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;dateDomain = database(&#34;&#34;, VALUE, 2018.05.01..2018.07.01) symDomain = database(&#34;&#34;, RANGE, string('A'..'Z') join `ZZZZZ) stockDB = database(&#34;dfs://stockDB&#34;, COMPO, [dateDomain, symDomain]) quoteSchema = table(10:0, `sym`date`time`bid`bidSize`ask`askSize, [SYMBOL,DATE,TIME,DOUBLE,INT,DOUBLE,INT]) stockDB.createPartitionedTable(quoteSchema, &#34;quotes&#34;, `date`sym) def loadJob(){ fileDir='/stockData' filenames = exec filename from files(fileDir) db = database(&#34;dfs://stockDB&#34;) for(fname in filenames){ jobId = fname.strReplace(&#34;.csv&#34;, &#34;&#34;) submitJob(jobId,, loadTextEx{db, &#34;quotes&#34;, `date`sym, fileDir+'/'+fname}) } } pnodeRun(loadJob);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:58;318:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;b class=&#34;+ topic/ph hi-d/b &#34; xtrc=&#34;b:1;318:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;在上面的例子中，database 的参数使用默认值（atomic='TRANS'），若多个 writer 并行加载数据，则需要确保这些 writer 不会同时往同一个分区写入数据，否则会导致事务失败&lt;/b&gt;。在上面的例子中，每一个文件存储了一天的数据，而 quotes 表的一个分区字段是日期，从而确保所有加载数据的作业不会产生有重叠的事务。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;54-数据导入的常用方法&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:21;320:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:21;320:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;5.4. 数据导入的常用方法&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:21;320:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:59;322:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 的分布式数据库提供标准方法&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:11;322:24&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;append!&lt;/codeph&gt;函数批量追加数据到到数据库。各种数据导入方法实际上就是直接或间接的调用这个函数将数据写入到数据库。后面的所有例子，都使用 5.4 中创建的 stockDB 的 quotes 表。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:13;324:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;n = 1000000 syms = `IBM`MSFT`GM`C`FB`GOOG`V`F`XOM`AMZN`TSLA`PG`S time = 09:30:00 + rand(21600000, n) bid = rand(10.0, n) bidSize = 1 + rand(100, n) ask = rand(10.0, n) askSize = 1 + rand(100, n) quotes = table(rand(syms, n) as sym, take(2018.05.04..2018.05.11,n) as date, time, bid, bidSize, ask, askSize) loadTable(&#34;dfs://stockDB&#34;, &#34;quotes&#34;).append!(quotes);&lt;/codeblock&gt;&lt;/body&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;541-从文本文件导入数据&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:22;337:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:22;337:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;5.4.1. 从文本文件导入数据&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:22;337:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:60;339:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 提供三个函数&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:12;339:17&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;loadText&lt;/codeph&gt;，&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:13;339:28&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;ploadText&lt;/codeph&gt;和&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:14;339:40&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;loadTextEx&lt;/codeph&gt;加载文本数据。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:14;340:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;workDir = &#34;C:/DolphinDB/Data&#34; if(!exists(workDir)) mkdir(workDir) quotes.saveText(workDir + &#34;/quotes.csv&#34;) quotes.saveText(workDir + &#34;/quotes_new.csv&#34;)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:61;347:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:15;347:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;loadText&lt;/codeph&gt;或&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:16;347:14&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;ploadText&lt;/codeph&gt;将数据从文件加载到内存，然后再调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:17;347:42&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;append!&lt;/codeph&gt;函数。这种方法适合于数据量小于物理内存的情况，因为数据将被全部导入内存。 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:18;347:88&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;ploadText&lt;/codeph&gt;和&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:19;347:100&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;loadText&lt;/codeph&gt;的区别在于前者采用并行方法加载文本文件。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:15;348:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;t=loadText(workDir + &#34;/quotes_new.csv&#34;) loadTable(&#34;dfs://stockDB&#34;, &#34;quotes&#34;).append!(t) &lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:62;354:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:20;354:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;loadTextEx&lt;/codeph&gt;直接将文本数据导入到数据库分区表，是 DolphinDB 推荐使用的加载文本数据的方法。它的优点是：并行处理速度快，而且文件尺寸可远远大于物理内存。&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:21;354:87&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;loadTextEx&lt;/codeph&gt;运行时，帮助用户调用了&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:22;354:110&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;append!&lt;/codeph&gt;函数。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:16;355:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;db = database(&#34;dfs://stockDB&#34;) loadTextEx(db, &#34;quotes&#34;, `date`sym, workDir + &#34;/quotes.csv&#34;)&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;542-订阅一个流数据批量写入&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:23;360:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:23;360:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;5.4.2. 订阅一个流数据，批量写入&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:23;360:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:63;362:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 支持流数据的处理。用户可以订阅一个流数据，将订阅到的流数据批量写入到分布式表中。详细内容，请参阅帮助文档关于流计算的部分。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:17;364:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;dfsQuotes = loadTable(&#34;dfs://stockDB&#34;, &#34;quotes&#34;) saveQuotesToDFS=def(mutable t, msg): t.append!(select today() as date,* from msg) subscribeTable(, &#34;quotes_stream&#34;, &#34;quotes&#34;, -1, saveQuotesToDFS{dfsQuotes}, true, 10000, 6)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:64;369:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;上面的例子中，我们订阅了流数据表 quotes_stream，等待时间超过 6 秒或缓存的 quotes 记录达到 1 万条，批量写入到分布式表 dfs://stockDB/quotes 中。&lt;/p&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;543-通过-odbc-导入数据&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:24;371:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:24;371:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;5.4.3. 通过 ODBC 导入数据&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:24;371:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:65;373:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;用户也可以通过 ODBC Plugin，将其它数据源中的数据导入到 DolphinDB 中。下面例子通过 ODBC 将 mysql 中的 quotes 表导入到 DolphinDB。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:66;375:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;下载插件解压并拷贝 plugins/odbc 目录下所有文件到 DolphinDB server/plugins/odbc 目录下。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:18;377:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;loadPlugin(&#34;plugins/odbc/odbc.cfg&#34;) conn=odbc::connect(&#34;Driver=MySQL;Data Source = mysql-stock;server=127.0.0.1;uid=[xxx];pwd=[xxx];database=stockDB&#34;) t=odbc::query(conn,&#34;select * from quotes&#34;) loadTable(&#34;dfs://stockDB&#34;, &#34;quotes&#34;).append!(t)&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;544-通过-programming-api-导入数据&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:25;384:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:25;384:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;5.4.4. 通过 Programming API 导入数据&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:25;384:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:67;386:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DolphinDB 提供了 Python, Java, C++, C#, R 以及 JavaScript 的编程接口。用户可在这些系统中准备好数据，然后调用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:23;386:79&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;append!&lt;/codeph&gt;函数，将数据导入到 DolphinDB 的分布式表。下面我们以 Java 为例，给出核心的代码。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:19;388:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;DBConnection conn = new DBConnection();&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:68;391:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;连接并登录到 DolphnDB 服务器：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:20;392:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;conn.connect(&#34;localhost&#34;, 8848, &#34;admin&#34;, &#34;123456&#34;);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:69;395:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;定义函数 saveQuotes：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:21;396:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;conn.run(&#34;def saveQuotes(t){ loadTable('dfs://stockDB','quotes').append!(t)}&#34;);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:70;399:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;准备一个数据表，具体过程省略：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:22;400:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;BasicTable quotes = ...&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:71;403:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;调用服务端函数 saveQuotes：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:23;404:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;List&amp;lt;Entity&amp;gt; args = new ArrayList&amp;lt;Entity&amp;gt;(1); args.add(quotes); conn.run(&#34;saveQuotes&#34;, args);&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;6-数据重分区和复制-dfs-表&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:26;410:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:26;410:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;6. 数据重分区和复制 DFS 表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:26;410:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;/&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;61-数据重分区&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:27;412:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:27;412:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;6.1. 数据重分区&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:27;412:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:72;414:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;数据库的分区类型和分区方案一旦确定以后，就不能修改。如果要对数据重新分区，需要新建一个数据库，然后把原数据库中的数据导入到新数据库中。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:73;416:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;例如，假设有一个组合分区的数据库 dfs://db1，第一层是按天分区，第二层根据股票代码范围划分为 30 个分区，创建数据库的代码如下：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:24;418:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;login(&#34;admin&#34;,&#34;123456&#34;) t=table(1:0,`timestamp`sym`qty`price,[TIMESTAMP,SYMBOL,DOUBLE,DOUBLE]) dates=2010.01.01..2020.12.31 syms=&#34;A&#34;+string(1..500) sym_ranges=cutPoints(syms,30) db1=database(&#34;&#34;,VALUE,dates) db2=database(&#34;&#34;,RANGE,sym_ranges) db=database(&#34;dfs://db1&#34;,COMPO,[db1,db2]) db.createPartitionedTable(t,`tb1,`timestamp`sym)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:74;430:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;现在要把以上数据库中的数据导入到新的数据库 dfs://db2 中。新数据库是组合分区，第一层依然是按天分区，第二层按照股票代码范围划分为 50 个分区，创建数据库的代码如下：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:25;432:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;login(&#34;admin&#34;,&#34;123456&#34;) t=table(1:0,`timestamp`sym`qty`price,[TIMESTAMP,SYMBOL,DOUBLE,DOUBLE]) dates=2010.01.01..2020.12.31 syms=&#34;A&#34;+string(1..500) sym_ranges=cutPoints(syms,50) db1=database(&#34;&#34;,VALUE,dates) db2=database(&#34;&#34;,RANGE,sym_ranges) db=database(&#34;dfs://db2&#34;,COMPO,[db1,db2]) db.createPartitionedTable(t,`tb2,`timestamp`sym)&lt;/codeblock&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:4;444:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:10;444:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;如果总数据量很小，可以直接把所有数据加载到内存表中，再把内存表中的数据保存到新的数据库中。&lt;/li&gt;&lt;/ul&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:26;446:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;allData=select * from loadTable(&#34;dfs://db1&#34;,&#34;tb1&#34;) tb2=loadTable(&#34;dfs://db2&#34;,&#34;tb2&#34;) tb2.append!(allData)&lt;/codeblock&gt;&lt;ul class=&#34;- topic/ul &#34; xtrc=&#34;ul:5;452:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;li class=&#34;- topic/li &#34; xtrc=&#34;li:11;452:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;但通常分布式表的数据量非常大，无法全量加载到内存中，可以用 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:24;452:33&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;repartitionDS&lt;/codeph&gt; 函数划分数据源，将数据划分为若干个内存能够容纳的小数据块，再通过 map-reduce 的方法将数据块分批加载到内存并保存到新的数据库中。这样做不仅可以解决内存不够的问题，而且通过并行加载提升性能。&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:25;452:148&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;repartitionDS&lt;/codeph&gt;函数的语法如下：&lt;/li&gt;&lt;/ul&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:27;454:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;repartitionDS(query, [column], [partitionType], [partitionScheme], [local=true])&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:75;458:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;下例按天将数据划分为多个小数据块，分批将数据写入新的数据库中：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:28;460:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;def writeDataTo(dbPath, tbName, mutable tbdata){ loadTable(dbPath,tbName).append!(tbdata) } datasrc=repartitionDS(&amp;lt;select * from loadTable(&#34;dfs://db1&#34;,&#34;tb1&#34;)&amp;gt;,`date,VALUE,dates) mr(ds=datasrc, mapFunc=writeDataTo{&#34;dfs://db2&#34;,&#34;tb2&#34;}, parallel=true)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:76;469:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;上例中 repartitionDS 函数中 local=true，表示会把重分区后的 chunk 数据都汇总到当前的协调节点，做进一步的 map-reduce 处理。如果当前节点的资源有限，可以将 local 设置为 false。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:77;471:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;mr 函数中 parallel=true 表示小数据块会并行加载到内存和写入到数据库，只有满足以下两个条件才能将 parallel 设置为 true：（1）内存充足；（2）两个 map 子任务不会同时写入新数据库中的某个分区。否则要将 parallel 设置为 false，local 设置为 true。假如新数据库 dfs://db3 的第一层分区是按日期的范围进行分区，每个月一个分区：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:29;473:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;login(&#34;admin&#34;,&#34;123456&#34;) t=table(1:0,`timestamp`sym`qty`price,[TIMESTAMP,SYMBOL,DOUBLE,DOUBLE]) months=date(2010.01M..2021.01M) syms=&#34;A&#34;+string(1..500) sym_ranges=cutPoints(syms,50) db1=database(&#34;&#34;,RANGE,months) //每个月一个分区 db2=database(&#34;&#34;,RANGE,sym_ranges) db=database(&#34;dfs://db3&#34;,COMPO,[db1,db2]) db.createPartitionedTable(t,`tb3,`timestamp`sym)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:78;485:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;由于&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:26;485:3&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;repartitionDS&lt;/codeph&gt;函数按天划分的多个小数据块对应新数据库中的同一个分区，而 DolphinDB 不允许同时对一个分区进行写入，因此要 parallel 设置为 false。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:30;487:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;def writeDataTo(dbPath, tbName, mutable tbdata){ loadTable(dbPath,tbName).append!(tbdata) } datasrc=repartitionDS(&amp;lt;select * from loadTable(&#34;dfs://db1&#34;,&#34;tb1&#34;)&amp;gt;,`date,VALUE,dates) mr(ds=datasrc, mapFunc=writeDataTo{&#34;dfs://db2&#34;,&#34;tb2&#34;}, parallel=true)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:79;496:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:27;496:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;repartitionDS&lt;/codeph&gt;目前支持 VALUE 和 RANGE 两种分区方法。上例中，如果内存充足，我们也可以按月划分数据：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:31;498:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;months=date(2010.01M..2021.01M) datasrc=repartitionDS(&amp;lt;select * from tb1&amp;gt;,`date,RANGE,months) //按月划分 mr(ds=datasrc, mapFunc=writeDataTo{&#34;dfs://db2&#34;,&#34;tb2&#34;}, parallel=false)&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;62-复制-dfs-表&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:28;504:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:28;504:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;6.2. 复制 DFS 表&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:28;504:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:80;506:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;如果只需复制 DFS 表，不改变数据的分区类型和分区方案，可以使用 &lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:28;506:35&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;sqlDS&lt;/codeph&gt; 函数划分数据源。例如，把 6.1 中表 tb1 的内容复制到同一个数据库的表 tb1_bak 中：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:32;508:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;//创建tb1_bak db=database(&#34;dfs://db1&#34;) t=table(1:0,`timestamp`sym`qty`price,[TIMESTAMP,SYMBOL,DOUBLE,DOUBLE]) db.createPartitionedTable(t,`tb1_bak,`timestamp`sym) //把表tb1的内容写入到表tb1_bak中 def writeDataTo(dbPath, tbName, mutable tbdata){ loadTable(dbPath,tbName).append!(tbdata) } datasrc=sqlDS(&amp;lt;select * from tb1&amp;gt;) mr(ds=datasrc, mapFunc=writeDataTo{&#34;dfs://db1&#34;,&#34;tb1_bak&#34;}, parallel=true)&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:81;523:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;当然，&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:29;523:4&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;repartitionDS&lt;/codeph&gt;的方法也适用于复制 DFS 表，但是使用&lt;codeph class=&#34;+ topic/ph pr-d/codeph &#34; xtrc=&#34;codeph:30;523:39&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;sqlDS&lt;/codeph&gt;的性能更好。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:33;525:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;datasrc=repartitionDS(&amp;lt;select * from tb1&amp;gt;,`date,VALUE) mr(ds=datasrc, mapFunc=writeDataTo{&#34;dfs://db1&#34;,&#34;tb1_bak&#34;}, parallel=true)&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;&lt;topic class=&#34;- topic/topic &#34; ditaarch:DITAArchVersion=&#34;2.0&#34; domains=&#34;a(props audience) a(props deliveryTarget) a(props otherprops) a(props platform) a(props product)&#34; id=&#34;7-查询分区表注意事项&#34; specializations=&#34;@props/audience @props/deliveryTarget @props/otherprops @props/platform @props/product&#34; xtrc=&#34;topic:29;530:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;title class=&#34;- topic/title &#34; xtrc=&#34;title:29;530:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;7. 查询分区表注意事项&lt;/title&gt;&lt;body class=&#34;- topic/body &#34; xtrc=&#34;body:29;530:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:82;532:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;系统在执行分布式查询时，首先根据 WHERE 条件确定需要的分区，然后把查询发送到相关分区所在的节点，最后整合这些分区的结果返回给用户。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:83;534:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;大多数分布式查询只涉及分布式表的部分分区。系统会根据关系运算符（&amp;lt;, &amp;lt;=, =, ==, &amp;gt;, &amp;gt;=, in, between）和逻辑运算符（or，and）在加载和处理数据前确定相关的分区，避免全表扫描，从而节省大量时间。下面的例子可以帮助理解 DolphinDB 如何确定相关分区。以下脚本创建了分布式表 pt，其中分区字段是 date，分区类型是 RANGE，从 1990.01.01 开始，每 2 个月为一个分区。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; outputclass=&#34;python&#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:34;536:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;n=10000000 id=take(1..1000, n).sort() date=1989.12.31+take(1..10000, n) x=rand(1.0, n) y=rand(10, n) t=table(id, date, x, y) db=database(&#34;dfs://rangedb1&#34;, RANGE, date(1990.01M+(0..200)*2)) pt = db.createPartitionedTable(t, `pt, `date) pt.append!(t); pt=db.loadTable(`pt);&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:84;550:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;以下类型的查询可以在加载和处理数据前缩小数据范围：&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:35;552:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;select * from pt where date&amp;gt;1990.04.01 and date&amp;lt;1990.06.01;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:85;555:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;系统确定了两个相关分区：[1990.03.01, 1990.05.01) 和[1990.05.01, 1990.07.01)。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:36;557:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;select * from pt where date between 1990.12.01:1990.12.10;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:86;560:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;系统确定了一个相关分区：[1990.11.01, 1991.01.01)。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:37;562:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;select count(*) from pt where date between 1990.08.01:1990.12.01 group by date;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:87;565:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;系统确定了三个相关分区：[1990.07.01, 1990.09.01)、[1990.09.01, 1990.11.01) 和[1990.11.01, 1991.01.01)。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:38;567:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;select * from pt where y&amp;lt;5 and date between 1990.08.01:1990.08.31;&lt;/codeblock&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:88;570:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;系统确定了一个相关分区：[1990.07.01, 1990.09.01)。注意，系统忽略了 y&amp;lt;5 的条件。加载了相关分区后，系统会根据 y&amp;lt;5 的条件进一步筛选数据。&lt;/p&gt;&lt;p class=&#34;- topic/p &#34; xtrc=&#34;p:89;572:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;以下类型的查询不能确定相关分区，会全表扫描。对于数据量非常大的分区表，会耗费大量时间，应当尽量避免。&lt;/p&gt;&lt;codeblock class=&#34;+ topic/pre pr-d/codeblock &#34; xml:space=&#34;preserve&#34; xtrc=&#34;codeblock:39;574:1&#34; xtrf=&#34;file:/var/lib/jenkins/workspace/packDocCN/documentation/zh/tutorials/database.md&#34;&gt;select * from pt where date+10&amp;gt;1990.08.01; select * from pt where 1990.08.01&amp;lt;date&amp;lt;1990.09.01; select * from pt where month(date)&amp;lt;=1990.03M; select * from pt where y&amp;lt;5; announcementDate=1990.08.01 select * from pt where date&amp;lt;announcementDate-3; select * from pt where y&amp;lt;5 or date between 1990.08.01:1990.08.31;&lt;/codeblock&gt;&lt;/body&gt;&lt;/topic&gt;&lt;/topic&gt;"/><meta name="wh-source-relpath" content="tutorials/database.md"/><meta name="wh-out-relpath" content="tutorials/database.html"/>

    <link rel="stylesheet" type="text/css" href="../oxygen-webhelp/app/commons.css?buildId=2024012323"/>
    <link rel="stylesheet" type="text/css" href="../oxygen-webhelp/app/topic.css?buildId=2024012323"/>

    <script src="../oxygen-webhelp/app/options/properties.js?buildId=20250305183303"></script>
    <script src="../oxygen-webhelp/app/localization/strings.js?buildId=2024012323"></script>
    <script src="../oxygen-webhelp/app/search/index/keywords.js?buildId=20250305183303"></script>
    <script defer="defer" src="../oxygen-webhelp/app/commons.js?buildId=2024012323"></script>
    <script defer="defer" src="../oxygen-webhelp/app/topic.js?buildId=2024012323"></script>
<link rel="stylesheet" type="text/css" href="../oxygen-webhelp/template/styles.css?buildId=2024012323"/><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script></head>

    <body id="分区数据库设计和操作" class="wh_topic_page frmBody">
        <a href="#wh_topic_body" class="sr-only sr-only-focusable">
            跳转到主要内容
        </a>
        
        
        
        
        <header class="navbar navbar-default wh_header">
    <div class="container-fluid">
        <div xmlns:whc="http://www.oxygenxml.com/webhelp/components" class="wh_header_flex_container navbar-nav navbar-expand-md navbar-dark">
            <div class="wh_logo_and_publication_title_container">
                <div class="wh_logo_and_publication_title">
                    
                    <a href="https://docs.dolphindb.cn/zh/index.html" class=" wh_logo d-none d-sm-block "><img src="../logo.png" alt="  DolphinDB 文档中心  "/></a>
                    <div class=" wh_publication_title "><a href="../index.html"><span class="booktitle">  <span class="ph mainbooktitle">DolphinDB 文档中心</span>  </span></a></div>
                    
                </div>
                
                
            </div>

            <div class="wh_top_menu_and_indexterms_link collapse navbar-collapse" id="wh_top_menu_and_indexterms_link">
                
                
                
                
            </div>
        <div class=" wh_search_input navbar-form wh_topic_page_search search " role="form">
            
            
            
            <form id="searchForm" method="get" role="search" action="../search.html"><div><input type="search" placeholder="搜索 " class="wh_search_textfield" id="textToSearch" name="searchQuery" aria-label="搜索查询" required="required"/><button type="submit" class="wh_search_button" aria-label="搜索"><span class="search_input_text">搜索</span></button></div></form>
            
            <script src="/vendors/react/umd/react.production.min.js" defer="defer"></script>
<script src="/vendors/react-dom/umd/react-dom.production.min.js" defer="defer"></script>
<script src="/vendors/dayjs/dayjs.min.js" defer="defer"></script>
<script src="/vendors/antd/dist/antd.min.js" defer="defer"></script>
<script src="/vendors/@ant-design/icons/dist/index.umd.min.js" defer="defer"></script>
<script src="/zh/index.js" type="module"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" defer="defer"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer="defer"><!--


--></script>
<script defer="defer"><!--

// 从主页重定向
const currentUrl = window.location.href;

// 判断当前URL是否包含index.html并且路径最后部分是index.html
if (currentUrl.endsWith('index.html')) {
    // 处理根目录下的index.html跳转
    const baseUrl = currentUrl.split('/index.html')[0]; // 获取index.html之前的部分
    const redirectUrl = `${baseUrl}/about/ddb_intro.html`; // 构建跳转路径
    window.location.href = redirectUrl; // 执行跳转
}

--></script>
            
        </div></div>
    </div>
</header>
        
        
         
        
        
        
        <div class="container-fluid" id="wh_topic_container">
            <div class="row">

                <nav class="wh_tools d-print-none navbar-expand-md" aria-label="Tools">
                    
                    <div data-tooltip-position="bottom" class=" wh_breadcrumb "><ol class="d-print-none"><li><span class="home"><a href="../index.html"><span>主页</span></a></span></li><li><div class="topicref" data-id="about_tutorials"><div class="title"><a href="../tutorials/about_tutorials.html"><span class="keyword label">教程</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 产品使用教程</p></div></div></div></li><li><div class="topicref"><div class="title"><a href="../tutorials/database.html">数据库</a></div></div></li><li class="active"><div class="topicref" data-id="分区数据库设计和操作"><div class="title"><a href="../tutorials/database.html">分区数据库设计和操作</a></div></div></li></ol></div>
                    
                    
                    
                    <div class="wh_right_tools">
                        <button class="wh_hide_highlight" aria-label="切换搜索突出显示" title="切换搜索突出显示"></button>
                        <button class="webhelp_expand_collapse_sections" data-next-state="collapsed" aria-label="折叠截面" title="折叠截面"></button>
                        
                        
                        
                        
                        <div class=" wh_print_link print d-none d-md-inline-block "><button onClick="window.print()" title="打印此页" aria-label="打印此页"></button></div>
                        
                        <button type="button" id="wh_toc_button" class="custom-toggler navbar-toggler collapsed wh_toggle_button navbar-light" aria-expanded="false" aria-label="Toggle publishing table of content" aria-controls="wh_publication_toc">
                            <span class="navbar-toggler-icon"></span>
                        </button>
                    </div>
                    
                </nav>
            </div>
            
            
            
            
            <div class="wh_content_area">
                <div class="row">
                    
                        <nav id="wh_publication_toc" class="col-lg-3 col-md-3 col-sm-12 d-md-block d-none d-print-none" aria-label="Table of Contents Container">
                            <div id="wh_publication_toc_content">
		                        
                            	<div class=" wh_publication_toc " data-tooltip-position="right"><span class="expand-button-action-labels"><span id="button-expand-action" role="button" aria-label="Expand"></span><span id="button-collapse-action" role="button" aria-label="Collapse"></span><span id="button-pending-action" role="button" aria-label="Pending"></span></span><ul role="tree" aria-label="Table of Contents"><li role="treeitem"><div data-tocid="ddb_intro-d9713e87" class="topicref" data-id="ddb_intro" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../about/ddb_intro.html" id="ddb_intro-d9713e87-link">关于DolphinDB</a></div></div></li><li role="treeitem"><div data-tocid="chap1_getstarted-d9713e136" class="topicref" data-id="chap1_getstarted" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../getstarted/chap1_getstarted.html" id="chap1_getstarted-d9713e136-link">快速上手</a><div class="wh-tooltip"><p class="shortdesc">如何快速部署 DolphinDB、建库建表、写入和查询数据</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="sectionddb_deployment-d9713e189" class="topicref" data-id="sectionddb_deployment" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action sectionddb_deployment-d9713e189-link" class="wh-expand-btn"></span><div class="title"><a href="../deploy/deploy_intro.html" id="sectionddb_deployment-d9713e189-link"><span class="keyword label">部署</span></a><div class="wh-tooltip"><p class="shortdesc">如何在不同的场景中部署 DolphinDB</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="new_chap_database_manage_new_chap_dbmanage_landing_page-d9713e2259" class="topicref" data-id="new_chap_database_manage_new_chap_dbmanage_landing_page" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action new_chap_database_manage_new_chap_dbmanage_landing_page-d9713e2259-link" class="wh-expand-btn"></span><div class="title"><a href="../db_distr_comp/cfg/db_intro.html" id="new_chap_database_manage_new_chap_dbmanage_landing_page-d9713e2259-link"><span class="keyword label">数据库</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 数据库的基本概念</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="chap7_tutorials_streaming-d9713e3760" class="topicref" data-id="chap7_tutorials_streaming" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action chap7_tutorials_streaming-d9713e3760-link" class="wh-expand-btn"></span><div class="title"><a href="../stream/str_intro.html" id="chap7_tutorials_streaming-d9713e3760-link"><span class="keyword label">流数据</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 流数据引擎及流数据计算的基本概念</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e7513" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e7513-link" class="wh-expand-btn"></span><div class="title"><a href="../db_distr_comp/db_oper/import_data.html" id="tocId-d9713e7513-link">数据迁移</a><div class="wh-tooltip"><p class="shortdesc">如何从不同数据源向 DolphinDB 迁移数据</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="chap7_tutorials_system_management-d9713e7940" class="topicref" data-id="chap7_tutorials_system_management" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action chap7_tutorials_system_management-d9713e7940-link" class="wh-expand-btn"></span><div class="title"><a href="../sys_man/om_intro.html" id="chap7_tutorials_system_management-d9713e7940-link"><span class="keyword label">系统运维</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 的系统运维功能及方法</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="troubleshooting-d9713e8780" class="topicref" data-id="troubleshooting" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action troubleshooting-d9713e8780-link" class="wh-expand-btn"></span><div class="title"><a href="../error_codes/troubleshooting.html" id="troubleshooting-d9713e8780-link">故障排查</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="about_language_resources-d9713e20911" class="topicref" data-id="about_language_resources" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action about_language_resources-d9713e20911-link" class="wh-expand-btn"></span><div class="title"><a href="../progr/progr_intro.html" id="about_language_resources-d9713e20911-link"><span class="keyword label">编程语言</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 编程基本概念与方法、SQL 在 DolphinDB 的应用</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="functions_references-d9713e30925" class="topicref" data-id="functions_references" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action functions_references-d9713e30925-link" class="wh-expand-btn"></span><div class="title"><a href="../funcs/funcs_intro.html" id="functions_references-d9713e30925-link"><span class="keyword label">函数参考</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 函数分类、语法、详解及示例</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="api_protocol-d9713e94064" class="topicref" data-id="api_protocol" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action api_protocol-d9713e94064-link" class="wh-expand-btn"></span><div class="title"><a href="../api/connapi_intro.html" id="api_protocol-d9713e94064-link"><span class="keyword label">连接器 &amp; API</span></a><div class="wh-tooltip"><p class="shortdesc">面向不同编程语言的 DolphinDB API 及连接器，相关协议和用法</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="chap6_plugin-d9713e94210" class="topicref" data-id="chap6_plugin" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action chap6_plugin-d9713e94210-link" class="wh-expand-btn"></span><div class="title"><a href="../plugins/plg_intro.html" id="chap6_plugin-d9713e94210-link"><span class="keyword label">插件</span></a><div class="wh-tooltip"><p class="shortdesc">多个应用场景的插件使用说明和插件开发指导</p></div></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="third_party-d9713e97904" class="topicref" data-id="third_party" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action third_party-d9713e97904-link" class="wh-expand-btn"></span><div class="title"><a href="../third_party.html" id="third_party-d9713e97904-link">第三方工具</a></div></div></li><li role="treeitem" aria-expanded="true"><div data-tocid="about_tutorials-d9713e98227" class="topicref" data-id="about_tutorials" data-state="expanded"><span role="button" tabindex="0" aria-labelledby="button-collapse-action about_tutorials-d9713e98227-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/about_tutorials.html" id="about_tutorials-d9713e98227-link"><span class="keyword label">教程</span></a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 产品使用教程</p></div></div></div><ul role="group" class="navbar-nav nav-list"><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e98280" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e98280-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/new_users_finance.html" id="tocId-d9713e98280-link">新用户入门</a></div></div></li><li role="treeitem" aria-expanded="true"><div data-tocid="tocId-d9713e98327" class="topicref" data-state="expanded"><span role="button" tabindex="0" aria-labelledby="button-collapse-action tocId-d9713e98327-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/database.html" id="tocId-d9713e98327-link">数据库</a></div></div><ul role="group" class="navbar-nav nav-list"><li role="treeitem" class="active"><div data-tocid="分区数据库设计和操作-d9713e98328" class="topicref" data-id="分区数据库设计和操作" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/database.html" id="分区数据库设计和操作-d9713e98328-link">分区数据库设计和操作</a></div></div></li><li role="treeitem"><div data-tocid="dolphindb-内存表详解-d9713e98374" class="topicref" data-id="dolphindb-内存表详解" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/in_memory_table.html" id="dolphindb-内存表详解-d9713e98374-link">DolphinDB 内存表详解</a></div></div></li><li role="treeitem"><div data-tocid="内存数据表-d9713e98420" class="topicref" data-id="内存数据表" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/partitioned_in_memory_table.html" id="内存数据表-d9713e98420-link">内存数据表</a></div></div></li><li role="treeitem"><div data-tocid="oltp-内存存储引擎非嵌入式版使用教程-d9713e98466" class="topicref" data-id="oltp-内存存储引擎非嵌入式版使用教程" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/oltp_in-memory_storage_engine_non-embedded_version_tutorials.html" id="oltp-内存存储引擎非嵌入式版使用教程-d9713e98466-link">OLTP 内存存储引擎（非嵌入式版）使用教程</a></div></div></li><li role="treeitem"><div data-tocid="利用缓存表快速实现-mysql-库间信息同步-d9713e98512" class="topicref" data-id="利用缓存表快速实现-mysql-库间信息同步" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/cachedtable.html" id="利用缓存表快速实现-mysql-库间信息同步-d9713e98512-link">利用缓存表快速实现 MySQL 库间信息同步</a></div></div></li><li role="treeitem"><div data-tocid="建库建表最容易忽略的十个细节-d9713e98558" class="topicref" data-id="建库建表最容易忽略的十个细节" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/database_and_table_creation_details.html" id="建库建表最容易忽略的十个细节-d9713e98558-link">建库建表最容易忽略的十个细节</a></div></div></li><li role="treeitem"><div data-tocid="redo-log-和-cache-engine-d9713e98604" class="topicref" data-id="redo-log-和-cache-engine" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/redoLog_cacheEngine.html" id="redo-log-和-cache-engine-d9713e98604-link">redo log 和 cache engine</a></div></div></li><li role="treeitem"><div data-tocid="tsdb-存储引擎简介-d9713e98650" class="topicref" data-id="tsdb-存储引擎简介" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/tsdb_engine.html" id="tsdb-存储引擎简介-d9713e98650-link">TSDB 存储引擎简介</a></div></div></li><li role="treeitem"><div data-tocid="tsdb-存储引擎详解-d9713e98696" class="topicref" data-id="tsdb-存储引擎详解" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/tsdb_explained.html" id="tsdb-存储引擎详解-d9713e98696-link">TSDB 存储引擎详解</a></div></div></li><li role="treeitem"><div data-tocid="分布式表数据更新原理和性能-d9713e98742" class="topicref" data-id="分布式表数据更新原理和性能" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/dolphindb_update.html" id="分布式表数据更新原理和性能-d9713e98742-link">分布式表数据更新原理和性能</a></div></div></li><li role="treeitem"><div data-tocid="软删除-d9713e98788" class="topicref" data-id="软删除" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/soft_delete.html" id="软删除-d9713e98788-link">软删除</a></div></div></li><li role="treeitem"><div data-tocid="基于-datax-的-dolphindb-数据导入工具-d9713e98835" class="topicref" data-id="基于-datax-的-dolphindb-数据导入工具" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/datax_writer.html" id="基于-datax-的-dolphindb-数据导入工具-d9713e98835-link">基于 DataX 的 DolphinDB 数据导入工具</a></div></div></li><li role="treeitem"><div data-tocid="debezium--kafka-实时同步-mysql-数据到-dolphindb-d9713e98881" class="topicref" data-id="debezium--kafka-实时同步-mysql-数据到-dolphindb" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/Debezium_and_Kafka_data_sync.html" id="debezium--kafka-实时同步-mysql-数据到-dolphindb-d9713e98881-link">Debezium + Kafka 实时同步 MySQL 数据到 DolphinDB</a></div></div></li><li role="treeitem"><div data-tocid="debeziumkafka-实时同步-oracle-11g-数据到-dolphindb-d9713e98927" class="topicref" data-id="debeziumkafka-实时同步-oracle-11g-数据到-dolphindb" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/Debezium_Kafka_Oracle_sync.html" id="debeziumkafka-实时同步-oracle-11g-数据到-dolphindb-d9713e98927-link">Debezium+Kafka 实时同步 Oracle 11g 数据到 DolphinDB</a></div></div></li><li role="treeitem"><div data-tocid="clear_cache-d9713e98973" class="topicref" data-id="clear_cache" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/clear_cache.html" id="clear_cache-d9713e98973-link">数据库缓存清理机制 </a></div></div></li><li role="treeitem"><div data-tocid="best_practice_for_storage_compute_separation-d9713e99019" class="topicref" data-id="best_practice_for_storage_compute_separation" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/best_practice_for_storage_compute_separation.html" id="best_practice_for_storage_compute_separation-d9713e99019-link">存算分离最佳实践教程</a></div></div></li><li role="treeitem"><div data-tocid="database_and_table_creation_wizard-d9713e99065" class="topicref" data-id="database_and_table_creation_wizard" data-state="leaf"><span role="button" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/database_and_table_creation_wizard.html" id="database_and_table_creation_wizard-d9713e99065-link">DolphinDB Web 界面库表创建指南</a></div></div></li></ul></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e99111" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e99111-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/std_sql_ddb.html" id="tocId-d9713e99111-link">编程</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e100448" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e100448-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming-real-time-correlation-processing_2.html" id="tocId-d9713e100448-link">流数据</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e100955" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e100955-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/scheduledJob_2.html" id="tocId-d9713e100955-link">系统运维</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="模块概述-d9713e101923" class="topicref" data-id="模块概述" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action 模块概述-d9713e101923-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/tu_modules.html" id="模块概述-d9713e101923-link">模块</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e102568" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e102568-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/OHLC_2.html" id="tocId-d9713e102568-link">金融场景案例</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e104827" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e104827-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/streaming_engine_anomaly_alerts_2.html" id="tocId-d9713e104827-link">物联网场景案例</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e105795" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e105795-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/dolphindb_tensor_libtorch_tutorial.html" id="tocId-d9713e105795-link">机器学习</a></div></div></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e105842" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e105842-link" class="wh-expand-btn"></span><div class="title"><a href="../tutorials/api_performance.html" id="tocId-d9713e105842-link">测试报告</a></div></div></li></ul></li><li role="treeitem" aria-expanded="false"><div data-tocid="tocId-d9713e105982" class="topicref" data-state="not-ready"><span role="button" tabindex="0" aria-labelledby="button-expand-action tocId-d9713e105982-link" class="wh-expand-btn"></span><div class="title"><a href="../rn/server/3_00_2.html" id="tocId-d9713e105982-link">版本说明</a><div class="wh-tooltip"><p class="shortdesc">DolphinDB 版本发布历史</p></div></div></div></li></ul></div>
		                        
                            </div>
                        </nav>
                    
                    
                    <div class="col-lg-7 col-md-9 col-sm-12" id="wh_topic_body">
                        <button id="wh_close_publication_toc_button" class="close-toc-button d-none" aria-label="Toggle publishing table of content" aria-controls="wh_publication_toc" aria-expanded="true">
                            <span class="close-toc-icon-container">
                                <span class="close-toc-icon"></span>     
                            </span>
                        </button>
                        <button id="wh_close_topic_toc_button" class="close-toc-button d-none" aria-label="Toggle topic table of content" aria-controls="wh_topic_toc" aria-expanded="true">
                            <span class="close-toc-icon-container">
                                <span class="close-toc-icon"></span>     
                            </span>
                        </button>
                        
                        <div class=" wh_topic_content body "><main role="main"><article class="- topic/topic topic" role="article" aria-labelledby="ariaid-title1"><h1 class="- topic/title title topictitle1" id="ariaid-title1">分区数据库设计和操作</h1><div class="- topic/body body"></div><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title2" id="1-为什么对数据库进行分区"><h2 class="- topic/title title topictitle2" id="ariaid-title2">1. 为什么对数据库进行分区</h2><div class="- topic/body body"><p class="- topic/p p">对数据库进行分区可以显著降低系统响应延迟，提高数据吞吐量。具体来说，分区有以下主要好处。</p><ul class="- topic/ul ul"><li class="- topic/li li">分区使得大型表更易于管理。对数据子集的维护操作也更加高效，因为这些操作只针对需要的数据而不是整个表。一个好的分区策略通过只读取查询所需的相关数据来减少要扫描的数据量。如果分区机制设计不合理，对数据库的查询、计算以及其它操作都可能受到磁盘访问 I/O 这个瓶颈的限制。</li><li class="- topic/li li">分区使得系统可以充分利用所有资源。选择一个良好的分区方案搭配并行计算，分布式计算可以充分利用所有节点来完成通常要在一个节点上完成的任务。若一个任务可以拆分成几个子任务，每个子任务访问不同的分区，可以显著提升效率。</li></ul></div></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title3" id="2-dolphindb-分区和基于-mpp-架构的数据存储的区别"><h2 class="- topic/title title topictitle2" id="ariaid-title3">2. DolphinDB 分区和基于 MPP 架构的数据存储的区别</h2><div class="- topic/body body"><p class="- topic/p p">MPP(Massive Parallel Processing) 是目前主流数据仓库普遍采用的一种方案，包括开源软件 Greenplum，云数据库 AWS Redshift 等。MPP 有一个主节点，每个客户端都连接到这个主节点。DolphinDB 在数据库层面不存在主节点，是点对点结构，每个客户端可以连接到任何一个数据节点，不会出现主节点瓶颈问题。</p><p class="- topic/p p">MPP 一般通过哈希规则，将数据分布到各个节点上（水平分割），在各个节点内部再进行分区（垂直分割）。哈希时容易出现各个节点数据分布不均匀的问题。DolphinDB 将各个节点的存储空间交给内置的分布式文件系统（DFS）统一进行管理，分区的规则与分区的存储位置解耦，数据分割不再按水平和垂直两个步骤进行，而是进行全局优化。这样一来，分区的粒度更细更均匀，在计算时能充分的利用集群的所有计算资源。</p><p class="- topic/p p">由于分布式文件系统具有强大的分区管理、容错、复制机制，以及事务管理机制，DolphinDB 的单表能轻松的支持百万级别的分区。若每个分区有 1GB 的数据，就可实现 PB 级数据的存储和快速查询。另外，通过引入 DFS，数据库的存储和数据库节点相分离，使得 DolphinDB 在集群水平扩展（新增节点）上更加方便。</p><br/><img class="- topic/image image" src="images/distributed_mpp.JPG"/><br/></div></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title4" id="3-分区类型"><h2 class="- topic/title title topictitle2" id="ariaid-title4">3. 分区类型</h2><div class="- topic/body body"><p class="- topic/p p">DolphinDB database 支持多种分区类型：范围分区、哈希分区、值分区、列表分区与复合分区。选择合适的分区类型，有助于用户根据业务特点对数据进行均匀分割。</p><ul class="- topic/ul ul"><li class="- topic/li li">范围分区对每个分区区间创建一个分区。</li><li class="- topic/li li">哈希分区利用哈希函数对分区列操作，方便建立指定数量的分区。</li><li class="- topic/li li">值分区每个值创建一个分区，例如股票交易日期、股票交易月等。</li><li class="- topic/li li">列表分区是根据用户枚举的列表来进行分区，比值分区更加灵活。</li><li class="- topic/li li">复合分区适用于数据量特别大而且 SQL where 或 group by 语句经常涉及多列。可使用 2 个或 3 个分区列，每个分区选择都可以采用区间、值、哈希或列表分区。例如按股票交易日期进行值分区，同时按股票代码进行范围分区。</li></ul><p class="- topic/p p">创建一个新的分布式数据库时，需要在<code class="+ topic/ph pr-d/codeph ph codeph">database</code>函数中指定数据库路径 directory，分区类型 partitionType 以及分区模式 partitionScheme。重新打开已有的分布式数据库时，只需指定数据库路径。不允许用不同的分区类型或分区方案覆盖已有的分布式数据库。</p><p class="- topic/p p">聚合函数在分区表上利用分区列操作时，例如当 group by 列与分区列一致时，运行速度特别快。</p><p class="- topic/p p">为了学习方便，以下分区例子使用 Windows 本地目录，用户可以将数据库创建使用的路径改成 Linux 或 DFS 目录。</p><p class="- topic/p p">调用 database 函数前，用户必须先登录，只有具有 DB_OWNER 或 admin 管理员权限才能创建数据库。默认的 admin 管理员登录脚本为：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>login(userId=`admin, password=`123456)</code></pre><p class="- topic/p p">下文提供的所有创建数据库脚本，默认已经登录。</p></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title5" id="31-范围-range-分区"><h3 class="- topic/title title topictitle3" id="ariaid-title5">3.1. 范围 (RANGE) 分区</h3><div class="- topic/body body"><p class="- topic/p p">在范围分区中，分区由区间决定，而区间由分区向量的任意两个相邻元素定义。区间包含起始值，但不包含结尾值。</p><p class="- topic/p p">在下面的例子中，数据库 db 有两个分区：[0,5) 和[5,10)。使用 ID 作为分区列，并使用函数 <code class="+ topic/ph pr-d/codeph ph codeph">append!</code> 在数据库 db 中保存表 t 为分区表 pt。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">n=<span class="hl-number">1000000</span>
ID=rand(<span class="hl-number">10</span>, n)
x=rand(<span class="hl-number">1.0</span>, n)
t=table(ID, x)
db=database(<span class="hl-string">"dfs://rangedb"</span>, RANGE,  <span class="hl-number">0</span> <span class="hl-number">5</span> <span class="hl-number">10</span>)

pt = db.createPartitionedTable(t, `pt, `ID)
pt.append!(t)

pt=loadTable(db,`pt)
select count(x) <strong class="hl-keyword">from</strong> pt;</pre><p class="- topic/p p">磁盘目录结构</p><br/><img class="- topic/image image" src="images/database/range.png"/><br/><p class="- topic/p p">范围分区创建后，可使用<code class="+ topic/ph pr-d/codeph ph codeph">addRangePartitions</code>函数来追加分区。细节参见用户手册。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title6" id="32-哈希-hash-分区"><h3 class="- topic/title title topictitle3" id="ariaid-title6">3.2. 哈希 (HASH) 分区</h3><div class="- topic/body body"><p class="- topic/p p">哈希分区对分区列使用哈希函数以产生分区。哈希分区是产生指定数量的分区的一个简便方法。但是要注意，哈希分区不能保证分区的大小一致，尤其当分区列的值的分布存在偏态的时候。此外，若要查找分区列中一个连续范围的数据时，哈希分区的效率比范围分区或值分区要低。</p><p class="- topic/p p">在下面的例子中，数据库 db 有两个分区。使用 ID 作为分区列，并使用函数<code class="+ topic/ph pr-d/codeph ph codeph">append!</code>在数据库 db 中保存表 t 为分区表 pt。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">n=<span class="hl-number">1000000</span>
ID=rand(<span class="hl-number">10</span>, n)
x=rand(<span class="hl-number">1.0</span>, n)
t=table(ID, x)
db=database(<span class="hl-string">"dfs://hashdb"</span>, HASH,  [INT, <span class="hl-number">2</span>])

pt = db.createPartitionedTable(t, `pt, `ID)
pt.append!(t)

pt=loadTable(db,`pt)
select count(x) <strong class="hl-keyword">from</strong> pt;</pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title7" id="33--值-value-分区"><h3 class="- topic/title title topictitle3" id="ariaid-title7">3.3.  值 (VALUE) 分区</h3><div class="- topic/body body"><p class="- topic/p p">在值域（VALUE）分区中，一个值代表一个分区。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">n=<span class="hl-number">1000000</span>
month=take(<span class="hl-number">2000.01</span>M.<span class="hl-number">.2016</span>.<span class="hl-number">12</span>M, n)
x=rand(<span class="hl-number">1.0</span>, n)
t=table(month, x)

db=database(<span class="hl-string">"dfs://valuedb"</span>, VALUE, <span class="hl-number">2000.01</span>M.<span class="hl-number">.2016</span>.<span class="hl-number">12</span>M)

pt = db.createPartitionedTable(t, `pt, `month)
pt.append!(t)

pt=loadTable(db,`pt)
select count(x) <strong class="hl-keyword">from</strong> pt;</pre><p class="- topic/p p">上面的例子定义了一个具有 204 个分区的数据库 db。每个分区是 2000 年 1 月到 2016 年 12 月之间的一个月 (如下图）。在数据库 db 中，表 t 被保存为分区表 pt，分区列为 month。</p><br/><img class="- topic/image image" src="images/database/value.png"/><br/><p class="- topic/p p">在默认配置（newValuePartitionPolicy=add）情况下，无需手动添加新的分区，当写入数据时，会自动增加对应分区。如本例中，2017年01月的数据写入时，会自动创建201701M这个分区。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title8" id="34-列表-list-分区"><h3 class="- topic/title title topictitle3" id="ariaid-title8">3.4. 列表 (LIST) 分区</h3><div class="- topic/body body"><p class="- topic/p p">在列表（LIST）分区中，我们用一个包含多个元素的列表代表一个分区。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">n=<span class="hl-number">1000000</span>
ticker = rand(`MSFT`GOOG`FB`ORCL`IBM,n)
x=rand(<span class="hl-number">1.0</span>, n)
t=table(ticker, x)

db=database(<span class="hl-string">"dfs://listdb"</span>, LIST, [`IBM`ORCL`MSFT, `GOOG`FB])
pt = db.createPartitionedTable(t, `pt, `ticker)
pt.append!(t)

pt=loadTable(db,`pt)
select count(x) <strong class="hl-keyword">from</strong> pt;</pre><p class="- topic/p p">上面的数据库有 2 个分区。第一个分区包含 3 个股票代号，第二个分区包含 2 个股票代号。</p><br/><img class="- topic/image image" src="images/database/list.png"/><br/></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title9" id="35-组合-compo-分区"><h3 class="- topic/title title topictitle3" id="ariaid-title9">3.5. 组合 (COMPO) 分区</h3><div class="- topic/body body"><p class="- topic/p p">组合（COMPO）分区可以定义 2 或 3 个分区列。每列可以独立采用范围 (RANGE)、值 (VALUE)、哈希 (HASH) 或列表 (LIST) 分区。组合分区的多个列在逻辑上是并列的，不存在从属关系或优先级关系。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">n=<span class="hl-number">1000000</span>
ID=rand(<span class="hl-number">100</span>, n)
dates=<span class="hl-number">2017.08</span>.<span class="hl-number">07.</span><span class="hl-number">.2017</span>.<span class="hl-number">08.11</span>
date=rand(dates, n)
x=rand(<span class="hl-number">10.0</span>, n)
t=table(ID, date, x)

dbDate = database(, VALUE, <span class="hl-number">2017.08</span>.<span class="hl-number">07.</span><span class="hl-number">.2017</span>.<span class="hl-number">08.11</span>)
dbID=database(, RANGE, <span class="hl-number">0</span> <span class="hl-number">50</span> <span class="hl-number">100</span>)
db = database(<span class="hl-string">"dfs://compoDB"</span>, COMPO, [dbDate, dbID])

pt = db.createPartitionedTable(t, `pt, `date`ID)
pt.append!(t)

pt=loadTable(db,`pt)
select count(x) <strong class="hl-keyword">from</strong> pt;</pre><p class="- topic/p p">值域有 5 个分区：</p><br/><img class="- topic/image image" src="images/database/hier1.png"/><br/><p class="- topic/p p">在 20170807 这个分区中，有 2 个区间域 (RANGE) 分区：</p><br/><img class="- topic/image image" src="images/database/hier2.png"/><br/><p class="- topic/p p">若组合分区有一列为值分区，创建后可使用<code class="+ topic/ph pr-d/codeph ph codeph">addValuePartitions</code>函数来追加分区。细节参见用户手册。</p></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title10" id="4-分区设计注意事项"><h2 class="- topic/title title topictitle2" id="ariaid-title10">4. 分区设计注意事项</h2><div class="- topic/body body"><p class="- topic/p p">分区的总原则是让数据管理更加高效，提高查询和计算的性能，达到低延时和高吞吐量。下面是设计和优化分区表的需要考虑的因素，以供参考。</p></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title11" id="41-选择合适的分区字段"><h3 class="- topic/title title topictitle3" id="ariaid-title11">4.1. 选择合适的分区字段</h3><div class="- topic/body body"><p class="- topic/p p">在 DolphinDB 中，可以用于分区的数据类型包括整型 (CHAR, SHORT, INT)，日期类型 (DATE, MONTH, TIME, MINUTE, SECOND, DATETIME, DATEHOUR)，以及 STRING 与 SYMBOL。除此之外，哈希分区还支持 LONG, UUID, IPADDR, INT128 类型。虽然 STRING 可作为分区列，但为了性能考虑，建议将 STRING 转化为 SYMBOL 再用于分区列。</p><p class="- topic/p p">FLOAT 和 DOUBLE 数据类型不可作为分区字段。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">db=database(<span class="hl-string">"dfs://rangedb1"</span>, RANGE,  <span class="hl-number">0.0</span> <span class="hl-number">5.0</span> <span class="hl-number">10.0</span>)</pre><p class="- topic/p p">会产生出错信息：DOUBLE 数据类型的字段不能作为分区字段</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">The data type DOUBLE can<span class="hl-string">'t be used for a partition column</span></pre><p class="- topic/p p">虽然 DolphinDB 支持对 TIME, SECOND, DATETIME 类型字段的分区，但是在实际使用中要尽量避免对这些数据类型采用值分区，以免分区粒度过细，将耗费大量时间创建或查询百万级以上的很小的分区。例如下面这个例子就会产生过多的分区。序列：2012.06.01T09:30:00..2012.06.30T16:00:00 包含 2,529,001 个元素。如果用这个序列进行值分区，将会在磁盘上产生 2,529,001 个分区，即 2,529,001 个文件目录和相关文件，从而使得分区表创建、写入、查询都非常缓慢。</p><p class="- topic/p p">分区字段应当在业务中，特别是数据更新的任务中有重要相关性。譬如在证券交易领域，许多任务都与股票交易日期或股票代码相关，因此以这两个字段来分区比较合理。更新数据库时，DolphinDB 的事务机制（在 5.2 中会提到）不允许多个 writer 的事务在分区上有重叠。鉴于经常需要对某个交易日或某只股票的数据进行更新，若采用其它分区字段（例如交易时刻），有可能造成多个 writer 同时对同一分区进行写入而导致问题。</p><p class="- topic/p p">一个分区字段相当于数据表的一个物理索引。如果查询时用到了该字段做数据过滤，SQL 引擎就能快速定位需要的数据块，而无需对整表进行扫描，从而大幅度提高处理速度。因此，分区字段应当选用查询和计算时经常用到的过滤字段。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title12" id="42-分区粒度不要过大"><h3 class="- topic/title title topictitle3" id="ariaid-title12">4.2. 分区粒度不要过大</h3><div class="- topic/body body"><p class="- topic/p p">一个分区内的多个列以文件形式独立存储在磁盘上，通常数据是经过压缩的。使用的时候，系统从磁盘读取所需要的列，解压后加载到内存。若分区粒度过大，可能会造成多个工作线程并行时内存不足，或者导致系统频繁地在磁盘和工作内存之间切换，影响性能。一个经验公式是，若数据节点的可用内存是 S，工作线程（worker）的的数量是 W，建议每个分区解压后在内存中的大小不超过 S/8W。假设工作内存上限为 32GB，并有 8 个工作线程，建议单个分区解压后的大小不超过 512MB。</p><p class="- topic/p p">DolphinDB 的子任务以分区为单位。因此分区粒度过大会造成无法有效利用多节点多分区的优势，将本来可以并行计算的任务转化成了顺序计算任务。</p><p class="- topic/p p">DolphinDB 是为 OLAP 的场景优化设计的，支持添加数据，不支持对个别行进行删除或更新。如果要修改数据，需以分区为单位替换全部数据。如果分区过大，会降低效率。DolphinDB 在节点之间复制副本数据时，同样以分区为单位，若分区过大，则不利于数据在节点之间的复制。</p><p class="- topic/p p">综上各种因素，建议一个分区未压缩前的原始数据大小不超过 1GB。当然这个限制可结合实际情况调整。譬如在大数据应用中，经常有宽表设计，一个表有几百个字段，但是单个应用只会使用一部分字段。这种情况下，可以适当放大上限的范围。</p><p class="- topic/p p">降低分区粒度可采用以下几种方法：（1）采用组合分区 (COMPO)；（2）增加分区个数；（3）将范围分区改为值分区。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title13" id="43-分区粒度不要过小"><h3 class="- topic/title title topictitle3" id="ariaid-title13">4.3. 分区粒度不要过小</h3><div class="- topic/body body"><p class="- topic/p p">若分区粒度过小，一个查询和计算作业往往会生成大量的子任务，这会增加数据节点和控制节点，以及控制节点之间的通讯和调度成本。分区粒度过小，也会造成很多低效的磁盘访问（小文件读写)，造成系统负荷过重。另外，所有的分区的元数据都会驻留在控制节点的内存中。分区粒度过小，分区数过多，可能会导致控制节点内存不足。我们建议每个分区未压缩前的数据量不要小于 100M。</p><p class="- topic/p p">综合前述，推荐分区大小控制在 100MB 到 1GB 之间。</p><p class="- topic/p p">股票的高频交易数据若按交易日期和股票代码的值做组合分区，会导致许多极小的分区，因为许多交易不活跃的股票的交易数据量太少。如果将股票代码的维度按照范围分区的方法来切分数据，将多个交易不活跃的股票组合在一个分区内，则可以有效解决分区粒度过小的问题，提高系统的性能。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title14" id="44-如何将数据均匀分区"><h3 class="- topic/title title topictitle3" id="ariaid-title14">4.4. 如何将数据均匀分区</h3><div class="- topic/body body"><p class="- topic/p p">当各个分区的数据量差异很大时，会造成系统负荷不均衡，部分节点任务过重，而其它节点处于闲置等待状态。当一个任务有多个子任务时，只有最后一个子任务完成了，才会将结果返回给用户。由于一个子任务对应一个分区，如果数据分布不均匀，可能会增大作业延时，影响用户体验。</p><p class="- topic/p p">为了方便根据数据的分布进行分区，DolphinDB 提供了函数<code class="+ topic/ph pr-d/codeph ph codeph">cutPoints(X, N, [freq])</code>。这里 X 是一个数组，N 指需要产生多少组，而 freq 是 X 的等长数组，其中每个元素对应着 X 中元素出现的频率。函数返回具有 (N + 1) 个元素的数组，代表 N 个组，使得 X 中的数据均匀地分布在这 N 个组中。</p><p class="- topic/p p">下面的例子中，需要对股票的报价数据按日期和股票代码两个维度做数据分区。如果简单的按股票的首字母进行范围分区，极易造成数据分布不均，因为极少量的股票代码以 U, V, X，Y，Z 等字母开头。我们这里使用<code class="+ topic/ph pr-d/codeph ph codeph">cutPoints</code>函数将 2020 年 10 月 01 日到 2020 年 10 月 29 日的数据根据股票代码划为 5 个分区，</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">dates=<span class="hl-number">2020.10</span>.<span class="hl-number">01.</span><span class="hl-number">.2020</span>.<span class="hl-number">10.29</span>;
syms=<span class="hl-string">"A"</span>+string(<span class="hl-number">1.</span><span class="hl-number">.13</span>);
syms.append!(string(<span class="hl-string">'B'</span>..<span class="hl-string">'Z'</span>));
buckets=cutPoints(syms,<span class="hl-number">5</span>);//cutpoints
t1=table(take(syms,<span class="hl-number">10000</span>) <strong class="hl-keyword">as</strong> stock, rand(dates,<span class="hl-number">10000</span>) <strong class="hl-keyword">as</strong> date, rand(<span class="hl-number">10.0</span>,<span class="hl-number">10000</span>) <strong class="hl-keyword">as</strong> x);
dateDomain = database(<span class="hl-string">""</span>, VALUE, dates);
symDomain = database(<span class="hl-string">""</span>, RANGE, buckets);
stockDB = database(<span class="hl-string">"dfs://stockDBTest"</span>, COMPO, [dateDomain, symDomain]);
pt = stockDB.createPartitionedTable(t1, `pt, `date`stock).append!(t1);</pre><p class="- topic/p p">除了使用范围分区的方法，列表分区也是解决数据分布不均匀的有效方法。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title15" id="45-时序类型分区"><h3 class="- topic/title title topictitle3" id="ariaid-title15">4.5. 时序类型分区</h3><div class="- topic/body body"><p class="- topic/p p">时间是实际数据中最常见的一个维度。DolphinDB 提供了丰富时间类型以满足用户的需求。当我们以时间类型字段作为分区字段时，在时间取值上可以预留分区以容纳未来的数据。下面的例子，我们创建一个数据库，以天为单位，将 2000.01.01 到 2030.01.01 的日期分区。注意，只有当实际数据写入数据库时，数据库才会真正创建需要的分区。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">dateDB = database(<span class="hl-string">"dfs://testDate"</span>, VALUE, <span class="hl-number">2000.01</span>.<span class="hl-number">01</span> .. <span class="hl-number">2030.01</span>.<span class="hl-number">01</span>)</pre><p class="- topic/p p">DolphinDB 使用时间类型作为分区字段时，还有一个特殊的优点。数据库定义的分区字段类型和数据表实际采用的时间类型可以不一致，只要保证定义的分区字段数据类型精度小于等于实际数据类型即可。比如说，如果数据库是按月（month）分区，数据表的字段可以是 month, date, datetime, timestamp 和 nanotimestamp。系统自动会作数据类型的转换。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title16" id="46-不同表相同分区的数据存于同一节点"><h3 class="- topic/title title topictitle3" id="ariaid-title16">4.6. 不同表相同分区的数据存于同一节点</h3><div class="- topic/body body"><p class="- topic/p p">在分布式数据库中，如果多个分区的数据表要连接（join）通常十分耗时，因为涉及到的分区可能在不同的节点上，需要在不同节点之间复制数据。为解决这个问题，DolphinDB 推出了共存储位置的分区机制，确保同一个分布式数据库里所有表在相同分区的数据存储在相同的节点上。这样的安排，保证了这些表在连接的时候非常高效。DolphinDB 当前版本对采用不同分区机制的多个分区表不提供连接功能。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">dateDomain = database(<span class="hl-string">""</span>, VALUE, <span class="hl-number">2018.05</span>.<span class="hl-number">01.</span><span class="hl-number">.2018</span>.<span class="hl-number">07.01</span>)
symDomain = database(<span class="hl-string">""</span>, RANGE, string(<span class="hl-string">'A'</span>..<span class="hl-string">'Z'</span>) join `ZZZZZ)
stockDB = database(<span class="hl-string">"dfs://stockDB"</span>, COMPO, [dateDomain, symDomain])

quoteSchema = table(<span class="hl-number">10</span>:<span class="hl-number">0</span>, `sym`date`time`bid`bidSize`ask`askSize, [SYMBOL,DATE,TIME,DOUBLE,INT,DOUBLE,INT])
stockDB.createPartitionedTable(quoteSchema, <span class="hl-string">"quotes"</span>, `date`sym)

tradeSchema = table(<span class="hl-number">10</span>:<span class="hl-number">0</span>, `sym`date`time`price`vol, [SYMBOL,DATE,TIME,DOUBLE,INT])
stockDB.createPartitionedTable(tradeSchema, <span class="hl-string">"trades"</span>, `date`sym)</pre><p class="- topic/p p">上面的例子中，quotes 和 trades 两个分区表采用同一个分区机制。</p></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title17" id="5-导入数据到分布式数据表"><h2 class="- topic/title title topictitle2" id="ariaid-title17">5. 导入数据到分布式数据表</h2><div class="- topic/body body"><p class="- topic/p p">DolphinDB 是为 OLAP 设计的系统，主要是解决海量结构化数据的快速存储和计算，以及通过内存数据库和流数据计算引擎实现高性能的数据处理。DolphinDB 不适合数据频繁更改的 OLTP 业务系统。DolphinDB 的数据写入与 Hadoop HDFS 类似，快速在每个分区或文件的末尾批量插入数据。插入的数据会压缩存储到磁盘，一般压缩比例在 20%~25%。数据一旦追加到基于磁盘的数据表后，不能快速更新或删除某些符合条件的记录，必须以分区为单位对数据表进行修改。这也是分区原则中提到单个分区不宜过大的原因之一。</p></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title18" id="51-多副本机制"><h3 class="- topic/title title topictitle3" id="ariaid-title18">5.1. 多副本机制</h3><div class="- topic/body body"><p class="- topic/p p">DolphinDB 允许为每一个分区保留多个副本，默认的副本个数是 2，可以修改控制节点的参数 dfsReplicationFactor 来设置副本数量。</p><p class="- topic/p p">设置冗余数据的目的有两个：
（1）当某个数据节点失效或者或磁盘数据损坏时，系统提供容错功能继续提供服务；
（2）当大量并发用户访问时，多副本提供负载均衡的功能，提高系统吞吐量，降低访问延时。</p><p class="- topic/p p">DolphinDB 通过两阶段事务提交机制，确保数据写入时，同一副本在多节点之间的数据强一致性。</p><p class="- topic/p p">在控制节点的参数文件 controller.cfg 中，还有一个非常重要的参数 dfsReplicaReliabilityLevel。该参数决定是否允许多个副本驻留在同一台物理服务器的多个数据节点上。在开发阶段，可允许在一个机器上配置多个节点，同时允许多个副本驻留在同一台物理服务器（dfsReplicaReliabilityLevel=0），但是在生产阶段需要设置成为 1，否则起不到容错备份的作用。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title19" id="52-事务机制"><h3 class="- topic/title title topictitle3" id="ariaid-title19">5.2. 事务机制</h3><div class="- topic/body body"><p class="- topic/p p">DolphinDB 对基于磁盘（分布式文件系统）的数据库表的读写支持事务，也就是说确保事务的原子性，一致性，隔离性和持久化。DolphinDB 采用多版本机制实现快照级别的隔离。在这种隔离机制下，数据的读操作和写操作互相不阻塞，可以最大程度优化数据仓库读的性能。</p><p class="- topic/p p">为了最大程度优化数据仓库查询、分析、计算的性能，DolphinDB 对事务作了一些限制：</p><ul class="- topic/ul ul"><li class="- topic/li li">首先，一个事务只能包含写或者读，不能同时进行写和读。</li><li class="- topic/li li">其次，一个写事务可以跨越多个分区，但当通过 database 建库且设置参数 atomic='TRANS'，则同一个分区不能被多个 writer 并发写入。当一个分区被某一个事务 A 锁定之后，另一个事务 B 试图再次去锁定这个分区时，系统立刻会抛出异常导致事务 B 失败回滚。当设置 atomic='CHUNK'时，无此限制。</li></ul></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title20" id="53-多-writer-并行写入"><h3 class="- topic/title title topictitle3" id="ariaid-title20">5.3. 多 Writer 并行写入</h3><div class="- topic/body body"><p class="- topic/p p">DolphinDB 中，单个数据表可有几百万个分区，这为高性能的并行数据加载创造了条件。特别是将海量数据从其它系统导入 DolphinDB 时，或者需要将实时数据以准实时的方式写入数据仓库时，并行加载对于性能尤为重要。</p><p class="- topic/p p">下面的例子将股票报价数据（quotes）并行加载到基于日期和股票代码的复合分区数据库 stockDB。数据存储在<a class="- topic/xref xref" href="data/database/quotes.zip">csv 文件</a>中，每个文件保存一天的报价数据。对每个文件，通过文件名产生 jobId 前缀，并通过命令<code class="+ topic/ph pr-d/codeph ph codeph">submitJob</code>提交后台程序调用<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>函数将数据加载到 stockDB 数据库中。通过<code class="+ topic/ph pr-d/codeph ph codeph">pnodeRun</code>将上述任务发送到集群的每个数据节点进行并行加载。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">dateDomain = database(<span class="hl-string">""</span>, VALUE, <span class="hl-number">2018.05</span>.<span class="hl-number">01.</span><span class="hl-number">.2018</span>.<span class="hl-number">07.01</span>)
symDomain = database(<span class="hl-string">""</span>, RANGE, string(<span class="hl-string">'A'</span>..<span class="hl-string">'Z'</span>) join `ZZZZZ)
stockDB = database(<span class="hl-string">"dfs://stockDB"</span>, COMPO, [dateDomain, symDomain])
quoteSchema = table(<span class="hl-number">10</span>:<span class="hl-number">0</span>, `sym`date`time`bid`bidSize`ask`askSize, [SYMBOL,DATE,TIME,DOUBLE,INT,DOUBLE,INT])
stockDB.createPartitionedTable(quoteSchema, <span class="hl-string">"quotes"</span>, `date`sym)

<strong class="hl-keyword">def</strong> loadJob(){
	fileDir=<span class="hl-string">'/stockData'</span>
	filenames = <strong class="hl-keyword">exec</strong> filename <strong class="hl-keyword">from</strong> files(fileDir)
	db = database(<span class="hl-string">"dfs://stockDB"</span>)

	<strong class="hl-keyword">for</strong>(fname <strong class="hl-keyword">in</strong> filenames){
		jobId = fname.strReplace(<span class="hl-string">".csv"</span>, <span class="hl-string">""</span>)
		submitJob(jobId,, loadTextEx{db, <span class="hl-string">"quotes"</span>, `date`sym, fileDir+<span class="hl-string">'/'</span>+fname})
	}
}

pnodeRun(loadJob);</pre><p class="- topic/p p"><strong class="+ topic/ph hi-d/b ph b">在上面的例子中，database 的参数使用默认值（atomic='TRANS'），若多个 writer 并行加载数据，则需要确保这些 writer 不会同时往同一个分区写入数据，否则会导致事务失败</strong>。在上面的例子中，每一个文件存储了一天的数据，而 quotes 表的一个分区字段是日期，从而确保所有加载数据的作业不会产生有重叠的事务。</p></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title21" id="54-数据导入的常用方法"><h3 class="- topic/title title topictitle3" id="ariaid-title21">5.4. 数据导入的常用方法</h3><div class="- topic/body body"><p class="- topic/p p">DolphinDB 的分布式数据库提供标准方法<code class="+ topic/ph pr-d/codeph ph codeph">append!</code>函数批量追加数据到到数据库。各种数据导入方法实际上就是直接或间接的调用这个函数将数据写入到数据库。后面的所有例子，都使用 5.4 中创建的 stockDB 的 quotes 表。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">n = <span class="hl-number">1000000</span>
syms = `IBM`MSFT`GM`C`FB`GOOG`V`F`XOM`AMZN`TSLA`PG`S
time = <span class="hl-number">09</span>:<span class="hl-number">30</span>:<span class="hl-number">00</span> + rand(<span class="hl-number">21600000</span>, n)
bid = rand(<span class="hl-number">10.0</span>, n)
bidSize = <span class="hl-number">1</span> + rand(<span class="hl-number">100</span>, n)
ask = rand(<span class="hl-number">10.0</span>, n)
askSize = <span class="hl-number">1</span> + rand(<span class="hl-number">100</span>, n)
quotes = table(rand(syms, n) <strong class="hl-keyword">as</strong> sym, take(<span class="hl-number">2018.05</span>.<span class="hl-number">04.</span><span class="hl-number">.2018</span>.<span class="hl-number">05.11</span>,n) <strong class="hl-keyword">as</strong> date, time, bid, bidSize, ask, askSize)

loadTable(<span class="hl-string">"dfs://stockDB"</span>, <span class="hl-string">"quotes"</span>).append!(quotes);</pre></div><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title22" id="541-从文本文件导入数据"><h4 class="- topic/title title topictitle4" id="ariaid-title22">5.4.1. 从文本文件导入数据</h4><div class="- topic/body body"><p class="- topic/p p">DolphinDB 提供三个函数<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>，<code class="+ topic/ph pr-d/codeph ph codeph">ploadText</code>和<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>加载文本数据。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">workDir = <span class="hl-string">"C:/DolphinDB/Data"</span>
<strong class="hl-keyword">if</strong>(!exists(workDir)) mkdir(workDir)
quotes.saveText(workDir + <span class="hl-string">"/quotes.csv"</span>)
quotes.saveText(workDir + <span class="hl-string">"/quotes_new.csv"</span>)</pre><p class="- topic/p p">使用<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>或<code class="+ topic/ph pr-d/codeph ph codeph">ploadText</code>将数据从文件加载到内存，然后再调用<code class="+ topic/ph pr-d/codeph ph codeph">append!</code>函数。这种方法适合于数据量小于物理内存的情况，因为数据将被全部导入内存。 <code class="+ topic/ph pr-d/codeph ph codeph">ploadText</code>和<code class="+ topic/ph pr-d/codeph ph codeph">loadText</code>的区别在于前者采用并行方法加载文本文件。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">t=loadText(workDir + <span class="hl-string">"/quotes_new.csv"</span>)
loadTable(<span class="hl-string">"dfs://stockDB"</span>, <span class="hl-string">"quotes"</span>).append!(t)
</pre><p class="- topic/p p"><code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>直接将文本数据导入到数据库分区表，是 DolphinDB 推荐使用的加载文本数据的方法。它的优点是：并行处理速度快，而且文件尺寸可远远大于物理内存。<code class="+ topic/ph pr-d/codeph ph codeph">loadTextEx</code>运行时，帮助用户调用了<code class="+ topic/ph pr-d/codeph ph codeph">append!</code>函数。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">db = database(<span class="hl-string">"dfs://stockDB"</span>)
loadTextEx(db, <span class="hl-string">"quotes"</span>, `date`sym, workDir + <span class="hl-string">"/quotes.csv"</span>)</pre></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title23" id="542-订阅一个流数据批量写入"><h4 class="- topic/title title topictitle4" id="ariaid-title23">5.4.2. 订阅一个流数据，批量写入</h4><div class="- topic/body body"><p class="- topic/p p">DolphinDB 支持流数据的处理。用户可以订阅一个流数据，将订阅到的流数据批量写入到分布式表中。详细内容，请参阅帮助文档关于流计算的部分。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">dfsQuotes = loadTable(<span class="hl-string">"dfs://stockDB"</span>, <span class="hl-string">"quotes"</span>)
saveQuotesToDFS=<strong class="hl-keyword">def</strong>(mutable t, msg): t.append!(select today() <strong class="hl-keyword">as</strong> date,* <strong class="hl-keyword">from</strong> msg)
subscribeTable(, <span class="hl-string">"quotes_stream"</span>, <span class="hl-string">"quotes"</span>, -<span class="hl-number">1</span>, saveQuotesToDFS{dfsQuotes}, true, <span class="hl-number">10000</span>, <span class="hl-number">6</span>)</pre><p class="- topic/p p">上面的例子中，我们订阅了流数据表 quotes_stream，等待时间超过 6 秒或缓存的 quotes 记录达到 1 万条，批量写入到分布式表 dfs://stockDB/quotes 中。</p></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title24" id="543-通过-odbc-导入数据"><h4 class="- topic/title title topictitle4" id="ariaid-title24">5.4.3. 通过 ODBC 导入数据</h4><div class="- topic/body body"><p class="- topic/p p">用户也可以通过 ODBC Plugin，将其它数据源中的数据导入到 DolphinDB 中。下面例子通过 ODBC 将 mysql 中的 quotes 表导入到 DolphinDB。</p><p class="- topic/p p">下载插件解压并拷贝 plugins/odbc 目录下所有文件到 DolphinDB server/plugins/odbc 目录下。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">loadPlugin(<span class="hl-string">"plugins/odbc/odbc.cfg"</span>)
conn=odbc::connect(<span class="hl-string">"Driver=MySQL;Data Source = mysql-stock;server=127.0.0.1;uid=[xxx];pwd=[xxx];database=stockDB"</span>)
t=odbc::query(conn,<span class="hl-string">"select * from quotes"</span>)
loadTable(<span class="hl-string">"dfs://stockDB"</span>, <span class="hl-string">"quotes"</span>).append!(t)</pre></div></article><article class="- topic/topic topic nested3" aria-labelledby="ariaid-title25" id="544-通过-programming-api-导入数据"><h4 class="- topic/title title topictitle4" id="ariaid-title25">5.4.4. 通过 Programming API 导入数据</h4><div class="- topic/body body"><p class="- topic/p p">DolphinDB 提供了 Python, Java, C++, C#, R 以及 JavaScript 的编程接口。用户可在这些系统中准备好数据，然后调用<code class="+ topic/ph pr-d/codeph ph codeph">append!</code>函数，将数据导入到 DolphinDB 的分布式表。下面我们以 Java 为例，给出核心的代码。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">DBConnection conn = new DBConnection();</pre><p class="- topic/p p">连接并登录到 DolphnDB 服务器：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">conn.connect(<span class="hl-string">"localhost"</span>, <span class="hl-number">8848</span>, <span class="hl-string">"admin"</span>, <span class="hl-string">"123456"</span>);</pre><p class="- topic/p p">定义函数 saveQuotes：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">conn.run(<span class="hl-string">"def saveQuotes(t){ loadTable('dfs://stockDB','quotes').append!(t)}"</span>);</pre><p class="- topic/p p">准备一个数据表，具体过程省略：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">BasicTable quotes = ...</pre><p class="- topic/p p">调用服务端函数 saveQuotes：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">List&lt;Entity&gt; args = new ArrayList&lt;Entity&gt;(<span class="hl-number">1</span>);
args.add(quotes);
conn.run(<span class="hl-string">"saveQuotes"</span>, args);</pre></div></article></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title26" id="6-数据重分区和复制-dfs-表"><h2 class="- topic/title title topictitle2" id="ariaid-title26">6. 数据重分区和复制 DFS 表</h2><div class="- topic/body body"></div><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title27" id="61-数据重分区"><h3 class="- topic/title title topictitle3" id="ariaid-title27">6.1. 数据重分区</h3><div class="- topic/body body"><p class="- topic/p p">数据库的分区类型和分区方案一旦确定以后，就不能修改。如果要对数据重新分区，需要新建一个数据库，然后把原数据库中的数据导入到新数据库中。</p><p class="- topic/p p">例如，假设有一个组合分区的数据库 dfs://db1，第一层是按天分区，第二层根据股票代码范围划分为 30 个分区，创建数据库的代码如下：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">login(<span class="hl-string">"admin"</span>,<span class="hl-string">"123456"</span>)
t=table(<span class="hl-number">1</span>:<span class="hl-number">0</span>,`timestamp`sym`qty`price,[TIMESTAMP,SYMBOL,DOUBLE,DOUBLE])
dates=<span class="hl-number">2010.01</span>.<span class="hl-number">01.</span><span class="hl-number">.2020</span>.<span class="hl-number">12.31</span>
syms=<span class="hl-string">"A"</span>+string(<span class="hl-number">1.</span><span class="hl-number">.500</span>)
sym_ranges=cutPoints(syms,<span class="hl-number">30</span>)
db1=database(<span class="hl-string">""</span>,VALUE,dates)
db2=database(<span class="hl-string">""</span>,RANGE,sym_ranges)
db=database(<span class="hl-string">"dfs://db1"</span>,COMPO,[db1,db2])
db.createPartitionedTable(t,`tb1,`timestamp`sym)</pre><p class="- topic/p p">现在要把以上数据库中的数据导入到新的数据库 dfs://db2 中。新数据库是组合分区，第一层依然是按天分区，第二层按照股票代码范围划分为 50 个分区，创建数据库的代码如下：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">login(<span class="hl-string">"admin"</span>,<span class="hl-string">"123456"</span>)
t=table(<span class="hl-number">1</span>:<span class="hl-number">0</span>,`timestamp`sym`qty`price,[TIMESTAMP,SYMBOL,DOUBLE,DOUBLE])
dates=<span class="hl-number">2010.01</span>.<span class="hl-number">01.</span><span class="hl-number">.2020</span>.<span class="hl-number">12.31</span>
syms=<span class="hl-string">"A"</span>+string(<span class="hl-number">1.</span><span class="hl-number">.500</span>)
sym_ranges=cutPoints(syms,<span class="hl-number">50</span>)
db1=database(<span class="hl-string">""</span>,VALUE,dates)
db2=database(<span class="hl-string">""</span>,RANGE,sym_ranges)
db=database(<span class="hl-string">"dfs://db2"</span>,COMPO,[db1,db2])
db.createPartitionedTable(t,`tb2,`timestamp`sym)</pre><ul class="- topic/ul ul"><li class="- topic/li li">如果总数据量很小，可以直接把所有数据加载到内存表中，再把内存表中的数据保存到新的数据库中。</li></ul><pre class="+ topic/pre pr-d/codeblock pre codeblock python">allData=select * <strong class="hl-keyword">from</strong> loadTable(<span class="hl-string">"dfs://db1"</span>,<span class="hl-string">"tb1"</span>)
tb2=loadTable(<span class="hl-string">"dfs://db2"</span>,<span class="hl-string">"tb2"</span>)
tb2.append!(allData)</pre><ul class="- topic/ul ul"><li class="- topic/li li">但通常分布式表的数据量非常大，无法全量加载到内存中，可以用 <code class="+ topic/ph pr-d/codeph ph codeph">repartitionDS</code> 函数划分数据源，将数据划分为若干个内存能够容纳的小数据块，再通过 map-reduce 的方法将数据块分批加载到内存并保存到新的数据库中。这样做不仅可以解决内存不够的问题，而且通过并行加载提升性能。<code class="+ topic/ph pr-d/codeph ph codeph">repartitionDS</code>函数的语法如下：</li></ul><pre class="+ topic/pre pr-d/codeblock pre codeblock python">repartitionDS(query, [column], [partitionType], [partitionScheme], [local=true])</pre><p class="- topic/p p">下例按天将数据划分为多个小数据块，分批将数据写入新的数据库中：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python"><strong class="hl-keyword">def</strong> writeDataTo(dbPath, tbName, mutable tbdata){
	loadTable(dbPath,tbName).append!(tbdata)
}

datasrc=repartitionDS(&lt;select * <strong class="hl-keyword">from</strong> loadTable(<span class="hl-string">"dfs://db1"</span>,<span class="hl-string">"tb1"</span>)&gt;,`date,VALUE,dates)
mr(ds=datasrc, mapFunc=writeDataTo{<span class="hl-string">"dfs://db2"</span>,<span class="hl-string">"tb2"</span>}, parallel=true)</pre><p class="- topic/p p">上例中 repartitionDS 函数中 local=true，表示会把重分区后的 chunk 数据都汇总到当前的协调节点，做进一步的 map-reduce 处理。如果当前节点的资源有限，可以将 local 设置为 false。</p><p class="- topic/p p">mr 函数中 parallel=true 表示小数据块会并行加载到内存和写入到数据库，只有满足以下两个条件才能将 parallel 设置为 true：（1）内存充足；（2）两个 map 子任务不会同时写入新数据库中的某个分区。否则要将 parallel 设置为 false，local 设置为 true。假如新数据库 dfs://db3 的第一层分区是按日期的范围进行分区，每个月一个分区：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">login(<span class="hl-string">"admin"</span>,<span class="hl-string">"123456"</span>)
t=table(<span class="hl-number">1</span>:<span class="hl-number">0</span>,`timestamp`sym`qty`price,[TIMESTAMP,SYMBOL,DOUBLE,DOUBLE])
months=date(<span class="hl-number">2010.01</span>M.<span class="hl-number">.2021</span>.<span class="hl-number">01</span>M)
syms=<span class="hl-string">"A"</span>+string(<span class="hl-number">1.</span><span class="hl-number">.500</span>)
sym_ranges=cutPoints(syms,<span class="hl-number">50</span>)
db1=database(<span class="hl-string">""</span>,RANGE,months) //每个月一个分区
db2=database(<span class="hl-string">""</span>,RANGE,sym_ranges)
db=database(<span class="hl-string">"dfs://db3"</span>,COMPO,[db1,db2])
db.createPartitionedTable(t,`tb3,`timestamp`sym)</pre><p class="- topic/p p">由于<code class="+ topic/ph pr-d/codeph ph codeph">repartitionDS</code>函数按天划分的多个小数据块对应新数据库中的同一个分区，而 DolphinDB 不允许同时对一个分区进行写入，因此要 parallel 设置为 false。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python"><strong class="hl-keyword">def</strong> writeDataTo(dbPath, tbName, mutable tbdata){
	loadTable(dbPath,tbName).append!(tbdata)
}

datasrc=repartitionDS(&lt;select * <strong class="hl-keyword">from</strong> loadTable(<span class="hl-string">"dfs://db1"</span>,<span class="hl-string">"tb1"</span>)&gt;,`date,VALUE,dates)
mr(ds=datasrc, mapFunc=writeDataTo{<span class="hl-string">"dfs://db2"</span>,<span class="hl-string">"tb2"</span>}, parallel=true)</pre><p class="- topic/p p"><code class="+ topic/ph pr-d/codeph ph codeph">repartitionDS</code>目前支持 VALUE 和 RANGE 两种分区方法。上例中，如果内存充足，我们也可以按月划分数据：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">months=date(<span class="hl-number">2010.01</span>M.<span class="hl-number">.2021</span>.<span class="hl-number">01</span>M)
datasrc=repartitionDS(&lt;select * <strong class="hl-keyword">from</strong> tb1&gt;,`date,RANGE,months) //按月划分
mr(ds=datasrc, mapFunc=writeDataTo{<span class="hl-string">"dfs://db2"</span>,<span class="hl-string">"tb2"</span>}, parallel=false)</pre></div></article><article class="- topic/topic topic nested2" aria-labelledby="ariaid-title28" id="62-复制-dfs-表"><h3 class="- topic/title title topictitle3" id="ariaid-title28">6.2. 复制 DFS 表</h3><div class="- topic/body body"><p class="- topic/p p">如果只需复制 DFS 表，不改变数据的分区类型和分区方案，可以使用 <code class="+ topic/ph pr-d/codeph ph codeph">sqlDS</code> 函数划分数据源。例如，把 6.1 中表 tb1 的内容复制到同一个数据库的表 tb1_bak 中：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">//创建tb1_bak
db=database(<span class="hl-string">"dfs://db1"</span>)
t=table(<span class="hl-number">1</span>:<span class="hl-number">0</span>,`timestamp`sym`qty`price,[TIMESTAMP,SYMBOL,DOUBLE,DOUBLE])
db.createPartitionedTable(t,`tb1_bak,`timestamp`sym)

//把表tb1的内容写入到表tb1_bak中
<strong class="hl-keyword">def</strong> writeDataTo(dbPath, tbName, mutable tbdata){
	loadTable(dbPath,tbName).append!(tbdata)
}

datasrc=sqlDS(&lt;select * <strong class="hl-keyword">from</strong> tb1&gt;)
mr(ds=datasrc, mapFunc=writeDataTo{<span class="hl-string">"dfs://db1"</span>,<span class="hl-string">"tb1_bak"</span>}, parallel=true)</pre><p class="- topic/p p">当然，<code class="+ topic/ph pr-d/codeph ph codeph">repartitionDS</code>的方法也适用于复制 DFS 表，但是使用<code class="+ topic/ph pr-d/codeph ph codeph">sqlDS</code>的性能更好。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">datasrc=repartitionDS(&lt;select * <strong class="hl-keyword">from</strong> tb1&gt;,`date,VALUE)
mr(ds=datasrc, mapFunc=writeDataTo{<span class="hl-string">"dfs://db1"</span>,<span class="hl-string">"tb1_bak"</span>}, parallel=true)</pre></div></article></article><article class="- topic/topic topic nested1" aria-labelledby="ariaid-title29" id="7-查询分区表注意事项"><h2 class="- topic/title title topictitle2" id="ariaid-title29">7. 查询分区表注意事项</h2><div class="- topic/body body"><p class="- topic/p p">系统在执行分布式查询时，首先根据 WHERE 条件确定需要的分区，然后把查询发送到相关分区所在的节点，最后整合这些分区的结果返回给用户。</p><p class="- topic/p p">大多数分布式查询只涉及分布式表的部分分区。系统会根据关系运算符（&lt;, &lt;=, =, ==, &gt;, &gt;=, in, between）和逻辑运算符（or，and）在加载和处理数据前确定相关的分区，避免全表扫描，从而节省大量时间。下面的例子可以帮助理解 DolphinDB 如何确定相关分区。以下脚本创建了分布式表 pt，其中分区字段是 date，分区类型是 RANGE，从 1990.01.01 开始，每 2 个月为一个分区。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock python">n=<span class="hl-number">10000000</span>
id=take(<span class="hl-number">1.</span><span class="hl-number">.1000</span>, n).sort()
date=<span class="hl-number">1989.12</span>.<span class="hl-number">31</span>+take(<span class="hl-number">1.</span><span class="hl-number">.10000</span>, n)
x=rand(<span class="hl-number">1.0</span>, n)
y=rand(<span class="hl-number">10</span>, n)
t=table(id, date, x, y)
db=database(<span class="hl-string">"dfs://rangedb1"</span>, RANGE, date(<span class="hl-number">1990.01</span>M+(<span class="hl-number">0.</span><span class="hl-number">.200</span>)*<span class="hl-number">2</span>))
pt = db.createPartitionedTable(t, `pt, `date)
pt.append!(t);

pt=db.loadTable(`pt);</pre><p class="- topic/p p">以下类型的查询可以在加载和处理数据前缩小数据范围：</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select * from pt where date&gt;1990.04.01 and date&lt;1990.06.01;</code></pre><p class="- topic/p p">系统确定了两个相关分区：[1990.03.01, 1990.05.01) 和[1990.05.01, 1990.07.01)。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select * from pt where date between 1990.12.01:1990.12.10;</code></pre><p class="- topic/p p">系统确定了一个相关分区：[1990.11.01, 1991.01.01)。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select count(*) from pt where date between 1990.08.01:1990.12.01 group by date;</code></pre><p class="- topic/p p">系统确定了三个相关分区：[1990.07.01, 1990.09.01)、[1990.09.01, 1990.11.01) 和[1990.11.01, 1991.01.01)。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select * from pt where y&lt;5 and date between 1990.08.01:1990.08.31;</code></pre><p class="- topic/p p">系统确定了一个相关分区：[1990.07.01, 1990.09.01)。注意，系统忽略了 y&lt;5 的条件。加载了相关分区后，系统会根据 y&lt;5 的条件进一步筛选数据。</p><p class="- topic/p p">以下类型的查询不能确定相关分区，会全表扫描。对于数据量非常大的分区表，会耗费大量时间，应当尽量避免。</p><pre class="+ topic/pre pr-d/codeblock pre codeblock"><code>select * from pt where date+10&gt;1990.08.01;

select * from pt where 1990.08.01&lt;date&lt;1990.09.01;

select * from pt where month(date)&lt;=1990.03M;

select * from pt where y&lt;5;

announcementDate=1990.08.01

select * from pt where date&lt;announcementDate-3;

select * from pt where y&lt;5 or date between 1990.08.01:1990.08.31;</code></pre></div></article></article></main></div>
                        
                        
                        
                        
                        
                        
                    </div>
                    
                        <nav role="navigation" id="wh_topic_toc" aria-label="On this page" class="col-lg-2 d-none d-lg-block navbar d-print-none"> 
                            <div id="wh_topic_toc_content">
		                        
	                            <div class=" wh_topic_toc "><div class="wh_topic_label">在本页上</div><ul><li class="topic-item"><a href="#1-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%AF%B9%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9B%E8%A1%8C%E5%88%86%E5%8C%BA" data-tocid="1-为什么对数据库进行分区">1. 为什么对数据库进行分区</a></li><li class="topic-item"><a href="#2-dolphindb-%E5%88%86%E5%8C%BA%E5%92%8C%E5%9F%BA%E4%BA%8E-mpp-%E6%9E%B6%E6%9E%84%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E7%9A%84%E5%8C%BA%E5%88%AB" data-tocid="2-dolphindb-分区和基于-mpp-架构的数据存储的区别">2. DolphinDB 分区和基于 MPP 架构的数据存储的区别</a></li><li class="topic-item"><a href="#3-%E5%88%86%E5%8C%BA%E7%B1%BB%E5%9E%8B" data-tocid="3-分区类型">3. 分区类型</a><ul><li class="topic-item"><a href="#31-%E8%8C%83%E5%9B%B4-range-%E5%88%86%E5%8C%BA" data-tocid="31-范围-range-分区">3.1. 范围 (RANGE) 分区</a></li><li class="topic-item"><a href="#32-%E5%93%88%E5%B8%8C-hash-%E5%88%86%E5%8C%BA" data-tocid="32-哈希-hash-分区">3.2. 哈希 (HASH) 分区</a></li><li class="topic-item"><a href="#33--%E5%80%BC-value-%E5%88%86%E5%8C%BA" data-tocid="33--值-value-分区">3.3.  值 (VALUE) 分区</a></li><li class="topic-item"><a href="#34-%E5%88%97%E8%A1%A8-list-%E5%88%86%E5%8C%BA" data-tocid="34-列表-list-分区">3.4. 列表 (LIST) 分区</a></li><li class="topic-item"><a href="#35-%E7%BB%84%E5%90%88-compo-%E5%88%86%E5%8C%BA" data-tocid="35-组合-compo-分区">3.5. 组合 (COMPO) 分区</a></li></ul></li><li class="topic-item"><a href="#4-%E5%88%86%E5%8C%BA%E8%AE%BE%E8%AE%A1%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9" data-tocid="4-分区设计注意事项">4. 分区设计注意事项</a><ul><li class="topic-item"><a href="#41-%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%88%86%E5%8C%BA%E5%AD%97%E6%AE%B5" data-tocid="41-选择合适的分区字段">4.1. 选择合适的分区字段</a></li><li class="topic-item"><a href="#42-%E5%88%86%E5%8C%BA%E7%B2%92%E5%BA%A6%E4%B8%8D%E8%A6%81%E8%BF%87%E5%A4%A7" data-tocid="42-分区粒度不要过大">4.2. 分区粒度不要过大</a></li><li class="topic-item"><a href="#43-%E5%88%86%E5%8C%BA%E7%B2%92%E5%BA%A6%E4%B8%8D%E8%A6%81%E8%BF%87%E5%B0%8F" data-tocid="43-分区粒度不要过小">4.3. 分区粒度不要过小</a></li><li class="topic-item"><a href="#44-%E5%A6%82%E4%BD%95%E5%B0%86%E6%95%B0%E6%8D%AE%E5%9D%87%E5%8C%80%E5%88%86%E5%8C%BA" data-tocid="44-如何将数据均匀分区">4.4. 如何将数据均匀分区</a></li><li class="topic-item"><a href="#45-%E6%97%B6%E5%BA%8F%E7%B1%BB%E5%9E%8B%E5%88%86%E5%8C%BA" data-tocid="45-时序类型分区">4.5. 时序类型分区</a></li><li class="topic-item"><a href="#46-%E4%B8%8D%E5%90%8C%E8%A1%A8%E7%9B%B8%E5%90%8C%E5%88%86%E5%8C%BA%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AD%98%E4%BA%8E%E5%90%8C%E4%B8%80%E8%8A%82%E7%82%B9" data-tocid="46-不同表相同分区的数据存于同一节点">4.6. 不同表相同分区的数据存于同一节点</a></li></ul></li><li class="topic-item"><a href="#5-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%88%B0%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E8%A1%A8" data-tocid="5-导入数据到分布式数据表">5. 导入数据到分布式数据表</a><ul><li class="topic-item"><a href="#51-%E5%A4%9A%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6" data-tocid="51-多副本机制">5.1. 多副本机制</a></li><li class="topic-item"><a href="#52-%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6" data-tocid="52-事务机制">5.2. 事务机制</a></li><li class="topic-item"><a href="#53-%E5%A4%9A-writer-%E5%B9%B6%E8%A1%8C%E5%86%99%E5%85%A5" data-tocid="53-多-writer-并行写入">5.3. 多 Writer 并行写入</a></li><li class="topic-item"><a href="#54-%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95" data-tocid="54-数据导入的常用方法">5.4. 数据导入的常用方法</a><ul><li class="topic-item"><a href="#541-%E4%BB%8E%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE" data-tocid="541-从文本文件导入数据">5.4.1. 从文本文件导入数据</a></li><li class="topic-item"><a href="#542-%E8%AE%A2%E9%98%85%E4%B8%80%E4%B8%AA%E6%B5%81%E6%95%B0%E6%8D%AE%E6%89%B9%E9%87%8F%E5%86%99%E5%85%A5" data-tocid="542-订阅一个流数据批量写入">5.4.2. 订阅一个流数据，批量写入</a></li><li class="topic-item"><a href="#543-%E9%80%9A%E8%BF%87-odbc-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE" data-tocid="543-通过-odbc-导入数据">5.4.3. 通过 ODBC 导入数据</a></li><li class="topic-item"><a href="#544-%E9%80%9A%E8%BF%87-programming-api-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE" data-tocid="544-通过-programming-api-导入数据">5.4.4. 通过 Programming API 导入数据</a></li></ul></li></ul></li><li class="topic-item"><a href="#6-%E6%95%B0%E6%8D%AE%E9%87%8D%E5%88%86%E5%8C%BA%E5%92%8C%E5%A4%8D%E5%88%B6-dfs-%E8%A1%A8" data-tocid="6-数据重分区和复制-dfs-表">6. 数据重分区和复制 DFS 表</a><ul><li class="topic-item"><a href="#61-%E6%95%B0%E6%8D%AE%E9%87%8D%E5%88%86%E5%8C%BA" data-tocid="61-数据重分区">6.1. 数据重分区</a></li><li class="topic-item"><a href="#62-%E5%A4%8D%E5%88%B6-dfs-%E8%A1%A8" data-tocid="62-复制-dfs-表">6.2. 复制 DFS 表</a></li></ul></li><li class="topic-item"><a href="#7-%E6%9F%A5%E8%AF%A2%E5%88%86%E5%8C%BA%E8%A1%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9" data-tocid="7-查询分区表注意事项">7. 查询分区表注意事项</a></li></ul></div>
	                        	
                        	</div>
                        </nav>
                    
                </div>
            </div>
            
            
            
        </div> 
        <footer class="navbar navbar-default wh_footer">
  <div class=" footer-container mx-auto ">
<title>Copyright</title><p><b> ©2025 浙江智臾科技有限公司 浙ICP备18048711号-3</b></p>
  </div>
</footer>
        
        <div id="go2top" class="d-print-none">
            <span class="oxy-icon oxy-icon-up"></span>
        </div>
        
        <div id="modal_img_large" class="modal">
            <span class="close oxy-icon oxy-icon-remove"></span>
            <div id="modal_img_container"></div>
            <div id="caption"></div>
        </div>
        
        
        
    </body>
</html>